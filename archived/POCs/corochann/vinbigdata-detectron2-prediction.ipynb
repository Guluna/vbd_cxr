{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014923,
     "end_time": "2021-02-06T01:14:40.700485",
     "exception": false,
     "start_time": "2021-02-06T01:14:40.685562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VinBigData detectron2 prediction\n",
    "\n",
    "\n",
    "**Following from the training kernel [VinBigData detectron2 train](https://www.kaggle.com/corochann/vinbigdata-detectron2-train), I will try prediction with the `detectron2` trained model**\n",
    "\n",
    "`detectron2` is one of the famous pytorch object detection library, I will introduce how to use this library to predict bounding boxes with the trained model.\n",
    "\n",
    " - https://github.com/facebookresearch/detectron2\n",
    "\n",
    "> Detectron2 is Facebook AI Research's next generation software system that implements state-of-the-art object detection algorithms. It is a ground-up rewrite of the previous version, Detectron, and it originates from maskrcnn-benchmark.\n",
    "![](https://user-images.githubusercontent.com/1381301/66535560-d3422200-eace-11e9-9123-5535d469db19.png)\n",
    "\n",
    "\n",
    "## Version history\n",
    "\n",
    "2021/1/22: Update to add 2-class filter in troduced in [VinBigData 🌟2 Class Filter🌟](https://www.kaggle.com/awsaf49/vinbigdata-2-class-filter) by @awsaf49 <br/>\n",
    "I also wrote kernel to train 2-class model: [📸VinBigData 2-class classifier complete pipeline](https://www.kaggle.com/corochann/vinbigdata-2-class-classifier-complete-pipeline)\n",
    "\n",
    "2021/2/6: Updated trained model [vinbigdata-alb-aug-512-cos](https://www.kaggle.com/corochann/vinbigdata-alb-aug-512-cos).<br/>\n",
    "Updated prediction kernel to align training kernel [VinBigData detectron2 train](https://www.kaggle.com/corochann/vinbigdata-detectron2-train), which uses customized augmentation.<br/>\n",
    "Apply 2-class filter in [📸VinBigData 2-class classifier complete pipeline](https://www.kaggle.com/corochann/vinbigdata-2-class-classifier-complete-pipeline)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013265,
     "end_time": "2021-02-06T01:14:40.727572",
     "exception": false,
     "start_time": "2021-02-06T01:14:40.714307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "** [Prediction method implementations](#pred_method)** <br/>\n",
    "** [Prediction scripts](#pred_scripts)** <br/>\n",
    "** [Apply 2 class filter](#2class)** <br/>\n",
    "** [Other kernels](#ref)** <br/>\n",
    "\n",
    "Since first setup part is same with the training kernel, I skipped listing on ToC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013207,
     "end_time": "2021-02-06T01:14:40.754198",
     "exception": false,
     "start_time": "2021-02-06T01:14:40.740991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset preparation\n",
    "\n",
    "Preprocessing x-ray image format (dicom) into normal png image format is already done by @xhlulu in the below discussion:\n",
    " - [Multiple preprocessed datasets: 256/512/1024px, PNG and JPG, modified and original ratio](https://www.kaggle.com/c/vinbigdata-chest-xray-abnormalities-detection/discussion/207955).\n",
    "\n",
    "Here I will just use the dataset [VinBigData Chest X-ray Resized PNG (256x256)](https://www.kaggle.com/xhlulu/vinbigdata-chest-xray-resized-png-256x256) to skip the preprocessing and focus on modeling part. Please upvote the dataset as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:14:40.791339Z",
     "iopub.status.busy": "2021-02-06T01:14:40.790766Z",
     "iopub.status.idle": "2021-02-06T01:14:49.356986Z",
     "shell.execute_reply": "2021-02-06T01:14:49.356148Z"
    },
    "papermill": {
     "duration": 8.589343,
     "end_time": "2021-02-06T01:14:49.357094",
     "exception": false,
     "start_time": "2021-02-06T01:14:40.767751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# --- plotly ---\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "# --- models ---\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "# --- setup ---\n",
    "pd.set_option('max_columns', 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014503,
     "end_time": "2021-02-06T01:14:49.387151",
     "exception": false,
     "start_time": "2021-02-06T01:14:49.372648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Installation\n",
    "\n",
    "detectron2 is not pre-installed in this kaggle docker, so let's install it. \n",
    "We can follow [installation instruction](https://github.com/facebookresearch/detectron2/blob/master/INSTALL.md), we need to know CUDA and pytorch version to install correct `detectron2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:14:49.425434Z",
     "iopub.status.busy": "2021-02-06T01:14:49.424686Z",
     "iopub.status.idle": "2021-02-06T01:14:50.098228Z",
     "shell.execute_reply": "2021-02-06T01:14:50.097773Z"
    },
    "papermill": {
     "duration": 0.696483,
     "end_time": "2021-02-06T01:14:50.098363",
     "exception": false,
     "start_time": "2021-02-06T01:14:49.401880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb  6 01:14:49 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   37C    P0    32W / 250W |      2MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:14:50.133826Z",
     "iopub.status.busy": "2021-02-06T01:14:50.133036Z",
     "iopub.status.idle": "2021-02-06T01:14:50.765558Z",
     "shell.execute_reply": "2021-02-06T01:14:50.765014Z"
    },
    "papermill": {
     "duration": 0.651732,
     "end_time": "2021-02-06T01:14:50.765678",
     "exception": false,
     "start_time": "2021-02-06T01:14:50.113946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Wed_Oct_23_19:24:38_PDT_2019\r\n",
      "Cuda compilation tools, release 10.2, V10.2.89\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:14:50.802267Z",
     "iopub.status.busy": "2021-02-06T01:14:50.801623Z",
     "iopub.status.idle": "2021-02-06T01:14:51.901525Z",
     "shell.execute_reply": "2021-02-06T01:14:51.900640Z"
    },
    "papermill": {
     "duration": 1.119558,
     "end_time": "2021-02-06T01:14:51.901633",
     "exception": false,
     "start_time": "2021-02-06T01:14:50.782075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01598,
     "end_time": "2021-02-06T01:14:51.934704",
     "exception": false,
     "start_time": "2021-02-06T01:14:51.918724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It seems CUDA=10.2 and torch==1.7.0 is used in this kaggle docker image.\n",
    "\n",
    "See [installation](https://detectron2.readthedocs.io/tutorials/install.html) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:14:51.976908Z",
     "iopub.status.busy": "2021-02-06T01:14:51.970938Z",
     "iopub.status.idle": "2021-02-06T01:15:17.686057Z",
     "shell.execute_reply": "2021-02-06T01:15:17.685027Z"
    },
    "papermill": {
     "duration": 25.735546,
     "end_time": "2021-02-06T01:15:17.686167",
     "exception": false,
     "start_time": "2021-02-06T01:14:51.950621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.7/index.html\r\n",
      "Collecting detectron2\r\n",
      "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.7/detectron2-0.3%2Bcu102-cp37-cp37m-linux_x86_64.whl (6.8 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 73.1 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from detectron2) (0.8.7)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from detectron2) (1.1.0)\r\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from detectron2) (2.4.0)\r\n",
      "Requirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.7/site-packages (from detectron2) (8.0.1)\r\n",
      "Requirement already satisfied: pydot in /opt/conda/lib/python3.7/site-packages (from detectron2) (1.4.1)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from detectron2) (1.6.0)\r\n",
      "Requirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from detectron2) (0.1.8)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from detectron2) (0.18.2)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from detectron2) (3.2.1)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.7/site-packages (from detectron2) (4.45.0)\r\n",
      "Collecting fvcore>=0.1.2\r\n",
      "  Downloading fvcore-0.1.3.post20210204.tar.gz (35 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore>=0.1.2->detectron2) (1.18.5)\r\n",
      "Requirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from detectron2) (0.1.8)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from fvcore>=0.1.2->detectron2) (5.3.1)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.7/site-packages (from detectron2) (4.45.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from detectron2) (1.1.0)\r\n",
      "Requirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.7/site-packages (from detectron2) (8.0.1)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from detectron2) (0.8.7)\r\n",
      "Collecting iopath>=0.1.2\r\n",
      "  Downloading iopath-0.1.3.tar.gz (10 kB)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.7/site-packages (from detectron2) (4.45.0)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from iopath>=0.1.2->fvcore>=0.1.2->detectron2) (2.0.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (2.8.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (2.4.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (1.2.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore>=0.1.2->detectron2) (1.18.5)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Collecting pycocotools>=2.0.2\r\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2) (0.29.21)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from detectron2) (3.2.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (2.4.7)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (1.23.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (1.0.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (0.34.2)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (3.2.1)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (1.7.0)\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (2.23.0)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (3.14.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore>=0.1.2->detectron2) (1.18.5)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (0.10.0)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (1.34.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (0.4.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.7)\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (3.1.1)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (1.23.0)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.2.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.25.9)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.9)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.12.5)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.0.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (2.23.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from fvcore>=0.1.2->detectron2) (5.3.1)\r\n",
      "Building wheels for collected packages: fvcore, iopath, pycocotools\r\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.3.post20210204-py3-none-any.whl size=44946 sha256=cebd71157a8c63796dd572aa0d25b0c30d288bfad63f3588790ab331d761d912\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/f2/8c/124367ec901d4b48b5ba4c0226c0a8239815b4e969ad15cc7a\r\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.3-py3-none-any.whl size=11169 sha256=4cc6176d7d4d20d3d74fa93127008acf6c3e0a6734d7fd12c2b4fb62d2c674ee\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/33/44/20/06445612ad8cf4ad6250aee85516e9499d5a49151ef5358164\r\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=273765 sha256=8c7b0e703bfde63e0c0cb0867ddeb6a26fa0d28d079ca6d26513f8602193ad7b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\r\n",
      "Successfully built fvcore iopath pycocotools\r\n",
      "Installing collected packages: iopath, pycocotools, fvcore, detectron2\r\n",
      "Successfully installed detectron2-0.3+cu102 fvcore-0.1.3.post20210204 iopath-0.1.3 pycocotools-2.0.2\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install detectron2 -f \\\n",
    "  https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.7/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030375,
     "end_time": "2021-02-06T01:15:17.747895",
     "exception": false,
     "start_time": "2021-02-06T01:15:17.717520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"pred_method\"></a>\n",
    "# Prediction method implementations\n",
    "\n",
    "Basically we don't need to implement neural network part, `detectron2` already implements famous architectures and provides its pre-trained weights. We can finetune these pre-trained architectures.\n",
    "\n",
    "These models are summarized in [MODEL_ZOO.md](https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md).\n",
    "\n",
    "In this competition, we need object detection model, I will choose [R50-FPN](https://github.com/facebookresearch/detectron2/blob/master/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml) for this kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030117,
     "end_time": "2021-02-06T01:15:17.808496",
     "exception": false,
     "start_time": "2021-02-06T01:15:17.778379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "`detectron2` provides high-level API for training custom dataset.\n",
    "\n",
    "To define custom dataset, we need to create **list of dict** where each dict contains following:\n",
    "\n",
    " - file_name: file name of the image.\n",
    " - image_id: id of the image, index is used here.\n",
    " - height: height of the image.\n",
    " - width: width of the image.\n",
    " - annotation: This is the ground truth annotation data for object detection, which contains following\n",
    "     - bbox: bounding box pixel location with shape (n_boxes, 4)\n",
    "     - bbox_mode: `BoxMode.XYXY_ABS` is used here, meaning that absolute value of (xmin, ymin, xmax, ymax) annotation is used in the `bbox`.\n",
    "     - category_id: class label id for each bounding box, with shape (n_boxes,)\n",
    "\n",
    "`get_vinbigdata_dicts` is for train dataset preparation and `get_vinbigdata_dicts_test` is for test dataset preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:17.888122Z",
     "iopub.status.busy": "2021-02-06T01:15:17.882822Z",
     "iopub.status.idle": "2021-02-06T01:15:18.420851Z",
     "shell.execute_reply": "2021-02-06T01:15:18.419793Z"
    },
    "papermill": {
     "duration": 0.582391,
     "end_time": "2021-02-06T01:15:18.420967",
     "exception": false,
     "start_time": "2021-02-06T01:15:17.838576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_vinbigdata_dicts(\n",
    "    imgdir: Path,\n",
    "    train_df: pd.DataFrame,\n",
    "    train_data_type: str = \"original\",\n",
    "    use_cache: bool = True,\n",
    "    debug: bool = True,\n",
    "    target_indices: Optional[np.ndarray] = None,\n",
    "    use_class14: bool = False,\n",
    "):\n",
    "    debug_str = f\"_debug{int(debug)}\"\n",
    "    train_data_type_str = f\"_{train_data_type}\"\n",
    "    class14_str = f\"_14class{int(use_class14)}\"\n",
    "    cache_path = Path(\".\") / f\"dataset_dicts_cache{train_data_type_str}{class14_str}{debug_str}.pkl\"\n",
    "    if not use_cache or not cache_path.exists():\n",
    "        print(\"Creating data...\")\n",
    "        train_meta = pd.read_csv(imgdir / \"train_meta.csv\")\n",
    "        if debug:\n",
    "            train_meta = train_meta.iloc[:500]  # For debug....\n",
    "\n",
    "        # Load 1 image to get image size.\n",
    "        image_id = train_meta.loc[0, \"image_id\"]\n",
    "        image_path = str(imgdir / \"train\" / f\"{image_id}.png\")\n",
    "        image = cv2.imread(image_path)\n",
    "        resized_height, resized_width, ch = image.shape\n",
    "        print(f\"image shape: {image.shape}\")\n",
    "\n",
    "        dataset_dicts = []\n",
    "        for index, train_meta_row in tqdm(train_meta.iterrows(), total=len(train_meta)):\n",
    "            record = {}\n",
    "\n",
    "            image_id, height, width = train_meta_row.values\n",
    "            filename = str(imgdir / \"train\" / f\"{image_id}.png\")\n",
    "            record[\"file_name\"] = filename\n",
    "            record[\"image_id\"] = image_id\n",
    "            record[\"height\"] = resized_height\n",
    "            record[\"width\"] = resized_width\n",
    "            objs = []\n",
    "            for index2, row in train_df.query(\"image_id == @image_id\").iterrows():\n",
    "                # print(row)\n",
    "                # print(row[\"class_name\"])\n",
    "                # class_name = row[\"class_name\"]\n",
    "                class_id = row[\"class_id\"]\n",
    "                if class_id == 14:\n",
    "                    # It is \"No finding\"\n",
    "                    if use_class14:\n",
    "                        # Use this No finding class with the bbox covering all image area.\n",
    "                        bbox_resized = [0, 0, resized_width, resized_height]\n",
    "                        obj = {\n",
    "                            \"bbox\": bbox_resized,\n",
    "                            \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                            \"category_id\": class_id,\n",
    "                        }\n",
    "                        objs.append(obj)\n",
    "                    else:\n",
    "                        # This annotator does not find anything, skip.\n",
    "                        pass\n",
    "                else:\n",
    "                    # bbox_original = [int(row[\"x_min\"]), int(row[\"y_min\"]), int(row[\"x_max\"]), int(row[\"y_max\"])]\n",
    "                    h_ratio = resized_height / height\n",
    "                    w_ratio = resized_width / width\n",
    "                    bbox_resized = [\n",
    "                        float(row[\"x_min\"]) * w_ratio,\n",
    "                        float(row[\"y_min\"]) * h_ratio,\n",
    "                        float(row[\"x_max\"]) * w_ratio,\n",
    "                        float(row[\"y_max\"]) * h_ratio,\n",
    "                    ]\n",
    "                    obj = {\n",
    "                        \"bbox\": bbox_resized,\n",
    "                        \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                        \"category_id\": class_id,\n",
    "                    }\n",
    "                    objs.append(obj)\n",
    "            record[\"annotations\"] = objs\n",
    "            dataset_dicts.append(record)\n",
    "        with open(cache_path, mode=\"wb\") as f:\n",
    "            pickle.dump(dataset_dicts, f)\n",
    "\n",
    "    print(f\"Load from cache {cache_path}\")\n",
    "    with open(cache_path, mode=\"rb\") as f:\n",
    "        dataset_dicts = pickle.load(f)\n",
    "    if target_indices is not None:\n",
    "        dataset_dicts = [dataset_dicts[i] for i in target_indices]\n",
    "    return dataset_dicts\n",
    "\n",
    "\n",
    "def get_vinbigdata_dicts_test(\n",
    "    imgdir: Path, test_meta: pd.DataFrame, use_cache: bool = True, debug: bool = True,\n",
    "):\n",
    "    debug_str = f\"_debug{int(debug)}\"\n",
    "    cache_path = Path(\".\") / f\"dataset_dicts_cache_test{debug_str}.pkl\"\n",
    "    if not use_cache or not cache_path.exists():\n",
    "        print(\"Creating data...\")\n",
    "        # test_meta = pd.read_csv(imgdir / \"test_meta.csv\")\n",
    "        if debug:\n",
    "            test_meta = test_meta.iloc[:500]  # For debug....\n",
    "\n",
    "        # Load 1 image to get image size.\n",
    "        image_id = test_meta.loc[0, \"image_id\"]\n",
    "        image_path = str(imgdir / \"test\" / f\"{image_id}.png\")\n",
    "        image = cv2.imread(image_path)\n",
    "        resized_height, resized_width, ch = image.shape\n",
    "        print(f\"image shape: {image.shape}\")\n",
    "\n",
    "        dataset_dicts = []\n",
    "        for index, test_meta_row in tqdm(test_meta.iterrows(), total=len(test_meta)):\n",
    "            record = {}\n",
    "\n",
    "            image_id, height, width = test_meta_row.values\n",
    "            filename = str(imgdir / \"test\" / f\"{image_id}.png\")\n",
    "            record[\"file_name\"] = filename\n",
    "            # record[\"image_id\"] = index\n",
    "            record[\"image_id\"] = image_id\n",
    "            record[\"height\"] = resized_height\n",
    "            record[\"width\"] = resized_width\n",
    "            # objs = []\n",
    "            # record[\"annotations\"] = objs\n",
    "            dataset_dicts.append(record)\n",
    "        with open(cache_path, mode=\"wb\") as f:\n",
    "            pickle.dump(dataset_dicts, f)\n",
    "\n",
    "    print(f\"Load from cache {cache_path}\")\n",
    "    with open(cache_path, mode=\"rb\") as f:\n",
    "        dataset_dicts = pickle.load(f)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030425,
     "end_time": "2021-02-06T01:15:18.482512",
     "exception": false,
     "start_time": "2021-02-06T01:15:18.452087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Methods for prediction for this competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:18.558789Z",
     "iopub.status.busy": "2021-02-06T01:15:18.557892Z",
     "iopub.status.idle": "2021-02-06T01:15:18.660026Z",
     "shell.execute_reply": "2021-02-06T01:15:18.659107Z"
    },
    "papermill": {
     "duration": 0.146868,
     "end_time": "2021-02-06T01:15:18.660146",
     "exception": false,
     "start_time": "2021-02-06T01:15:18.513278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Methods for prediction for this competition\n",
    "from math import ceil\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import cv2\n",
    "import detectron2\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "import torch\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def format_pred(labels: ndarray, boxes: ndarray, scores: ndarray) -> str:\n",
    "    pred_strings = []\n",
    "    for label, score, bbox in zip(labels, scores, boxes):\n",
    "        xmin, ymin, xmax, ymax = bbox.astype(np.int64)\n",
    "        pred_strings.append(f\"{label} {score} {xmin} {ymin} {xmax} {ymax}\")\n",
    "    return \" \".join(pred_strings)\n",
    "\n",
    "\n",
    "def predict_batch(predictor: DefaultPredictor, im_list: List[ndarray]) -> List:\n",
    "    with torch.no_grad():  # https://github.com/sphinx-doc/sphinx/issues/4258\n",
    "        inputs_list = []\n",
    "        for original_image in im_list:\n",
    "            # Apply pre-processing to image.\n",
    "            if predictor.input_format == \"RGB\":\n",
    "                # whether the model expects BGR inputs or RGB\n",
    "                original_image = original_image[:, :, ::-1]\n",
    "            height, width = original_image.shape[:2]\n",
    "            # Do not apply original augmentation, which is resize.\n",
    "            # image = predictor.aug.get_transform(original_image).apply_image(original_image)\n",
    "            image = original_image\n",
    "            image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "            inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
    "            inputs_list.append(inputs)\n",
    "        predictions = predictor.model(inputs_list)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:18.728927Z",
     "iopub.status.busy": "2021-02-06T01:15:18.728237Z",
     "iopub.status.idle": "2021-02-06T01:15:18.731353Z",
     "shell.execute_reply": "2021-02-06T01:15:18.730916Z"
    },
    "papermill": {
     "duration": 0.040308,
     "end_time": "2021-02-06T01:15:18.731448",
     "exception": false,
     "start_time": "2021-02-06T01:15:18.691140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- utils ---\n",
    "from pathlib import Path\n",
    "from typing import Any, Union\n",
    "\n",
    "import yaml\n",
    "\n",
    "\n",
    "def save_yaml(filepath: Union[str, Path], content: Any, width: int = 120):\n",
    "    with open(filepath, \"w\") as f:\n",
    "        yaml.dump(content, f, width=width)\n",
    "\n",
    "\n",
    "def load_yaml(filepath: Union[str, Path]) -> Any:\n",
    "    with open(filepath, \"r\") as f:\n",
    "        content = yaml.full_load(f)\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:18.798362Z",
     "iopub.status.busy": "2021-02-06T01:15:18.797588Z",
     "iopub.status.idle": "2021-02-06T01:15:18.800281Z",
     "shell.execute_reply": "2021-02-06T01:15:18.799875Z"
    },
    "papermill": {
     "duration": 0.038382,
     "end_time": "2021-02-06T01:15:18.800387",
     "exception": false,
     "start_time": "2021-02-06T01:15:18.762005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- configs ---\n",
    "thing_classes = [\n",
    "    \"Aortic enlargement\",\n",
    "    \"Atelectasis\",\n",
    "    \"Calcification\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Consolidation\",\n",
    "    \"ILD\",\n",
    "    \"Infiltration\",\n",
    "    \"Lung Opacity\",\n",
    "    \"Nodule/Mass\",\n",
    "    \"Other lesion\",\n",
    "    \"Pleural effusion\",\n",
    "    \"Pleural thickening\",\n",
    "    \"Pneumothorax\",\n",
    "    \"Pulmonary fibrosis\"\n",
    "]\n",
    "category_name_to_id = {class_name: index for index, class_name in enumerate(thing_classes)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030436,
     "end_time": "2021-02-06T01:15:18.861660",
     "exception": false,
     "start_time": "2021-02-06T01:15:18.831224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This `Flags` class is to manage experiments. I will tune these parameters through the competition to improve model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:18.934748Z",
     "iopub.status.busy": "2021-02-06T01:15:18.933968Z",
     "iopub.status.idle": "2021-02-06T01:15:18.936638Z",
     "shell.execute_reply": "2021-02-06T01:15:18.936201Z"
    },
    "papermill": {
     "duration": 0.044023,
     "end_time": "2021-02-06T01:15:18.936724",
     "exception": false,
     "start_time": "2021-02-06T01:15:18.892701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- flags ---\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Flags:\n",
    "    # General\n",
    "    debug: bool = True\n",
    "    outdir: str = \"results/det\"\n",
    "\n",
    "    # Data config\n",
    "    imgdir_name: str = \"vinbigdata-chest-xray-resized-png-256x256\"\n",
    "    split_mode: str = \"all_train\"  # all_train or valid20\n",
    "    seed: int = 111\n",
    "    train_data_type: str = \"original\"  # original or wbf\n",
    "    use_class14: bool = False\n",
    "    # Training config\n",
    "    iter: int = 10000\n",
    "    ims_per_batch: int = 2  # images per batch, this corresponds to \"total batch size\"\n",
    "    num_workers: int = 4\n",
    "    lr_scheduler_name: str = \"WarmupMultiStepLR\"  # WarmupMultiStepLR (default) or WarmupCosineLR\n",
    "    base_lr: float = 0.00025\n",
    "    roi_batch_size_per_image: int = 512\n",
    "    eval_period: int = 10000\n",
    "    aug_kwargs: Dict = field(default_factory=lambda: {})\n",
    "\n",
    "    def update(self, param_dict: Dict) -> \"Flags\":\n",
    "        # Overwrite by `param_dict`\n",
    "        for key, value in param_dict.items():\n",
    "            if not hasattr(self, key):\n",
    "                raise ValueError(f\"[ERROR] Unexpected key for flag = {key}\")\n",
    "            setattr(self, key, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062839,
     "end_time": "2021-02-06T01:15:19.030588",
     "exception": false,
     "start_time": "2021-02-06T01:15:18.967749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"pred_scripts\"></a>\n",
    "# Prediction scripts\n",
    "\n",
    "Now the methods are ready. Main training scripts starts from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:19.099562Z",
     "iopub.status.busy": "2021-02-06T01:15:19.099024Z",
     "iopub.status.idle": "2021-02-06T01:15:19.151049Z",
     "shell.execute_reply": "2021-02-06T01:15:19.150450Z"
    },
    "papermill": {
     "duration": 0.089808,
     "end_time": "2021-02-06T01:15:19.151183",
     "exception": false,
     "start_time": "2021-02-06T01:15:19.061375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags Flags(debug=False, outdir='results/20210125_all_alb_aug_512_cos', imgdir_name='vinbigdata-chest-xray-resized-png-512x512', split_mode='all_train', seed=111, train_data_type='original', use_class14=False, iter=30000, ims_per_batch=2, num_workers=4, lr_scheduler_name='WarmupCosineLR', base_lr=0.001, roi_batch_size_per_image=512, eval_period=2000, aug_kwargs={'HorizontalFlip': {'p': 0.5}, 'RandomBrightnessContrast': {'p': 0.5}, 'ShiftScaleRotate': {'p': 0.5, 'rotate_limit': 10, 'scale_limit': 0.15}})\n"
     ]
    }
   ],
   "source": [
    "inputdir = Path(\"/kaggle/input\")\n",
    "traineddir = inputdir / \"vinbigdata-alb-aug-512-cos\"\n",
    "\n",
    "# flags = Flags()\n",
    "flags: Flags = Flags().update(load_yaml(str(traineddir/\"flags.yaml\")))\n",
    "print(\"flags\", flags)\n",
    "debug = flags.debug\n",
    "# flags_dict = dataclasses.asdict(flags)\n",
    "outdir = Path(flags.outdir)\n",
    "os.makedirs(str(outdir), exist_ok=True)\n",
    "\n",
    "# --- Read data ---\n",
    "datadir = inputdir / \"vinbigdata-chest-xray-abnormalities-detection\"\n",
    "if flags.imgdir_name == \"vinbigdata-chest-xray-resized-png-512x512\":\n",
    "    imgdir = inputdir/ \"vinbigdata\"\n",
    "else:\n",
    "    imgdir = inputdir / flags.imgdir_name\n",
    "\n",
    "# Read in the data CSV files\n",
    "# train = pd.read_csv(datadir / \"train.csv\")\n",
    "test_meta = pd.read_csv(inputdir / \"vinbigdata-testmeta\" / \"test_meta.csv\")\n",
    "sample_submission = pd.read_csv(datadir / \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:19.241650Z",
     "iopub.status.busy": "2021-02-06T01:15:19.240750Z",
     "iopub.status.idle": "2021-02-06T01:18:09.029757Z",
     "shell.execute_reply": "2021-02-06T01:18:09.030176Z"
    },
    "papermill": {
     "duration": 169.846964,
     "end_time": "2021-02-06T01:18:09.030345",
     "exception": false,
     "start_time": "2021-02-06T01:15:19.183381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg.OUTPUT_DIR ./output -> results/20210125_all_alb_aug_512_cos\n",
      "Original thresh 0.05\n",
      "Changed  thresh 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1105/3000 [00:00<00:00, 11045.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data...\n",
      "image shape: (512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 10825.12it/s]\n",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from cache dataset_dicts_cache_test_debug0.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:124: UserWarning:\n",
      "\n",
      "This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729138878/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "\n",
      "100%|██████████| 750/750 [02:37<00:00,  4.77it/s]\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "original_output_dir = cfg.OUTPUT_DIR\n",
    "cfg.OUTPUT_DIR = str(outdir)\n",
    "print(f\"cfg.OUTPUT_DIR {original_output_dir} -> {cfg.OUTPUT_DIR}\")\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"vinbigdata_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "# cfg.DATASETS.TEST = (\"vinbigdata_train\",)\n",
    "# cfg.TEST.EVAL_PERIOD = 50\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "# Let training initialize from model zoo\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = flags.base_lr  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = flags.iter\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = flags.roi_batch_size_per_image\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(thing_classes)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "### --- Inference & Evaluation ---\n",
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "# path to the model we just trained\n",
    "cfg.MODEL.WEIGHTS = str(traineddir/\"model_final.pth\")\n",
    "print(\"Original thresh\", cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST)  # 0.05\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.0  # set a custom testing threshold\n",
    "print(\"Changed  thresh\", cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST)\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "DatasetCatalog.register(\n",
    "    \"vinbigdata_test\", lambda: get_vinbigdata_dicts_test(imgdir, test_meta, debug=debug)\n",
    ")\n",
    "MetadataCatalog.get(\"vinbigdata_test\").set(thing_classes=thing_classes)\n",
    "metadata = MetadataCatalog.get(\"vinbigdata_test\")\n",
    "dataset_dicts = get_vinbigdata_dicts_test(imgdir, test_meta, debug=debug)\n",
    "\n",
    "if debug:\n",
    "    dataset_dicts = dataset_dicts[:100]\n",
    "\n",
    "results_list = []\n",
    "index = 0\n",
    "batch_size = 4\n",
    "\n",
    "for i in tqdm(range(ceil(len(dataset_dicts) / batch_size))):\n",
    "    inds = list(range(batch_size * i, min(batch_size * (i + 1), len(dataset_dicts))))\n",
    "    dataset_dicts_batch = [dataset_dicts[i] for i in inds]\n",
    "    im_list = [cv2.imread(d[\"file_name\"]) for d in dataset_dicts_batch]\n",
    "    outputs_list = predict_batch(predictor, im_list)\n",
    "\n",
    "    for im, outputs, d in zip(im_list, outputs_list, dataset_dicts_batch):\n",
    "        resized_height, resized_width, ch = im.shape\n",
    "        # outputs = predictor(im)\n",
    "        if index < 5:\n",
    "            # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "            v = Visualizer(\n",
    "                im[:, :, ::-1],\n",
    "                metadata=metadata,\n",
    "                scale=0.5,\n",
    "                instance_mode=ColorMode.IMAGE_BW\n",
    "                # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "            )\n",
    "            out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "            # cv2_imshow(out.get_image()[:, :, ::-1])\n",
    "            cv2.imwrite(str(outdir / f\"pred_{index}.jpg\"), out.get_image()[:, :, ::-1])\n",
    "\n",
    "        image_id, dim0, dim1 = test_meta.iloc[index].values\n",
    "\n",
    "        instances = outputs[\"instances\"]\n",
    "        if len(instances) == 0:\n",
    "            # No finding, let's set 14 1 0 0 1 1x.\n",
    "            result = {\"image_id\": image_id, \"PredictionString\": \"14 1.0 0 0 1 1\"}\n",
    "        else:\n",
    "            # Find some bbox...\n",
    "            # print(f\"index={index}, find {len(instances)} bbox.\")\n",
    "            fields: Dict[str, Any] = instances.get_fields()\n",
    "            pred_classes = fields[\"pred_classes\"]  # (n_boxes,)\n",
    "            pred_scores = fields[\"scores\"]\n",
    "            # shape (n_boxes, 4). (xmin, ymin, xmax, ymax)\n",
    "            pred_boxes = fields[\"pred_boxes\"].tensor\n",
    "\n",
    "            h_ratio = dim0 / resized_height\n",
    "            w_ratio = dim1 / resized_width\n",
    "            pred_boxes[:, [0, 2]] *= w_ratio\n",
    "            pred_boxes[:, [1, 3]] *= h_ratio\n",
    "\n",
    "            pred_classes_array = pred_classes.cpu().numpy()\n",
    "            pred_boxes_array = pred_boxes.cpu().numpy()\n",
    "            pred_scores_array = pred_scores.cpu().numpy()\n",
    "\n",
    "            result = {\n",
    "                \"image_id\": image_id,\n",
    "                \"PredictionString\": format_pred(\n",
    "                    pred_classes_array, pred_boxes_array, pred_scores_array\n",
    "                ),\n",
    "            }\n",
    "        results_list.append(result)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.236492,
     "end_time": "2021-02-06T01:18:09.503575",
     "exception": false,
     "start_time": "2021-02-06T01:18:09.267083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here I set `cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.0` to produce **all the detection box prediction even if confidence score is very low**.<br/>\n",
    "Actually it affects a lot to score, since competition metric is AP (Average-Precision) which is calculated using the boxes with confidence score = 0~100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T01:18:09.984011Z",
     "iopub.status.busy": "2021-02-06T01:18:09.983235Z",
     "iopub.status.idle": "2021-02-06T01:18:10.623768Z",
     "shell.execute_reply": "2021-02-06T01:18:10.624195Z"
    },
    "papermill": {
     "duration": 0.885336,
     "end_time": "2021-02-06T01:18:10.624332",
     "exception": false,
     "start_time": "2021-02-06T01:18:09.738996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8dec5497ecc246766acfba5a4be4e619</td>\n",
       "      <td>0 0.775484561920166 1010 603 1248 893 13 0.501...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287422bed1d9d153387361889619abed</td>\n",
       "      <td>3 0.9862767457962036 666 1289 1865 1820 0 0.78...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1d12b94b7acbeadef7d7700b50aa90d4</td>\n",
       "      <td>0 0.8117097616195679 1173 896 1433 1138 3 0.78...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6b872791e23742f6c33a08fc24f77365</td>\n",
       "      <td>11 0.3285936415195465 1799 2196 1900 2336 10 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d0d2addff91ad7beb1d92126ff74d621</td>\n",
       "      <td>0 0.850891649723053 1422 828 1707 1140 3 0.741...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>78b44b96b121d6075d7ae27135278e03</td>\n",
       "      <td>0 0.5035402178764343 1036 771 1214 949 11 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>afee8ff90f29b8827d0eb78774d25324</td>\n",
       "      <td>0 0.27024954557418823 1028 714 1243 947 11 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>6e07fab2014be723250f7897ab6e3df2</td>\n",
       "      <td>0 0.990529477596283 1667 801 1972 1131 3 0.977...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>690bb572300ef08bbbb7ebf4196099cf</td>\n",
       "      <td>0 0.5590820908546448 1085 689 1337 956 8 0.464...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0a08191a658edb1327e7282045ec71cf</td>\n",
       "      <td>11 0.45100387930870056 565 379 797 479 11 0.16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              image_id  \\\n",
       "0     8dec5497ecc246766acfba5a4be4e619   \n",
       "1     287422bed1d9d153387361889619abed   \n",
       "2     1d12b94b7acbeadef7d7700b50aa90d4   \n",
       "3     6b872791e23742f6c33a08fc24f77365   \n",
       "4     d0d2addff91ad7beb1d92126ff74d621   \n",
       "...                                ...   \n",
       "2995  78b44b96b121d6075d7ae27135278e03   \n",
       "2996  afee8ff90f29b8827d0eb78774d25324   \n",
       "2997  6e07fab2014be723250f7897ab6e3df2   \n",
       "2998  690bb572300ef08bbbb7ebf4196099cf   \n",
       "2999  0a08191a658edb1327e7282045ec71cf   \n",
       "\n",
       "                                       PredictionString  \n",
       "0     0 0.775484561920166 1010 603 1248 893 13 0.501...  \n",
       "1     3 0.9862767457962036 666 1289 1865 1820 0 0.78...  \n",
       "2     0 0.8117097616195679 1173 896 1433 1138 3 0.78...  \n",
       "3     11 0.3285936415195465 1799 2196 1900 2336 10 0...  \n",
       "4     0 0.850891649723053 1422 828 1707 1140 3 0.741...  \n",
       "...                                                 ...  \n",
       "2995  0 0.5035402178764343 1036 771 1214 949 11 0.10...  \n",
       "2996  0 0.27024954557418823 1028 714 1243 947 11 0.0...  \n",
       "2997  0 0.990529477596283 1667 801 1972 1131 3 0.977...  \n",
       "2998  0 0.5590820908546448 1085 689 1337 956 8 0.464...  \n",
       "2999  11 0.45100387930870056 565 379 797 479 11 0.16...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This submission includes only detection model's predictions\n",
    "submission_det = pd.DataFrame(results_list, columns=['image_id', 'PredictionString'])\n",
    "submission_det.to_csv(outdir/\"submission.csv\", index=False)\n",
    "submission_det"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.23829,
     "end_time": "2021-02-06T01:18:11.100744",
     "exception": false,
     "start_time": "2021-02-06T01:18:10.862454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"2class\"></a>\n",
    "# Apply 2 class filter\n",
    "\n",
    "I moved this section to [📸VinBigData 2-class classifier complete pipeline](https://www.kaggle.com/corochann/vinbigdata-2-class-classifier-complete-pipeline).<br/>\n",
    "Please refer the kernel, **it improves LB score significantly from 0.141 -> 0.221**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.237073,
     "end_time": "2021-02-06T01:18:11.575869",
     "exception": false,
     "start_time": "2021-02-06T01:18:11.338796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Discussion: How to improve more?**\n",
    "\n",
    "I'm now thinking that it's better to include normal images for training to learn where there is **no** abnormality.<br/>\n",
    "Also, I think it's nice to try **including \"No finding\" class during detection training** (by adding virtual \"No finding\" boxes, or by adding global classifier together with the detection).\n",
    "\n",
    "\n",
    "That's all!\n",
    "Object deteaction is rather complicated task among deep learning tasks, but it's easy to train SoTA models & predict using `detectron2`!!!\n",
    "\n",
    "<h3 style=\"color:red\">If this kernel helps you, please upvote to keep me motivated 😁<br>Thanks!</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.237289,
     "end_time": "2021-02-06T01:18:12.051338",
     "exception": false,
     "start_time": "2021-02-06T01:18:11.814049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"ref\"></a>\n",
    "# Other kernels\n",
    "\n",
    "[📸VinBigData detectron2 train](https://www.kaggle.com/corochann/vinbigdata-detectron2-train) kernel explains how to run object detection training, using `detectron2` library.\n",
    "\n",
    "[📸VinBigData 2-class classifier complete pipeline](https://www.kaggle.com/corochann/vinbigdata-2-class-classifier-complete-pipeline) kernel explains how to train 2 class classifier model for the prediction and submisssion for this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.237092,
     "end_time": "2021-02-06T01:18:12.526004",
     "exception": false,
     "start_time": "2021-02-06T01:18:12.288912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 216.743164,
   "end_time": "2021-02-06T01:18:13.273240",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-06T01:14:36.530076",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
