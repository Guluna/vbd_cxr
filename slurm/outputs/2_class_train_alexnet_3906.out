cuda
Program started
Epoch 0/49
----------
Train Iteration #0:: 1.171302080154419 Acc: 0.5
Train Iteration #50:: 0.9656960368156433 Acc: 0.53125
Train Iteration #100:: 0.8653061389923096 Acc: 0.71875
Train Iteration #150:: 0.8073803782463074 Acc: 0.53125
Train Iteration #200:: 0.8744946718215942 Acc: 0.65625
Train Iteration #250:: 0.8243408203125 Acc: 0.6875
Train Iteration #300:: 0.8242448568344116 Acc: 0.5625
Train Iteration #350:: 0.9322057962417603 Acc: 0.46875
Training:: Loss: 0.9183 Acc: 0.6086
Validation Iteration #0:: 0.7619652152061462 Acc: 0.5625
Validation:: Loss: 0.8922 Acc: 0.5056
Epoch 1/49
----------
Train Iteration #400:: 0.7586995363235474 Acc: 0.8125
Train Iteration #450:: 0.8285437822341919 Acc: 0.625
Train Iteration #500:: 0.8592279553413391 Acc: 0.625
Train Iteration #550:: 0.8560267686843872 Acc: 0.65625
Train Iteration #600:: 0.9803269505500793 Acc: 0.59375
Train Iteration #650:: 0.7549151182174683 Acc: 0.59375
Train Iteration #700:: 0.836939811706543 Acc: 0.5
Train Iteration #750:: 0.6116908192634583 Acc: 0.84375
Training:: Loss: 0.8568 Acc: 0.6499
Validation Iteration #50:: 0.9337038993835449 Acc: 0.46875
Validation:: Loss: 0.9570 Acc: 0.4640
Epoch 2/49
----------
Train Iteration #800:: 0.821690559387207 Acc: 0.75
Train Iteration #850:: 1.0069947242736816 Acc: 0.59375
Train Iteration #900:: 0.8340604305267334 Acc: 0.59375
Train Iteration #950:: 0.8574085831642151 Acc: 0.625
Train Iteration #1000:: 0.9985517859458923 Acc: 0.5
Train Iteration #1050:: 1.1466445922851562 Acc: 0.4375
Train Iteration #1100:: 0.9345276355743408 Acc: 0.65625
Training:: Loss: 0.8301 Acc: 0.6703
Validation Iteration #100:: 1.039168357849121 Acc: 0.4375
Validation:: Loss: 1.0760 Acc: 0.4433
Epoch 3/49
----------
Train Iteration #1150:: 1.144300103187561 Acc: 0.6875
Train Iteration #1200:: 0.7498447895050049 Acc: 0.75
Train Iteration #1250:: 0.8275672793388367 Acc: 0.6875
Train Iteration #1300:: 0.8594965934753418 Acc: 0.71875
Train Iteration #1350:: 1.1872031688690186 Acc: 0.53125
Train Iteration #1400:: 1.2481045722961426 Acc: 0.5625
Train Iteration #1450:: 0.9042111039161682 Acc: 0.71875
Train Iteration #1500:: 0.8106544017791748 Acc: 0.65625
Training:: Loss: 0.8265 Acc: 0.6785
Validation Iteration #150:: 0.706298828125 Acc: 0.625
Validation:: Loss: 0.9129 Acc: 0.5056
Epoch 4/49
----------
Train Iteration #1550:: 0.838952898979187 Acc: 0.75
Train Iteration #1600:: 1.0106481313705444 Acc: 0.6875
Train Iteration #1650:: 0.757910966873169 Acc: 0.65625
Train Iteration #1700:: 0.7256708741188049 Acc: 0.78125
Train Iteration #1750:: 0.4700087904930115 Acc: 0.9375
Train Iteration #1800:: 0.8311057090759277 Acc: 0.625
Train Iteration #1850:: 0.8372257947921753 Acc: 0.71875
Training:: Loss: 0.8166 Acc: 0.6865
Validation Iteration #200:: 0.670309841632843 Acc: 0.6875
Validation:: Loss: 0.7053 Acc: 0.6360
Epoch 5/49
----------
Train Iteration #1900:: 0.9389150738716125 Acc: 0.5625
Train Iteration #1950:: 0.9843634963035583 Acc: 0.78125
Train Iteration #2000:: 0.8774609565734863 Acc: 0.625
Train Iteration #2050:: 0.9829840064048767 Acc: 0.71875
Train Iteration #2100:: 0.7293089628219604 Acc: 0.6875
Train Iteration #2150:: 0.5477417707443237 Acc: 0.875
Train Iteration #2200:: 0.7052385210990906 Acc: 0.78125
Train Iteration #2250:: 0.982674777507782 Acc: 0.65625
Training:: Loss: 0.8208 Acc: 0.6850
Validation Iteration #250:: 0.8049049973487854 Acc: 0.59375
Validation:: Loss: 0.8117 Acc: 0.5471
Epoch 6/49
----------
Train Iteration #2300:: 1.2211683988571167 Acc: 0.5
Train Iteration #2350:: 0.9109441637992859 Acc: 0.65625
Train Iteration #2400:: 0.8152902126312256 Acc: 0.625
Train Iteration #2450:: 0.49490776658058167 Acc: 0.78125
Train Iteration #2500:: 0.6550501585006714 Acc: 0.71875
Train Iteration #2550:: 0.816243052482605 Acc: 0.625
Train Iteration #2600:: 0.8077307939529419 Acc: 0.6875
Train Iteration #2650:: 0.8845871090888977 Acc: 0.75
Training:: Loss: 0.8173 Acc: 0.6919
Validation Iteration #300:: 0.9927725195884705 Acc: 0.4
Validation:: Loss: 0.9138 Acc: 0.5078
Epoch 7/49
----------
Train Iteration #2700:: 0.9233474731445312 Acc: 0.5625
Train Iteration #2750:: 0.6728886365890503 Acc: 0.71875
Train Iteration #2800:: 0.6382028460502625 Acc: 0.71875
Train Iteration #2850:: 1.132110834121704 Acc: 0.5625
Train Iteration #2900:: 0.7733684778213501 Acc: 0.6875
Train Iteration #2950:: 0.583702564239502 Acc: 0.8125
Train Iteration #3000:: 1.0356794595718384 Acc: 0.59375
Training:: Loss: 0.8186 Acc: 0.6915
Validation:: Loss: 0.7606 Acc: 0.5871
Epoch 8/49
----------
Train Iteration #3050:: 1.0123714208602905 Acc: 0.53125
Train Iteration #3100:: 0.953265905380249 Acc: 0.5625
Train Iteration #3150:: 1.0074928998947144 Acc: 0.65625
Train Iteration #3200:: 0.7123932838439941 Acc: 0.8125
Train Iteration #3250:: 1.2009780406951904 Acc: 0.53125
Train Iteration #3300:: 0.6586904525756836 Acc: 0.78125
Train Iteration #3350:: 0.6742743849754333 Acc: 0.78125
Train Iteration #3400:: 0.9166707396507263 Acc: 0.65625
Training:: Loss: 0.8097 Acc: 0.6926
Validation Iteration #350:: 0.524067223072052 Acc: 0.8125
Validation:: Loss: 0.6237 Acc: 0.7279
Epoch 9/49
----------
Train Iteration #3450:: 0.7446495294570923 Acc: 0.65625
Train Iteration #3500:: 0.7676267623901367 Acc: 0.71875
Train Iteration #3550:: 0.5183637142181396 Acc: 0.84375
Train Iteration #3600:: 0.7738612294197083 Acc: 0.65625
Train Iteration #3650:: 0.9228232502937317 Acc: 0.5625
Train Iteration #3700:: 0.8886778354644775 Acc: 0.6875
Train Iteration #3750:: 0.8496731519699097 Acc: 0.75
Training:: Loss: 0.7985 Acc: 0.7010
Validation Iteration #400:: 0.825819730758667 Acc: 0.625
Validation:: Loss: 0.6793 Acc: 0.6546
Epoch 10/49
----------
Train Iteration #3800:: 0.9922481179237366 Acc: 0.65625
Train Iteration #3850:: 0.9915143251419067 Acc: 0.71875
Train Iteration #3900:: 0.816421627998352 Acc: 0.71875
Train Iteration #3950:: 0.7523330450057983 Acc: 0.71875
Train Iteration #4000:: 0.7011977434158325 Acc: 0.625
Train Iteration #4050:: 0.9054641723632812 Acc: 0.625
Train Iteration #4100:: 1.0305570363998413 Acc: 0.625
Train Iteration #4150:: 0.6395601034164429 Acc: 0.8125
Training:: Loss: 0.8008 Acc: 0.6991
Validation Iteration #450:: 0.7575472593307495 Acc: 0.5625
Validation:: Loss: 0.7480 Acc: 0.6093
Epoch 11/49
----------
Train Iteration #4200:: 1.0699836015701294 Acc: 0.59375
Train Iteration #4250:: 0.9827209711074829 Acc: 0.625
Train Iteration #4300:: 0.9814079403877258 Acc: 0.5
Train Iteration #4350:: 0.7860839366912842 Acc: 0.75
Train Iteration #4400:: 0.7905073165893555 Acc: 0.78125
Train Iteration #4450:: 0.6535509824752808 Acc: 0.625
Train Iteration #4500:: 0.8091870546340942 Acc: 0.6875
Train Iteration #4550:: 0.8463027477264404 Acc: 0.65625
Training:: Loss: 0.8141 Acc: 0.6967
Validation Iteration #500:: 0.6684489250183105 Acc: 0.65625
Validation:: Loss: 0.6559 Acc: 0.6976
Epoch 12/49
----------
Train Iteration #4600:: 0.8447400331497192 Acc: 0.65625
Train Iteration #4650:: 1.2612422704696655 Acc: 0.5625
Train Iteration #4700:: 0.8996189832687378 Acc: 0.6875
Train Iteration #4750:: 1.0175507068634033 Acc: 0.65625
Train Iteration #4800:: 0.8280082941055298 Acc: 0.65625
Train Iteration #4850:: 0.8547472953796387 Acc: 0.8125
Train Iteration #4900:: 0.7543069124221802 Acc: 0.6875
Training:: Loss: 0.8027 Acc: 0.7001
Validation Iteration #550:: 0.5201026797294617 Acc: 0.75
Validation:: Loss: 0.6616 Acc: 0.6835
Epoch 13/49
----------
Train Iteration #4950:: 0.7504791021347046 Acc: 0.75
Train Iteration #5000:: 0.7786151170730591 Acc: 0.65625
Train Iteration #5050:: 0.9259835481643677 Acc: 0.71875
Train Iteration #5100:: 0.5891445875167847 Acc: 0.78125
Train Iteration #5150:: 0.9069033861160278 Acc: 0.5625
Train Iteration #5200:: 0.7511477470397949 Acc: 0.71875
Train Iteration #5250:: 0.7550992369651794 Acc: 0.8125
Train Iteration #5300:: 0.981065034866333 Acc: 0.71875
Training:: Loss: 0.8056 Acc: 0.6983
Validation Iteration #600:: 0.6411255598068237 Acc: 0.71875
Validation:: Loss: 0.7232 Acc: 0.6212
Epoch 14/49
----------
Train Iteration #5350:: 0.739712119102478 Acc: 0.8125
Train Iteration #5400:: 0.801436185836792 Acc: 0.75
Train Iteration #5450:: 0.6644205451011658 Acc: 0.75
Train Iteration #5500:: 0.923293948173523 Acc: 0.53125
Train Iteration #5550:: 0.7195850610733032 Acc: 0.65625
Train Iteration #5600:: 0.6499309539794922 Acc: 0.75
Train Iteration #5650:: 0.5751504898071289 Acc: 0.78125
Training:: Loss: 0.8163 Acc: 0.6946
Validation:: Loss: 0.6407 Acc: 0.6864
Epoch 15/49
----------
Train Iteration #5700:: 1.0529422760009766 Acc: 0.5625
Train Iteration #5750:: 0.8608803749084473 Acc: 0.71875
Train Iteration #5800:: 0.6848024129867554 Acc: 0.8125
Train Iteration #5850:: 0.7167483568191528 Acc: 0.71875
Train Iteration #5900:: 1.029433012008667 Acc: 0.71875
Train Iteration #5950:: 1.1888554096221924 Acc: 0.46875
Train Iteration #6000:: 0.48124194145202637 Acc: 0.875
Train Iteration #6050:: 0.5063919425010681 Acc: 0.8125
Training:: Loss: 0.8002 Acc: 0.7036
Validation Iteration #650:: 1.2036631107330322 Acc: 0.34375
Validation:: Loss: 0.9197 Acc: 0.5159
Epoch 16/49
----------
Train Iteration #6100:: 0.7719975113868713 Acc: 0.75
Train Iteration #6150:: 0.6353429555892944 Acc: 0.71875
Train Iteration #6200:: 0.9142808318138123 Acc: 0.6875
Train Iteration #6250:: 0.7605346441268921 Acc: 0.8125
Train Iteration #6300:: 0.5313863158226013 Acc: 0.8125
Train Iteration #6350:: 0.5753065943717957 Acc: 0.78125
Train Iteration #6400:: 0.5915433168411255 Acc: 0.75
Train Iteration #6450:: 0.6348741054534912 Acc: 0.75
Training:: Loss: 0.8044 Acc: 0.6996
Validation Iteration #700:: 0.5497238039970398 Acc: 0.71875
Validation:: Loss: 0.6506 Acc: 0.6827
Epoch 17/49
----------
Train Iteration #6500:: 1.0560801029205322 Acc: 0.5625
Train Iteration #6550:: 0.7629550695419312 Acc: 0.71875
Train Iteration #6600:: 0.9501267075538635 Acc: 0.59375
Train Iteration #6650:: 0.8302863836288452 Acc: 0.625
Train Iteration #6700:: 0.6607409119606018 Acc: 0.8125
Train Iteration #6750:: 1.025923252105713 Acc: 0.5625
Train Iteration #6800:: 0.9720004796981812 Acc: 0.46875
Training:: Loss: 0.8172 Acc: 0.6948
Validation Iteration #750:: 0.6121244430541992 Acc: 0.6875
Validation:: Loss: 0.6512 Acc: 0.6768
Epoch 18/49
----------
Train Iteration #6850:: 0.7080820798873901 Acc: 0.875
Train Iteration #6900:: 0.7480138540267944 Acc: 0.78125
Train Iteration #6950:: 0.8307845592498779 Acc: 0.65625
Train Iteration #7000:: 0.7481357455253601 Acc: 0.625
Train Iteration #7050:: 0.8963892459869385 Acc: 0.6875
Train Iteration #7100:: 0.7483079433441162 Acc: 0.78125
Train Iteration #7150:: 0.7422490119934082 Acc: 0.71875
Train Iteration #7200:: 0.7948520183563232 Acc: 0.71875
Training:: Loss: 0.8110 Acc: 0.6966
Validation Iteration #800:: 0.7008016109466553 Acc: 0.6875
Validation:: Loss: 0.6212 Acc: 0.7116
Epoch 19/49
----------
Train Iteration #7250:: 0.7036598920822144 Acc: 0.71875
Train Iteration #7300:: 0.8550885915756226 Acc: 0.65625
Train Iteration #7350:: 0.866077184677124 Acc: 0.65625
Train Iteration #7400:: 0.6649026870727539 Acc: 0.65625
Train Iteration #7450:: 0.6836679577827454 Acc: 0.8125
Train Iteration #7500:: 0.7341294884681702 Acc: 0.71875
Train Iteration #7550:: 0.9088598489761353 Acc: 0.59375
Training:: Loss: 0.8123 Acc: 0.6922
Validation Iteration #850:: 0.7937787771224976 Acc: 0.625
Validation:: Loss: 0.8762 Acc: 0.5374
Epoch 20/49
----------
Train Iteration #7600:: 1.1236640214920044 Acc: 0.5625
Train Iteration #7650:: 0.5680321455001831 Acc: 0.78125
Train Iteration #7700:: 0.7797456383705139 Acc: 0.84375
Train Iteration #7750:: 0.6195482015609741 Acc: 0.75
Train Iteration #7800:: 0.9755278825759888 Acc: 0.5625
Train Iteration #7850:: 0.780997633934021 Acc: 0.6875
Train Iteration #7900:: 0.5260781049728394 Acc: 0.84375
Train Iteration #7950:: 0.8799545168876648 Acc: 0.5625
Training:: Loss: 0.7990 Acc: 0.7022
Validation Iteration #900:: 0.6180357933044434 Acc: 0.65625
Validation:: Loss: 0.6556 Acc: 0.6768
Epoch 21/49
----------
Train Iteration #8000:: 1.0510494709014893 Acc: 0.6875
Train Iteration #8050:: 1.1092277765274048 Acc: 0.5
Train Iteration #8100:: 1.0649921894073486 Acc: 0.53125
Train Iteration #8150:: 0.8016921281814575 Acc: 0.6875
Train Iteration #8200:: 0.7324938178062439 Acc: 0.75
Train Iteration #8250:: 0.9515047669410706 Acc: 0.65625
Train Iteration #8300:: 0.8261761665344238 Acc: 0.59375
Train Iteration #8350:: 0.7125855684280396 Acc: 0.71875
Training:: Loss: 0.8071 Acc: 0.6964
Validation:: Loss: 0.6760 Acc: 0.6568
Epoch 22/49
----------
Train Iteration #8400:: 1.4117413759231567 Acc: 0.65625
Train Iteration #8450:: 0.9506763219833374 Acc: 0.59375
Train Iteration #8500:: 0.8251712322235107 Acc: 0.71875
Train Iteration #8550:: 0.8073732852935791 Acc: 0.59375
Train Iteration #8600:: 0.82749342918396 Acc: 0.625
Train Iteration #8650:: 0.7433664798736572 Acc: 0.78125
Train Iteration #8700:: 0.8967285752296448 Acc: 0.59375
Training:: Loss: 0.8113 Acc: 0.6999
Validation Iteration #950:: 0.8550411462783813 Acc: 0.53125
Validation:: Loss: 0.7214 Acc: 0.6160
Epoch 23/49
----------
Train Iteration #8750:: 1.0819048881530762 Acc: 0.71875
Train Iteration #8800:: 0.6478078961372375 Acc: 0.75
Train Iteration #8850:: 0.9267237186431885 Acc: 0.59375
Train Iteration #8900:: 0.766236424446106 Acc: 0.84375
Train Iteration #8950:: 0.7943952083587646 Acc: 0.6875
Train Iteration #9000:: 1.086767315864563 Acc: 0.53125
Train Iteration #9050:: 0.8726382851600647 Acc: 0.6875
Train Iteration #9100:: 0.8443474173545837 Acc: 0.6875
Training:: Loss: 0.8153 Acc: 0.6950
Validation Iteration #1000:: 0.8157460689544678 Acc: 0.46875
Validation:: Loss: 0.7425 Acc: 0.5997
Epoch 24/49
----------
Train Iteration #9150:: 0.7170819640159607 Acc: 0.8125
Train Iteration #9200:: 1.0031039714813232 Acc: 0.53125
Train Iteration #9250:: 1.1564654111862183 Acc: 0.53125
Train Iteration #9300:: 0.8630073070526123 Acc: 0.71875
Train Iteration #9350:: 0.6379289627075195 Acc: 0.8125
Train Iteration #9400:: 0.8209201693534851 Acc: 0.75
Train Iteration #9450:: 0.7819477319717407 Acc: 0.625
Training:: Loss: 0.8146 Acc: 0.6989
Validation Iteration #1050:: 0.8476670980453491 Acc: 0.5
Validation:: Loss: 0.7086 Acc: 0.6271
Epoch 25/49
----------
Train Iteration #9500:: 1.1342250108718872 Acc: 0.5625
Train Iteration #9550:: 0.622589111328125 Acc: 0.75
Train Iteration #9600:: 1.1333743333816528 Acc: 0.59375
Train Iteration #9650:: 0.6024535894393921 Acc: 0.6875
Train Iteration #9700:: 0.7562089562416077 Acc: 0.78125
Train Iteration #9750:: 0.8366825580596924 Acc: 0.75
Train Iteration #9800:: 0.6798907518386841 Acc: 0.78125
Train Iteration #9850:: 0.8055508136749268 Acc: 0.75
Training:: Loss: 0.8109 Acc: 0.6978
Validation Iteration #1100:: 0.6643369197845459 Acc: 0.75
Validation:: Loss: 0.6744 Acc: 0.6546
Epoch 26/49
----------
Train Iteration #9900:: 0.6884629130363464 Acc: 0.75
Train Iteration #9950:: 0.7221859693527222 Acc: 0.71875
Train Iteration #10000:: 0.6618077754974365 Acc: 0.8125
Train Iteration #10050:: 0.8246743679046631 Acc: 0.8125
Train Iteration #10100:: 0.7501033544540405 Acc: 0.71875
Train Iteration #10150:: 1.0432146787643433 Acc: 0.4375
Train Iteration #10200:: 0.7663205862045288 Acc: 0.6875
Train Iteration #10250:: 0.8223884105682373 Acc: 0.5625
Training:: Loss: 0.8133 Acc: 0.6966
Validation Iteration #1150:: 0.7269156575202942 Acc: 0.625
Validation:: Loss: 0.6604 Acc: 0.6731
Epoch 27/49
----------
Train Iteration #10300:: 0.8912434577941895 Acc: 0.65625
Train Iteration #10350:: 0.9466370940208435 Acc: 0.65625
Train Iteration #10400:: 0.9360857605934143 Acc: 0.65625
Train Iteration #10450:: 0.6143300533294678 Acc: 0.78125
Train Iteration #10500:: 0.7955367565155029 Acc: 0.625
Train Iteration #10550:: 0.7563788890838623 Acc: 0.6875
Train Iteration #10600:: 0.8771605491638184 Acc: 0.5625
Training:: Loss: 0.7947 Acc: 0.7037
Validation Iteration #1200:: 0.6259715557098389 Acc: 0.75
Validation:: Loss: 0.5622 Acc: 0.7895
Epoch 28/49
----------
Train Iteration #10650:: 0.658318281173706 Acc: 0.65625
Train Iteration #10700:: 0.8151520490646362 Acc: 0.6875
Train Iteration #10750:: 0.9095820188522339 Acc: 0.65625
Train Iteration #10800:: 0.8613252639770508 Acc: 0.6875
Train Iteration #10850:: 0.8420411944389343 Acc: 0.65625
Train Iteration #10900:: 0.7429914474487305 Acc: 0.75
Train Iteration #10950:: 0.8002282381057739 Acc: 0.5625
Train Iteration #11000:: 0.6057165861129761 Acc: 0.8125
Training:: Loss: 0.8183 Acc: 0.6930
Validation:: Loss: 0.6322 Acc: 0.6946
Epoch 29/49
----------
Train Iteration #11050:: 1.0672911405563354 Acc: 0.78125
Train Iteration #11100:: 1.0163064002990723 Acc: 0.5
Train Iteration #11150:: 0.6083446741104126 Acc: 0.71875
Train Iteration #11200:: 1.0302609205245972 Acc: 0.6875
Train Iteration #11250:: 0.7463639378547668 Acc: 0.75
Train Iteration #11300:: 0.7324193716049194 Acc: 0.84375
Train Iteration #11350:: 1.078523874282837 Acc: 0.59375
Training:: Loss: 0.8199 Acc: 0.6971
Validation Iteration #1250:: 0.6189456582069397 Acc: 0.71875
Validation:: Loss: 0.6836 Acc: 0.6494
Epoch 30/49
----------
Train Iteration #11400:: 1.36055326461792 Acc: 0.40625
Train Iteration #11450:: 0.5395473837852478 Acc: 0.78125
Train Iteration #11500:: 0.5329611897468567 Acc: 0.84375
Train Iteration #11550:: 1.1340043544769287 Acc: 0.6875
Train Iteration #11600:: 0.763815701007843 Acc: 0.6875
Train Iteration #11650:: 0.8508259057998657 Acc: 0.6875
Train Iteration #11700:: 0.8037129640579224 Acc: 0.65625
Train Iteration #11750:: 0.7329568266868591 Acc: 0.6875
Training:: Loss: 0.7959 Acc: 0.7036
Validation Iteration #1300:: 0.6636895537376404 Acc: 0.59375
Validation:: Loss: 0.6473 Acc: 0.6768
Epoch 31/49
----------
Train Iteration #11800:: 0.7573866844177246 Acc: 0.78125
Train Iteration #11850:: 0.8444465398788452 Acc: 0.78125
Train Iteration #11900:: 0.8317301273345947 Acc: 0.6875
Train Iteration #11950:: 0.8521382808685303 Acc: 0.625
Train Iteration #12000:: 1.0419158935546875 Acc: 0.6875
Train Iteration #12050:: 0.821245551109314 Acc: 0.71875
Train Iteration #12100:: 0.7981362342834473 Acc: 0.625
Train Iteration #12150:: 0.8359637260437012 Acc: 0.65625
Training:: Loss: 0.8113 Acc: 0.6980
Validation Iteration #1350:: 0.7995821237564087 Acc: 0.625
Validation:: Loss: 0.7515 Acc: 0.6116
Epoch 32/49
----------
Train Iteration #12200:: 0.63605797290802 Acc: 0.78125
Train Iteration #12250:: 0.9509587287902832 Acc: 0.65625
Train Iteration #12300:: 0.8951737880706787 Acc: 0.71875
Train Iteration #12350:: 0.9617614150047302 Acc: 0.59375
Train Iteration #12400:: 1.1659421920776367 Acc: 0.53125
Train Iteration #12450:: 0.5984947681427002 Acc: 0.78125
Train Iteration #12500:: 1.2286298274993896 Acc: 0.625
Training:: Loss: 0.8122 Acc: 0.7009
Validation Iteration #1400:: 0.49258142709732056 Acc: 0.71875
Validation:: Loss: 0.5955 Acc: 0.7413
Epoch 33/49
----------
Train Iteration #12550:: 0.621325671672821 Acc: 0.84375
Train Iteration #12600:: 0.8648726344108582 Acc: 0.65625
Train Iteration #12650:: 0.6701688170433044 Acc: 0.71875
Train Iteration #12700:: 0.6702914834022522 Acc: 0.78125
Train Iteration #12750:: 0.7675225734710693 Acc: 0.78125
Train Iteration #12800:: 0.8951002359390259 Acc: 0.59375
Train Iteration #12850:: 0.8365883827209473 Acc: 0.6875
Train Iteration #12900:: 1.1236467361450195 Acc: 0.625
Training:: Loss: 0.8153 Acc: 0.6988
Validation Iteration #1450:: 0.7716234922409058 Acc: 0.5
Validation:: Loss: 0.6087 Acc: 0.7146
Epoch 34/49
----------
Train Iteration #12950:: 0.530674934387207 Acc: 0.75
Train Iteration #13000:: 0.8392173051834106 Acc: 0.65625
Train Iteration #13050:: 0.7275911569595337 Acc: 0.75
Train Iteration #13100:: 0.7266286611557007 Acc: 0.78125
Train Iteration #13150:: 0.8661755919456482 Acc: 0.65625
Train Iteration #13200:: 0.5831414461135864 Acc: 0.8125
Train Iteration #13250:: 0.7125709056854248 Acc: 0.78125
Training:: Loss: 0.8061 Acc: 0.7018
Validation Iteration #1500:: 0.5831818580627441 Acc: 0.6875
Validation:: Loss: 0.6257 Acc: 0.6990
Epoch 35/49
----------
Train Iteration #13300:: 1.1466201543807983 Acc: 0.59375
Train Iteration #13350:: 0.6740562319755554 Acc: 0.8125
Train Iteration #13400:: 0.6167367100715637 Acc: 0.71875
Train Iteration #13450:: 1.0444653034210205 Acc: 0.59375
Train Iteration #13500:: 0.8203742504119873 Acc: 0.6875
Train Iteration #13550:: 0.8463026285171509 Acc: 0.71875
Train Iteration #13600:: 0.9227514266967773 Acc: 0.6875
Train Iteration #13650:: 0.5522885322570801 Acc: 0.84375
Training:: Loss: 0.8078 Acc: 0.6996
Validation:: Loss: 0.6719 Acc: 0.6649
Epoch 36/49
----------
Train Iteration #13700:: 0.8565686941146851 Acc: 0.65625
Train Iteration #13750:: 0.7239418029785156 Acc: 0.75
Train Iteration #13800:: 0.8727949857711792 Acc: 0.6875
Train Iteration #13850:: 0.6210496425628662 Acc: 0.84375
Train Iteration #13900:: 0.9234755635261536 Acc: 0.65625
Train Iteration #13950:: 0.8184999227523804 Acc: 0.71875
Train Iteration #14000:: 0.8737388849258423 Acc: 0.625
Train Iteration #14050:: 0.73191899061203 Acc: 0.84375
Training:: Loss: 0.8089 Acc: 0.6999
Validation Iteration #1550:: 0.7834937572479248 Acc: 0.59375
Validation:: Loss: 0.7718 Acc: 0.5901
Epoch 37/49
----------
Train Iteration #14100:: 0.7879416942596436 Acc: 0.75
Train Iteration #14150:: 0.7839912176132202 Acc: 0.6875
Train Iteration #14200:: 0.6775875091552734 Acc: 0.78125
Train Iteration #14250:: 0.9570102095603943 Acc: 0.625
Train Iteration #14300:: 0.7183451652526855 Acc: 0.71875
Train Iteration #14350:: 0.8738409876823425 Acc: 0.6875
Train Iteration #14400:: 0.618476390838623 Acc: 0.84375
Training:: Loss: 0.8125 Acc: 0.6933
Validation Iteration #1600:: 0.6608998775482178 Acc: 0.625
Validation:: Loss: 0.6771 Acc: 0.6397
Epoch 38/49
----------
Train Iteration #14450:: 0.7248011827468872 Acc: 0.78125
Train Iteration #14500:: 0.8775481581687927 Acc: 0.6875
Train Iteration #14550:: 0.7435705661773682 Acc: 0.75
Train Iteration #14600:: 0.6993579268455505 Acc: 0.6875
Train Iteration #14650:: 0.7124363780021667 Acc: 0.84375
Train Iteration #14700:: 0.9417010545730591 Acc: 0.625
Train Iteration #14750:: 0.4939161539077759 Acc: 0.75
Train Iteration #14800:: 1.3005781173706055 Acc: 0.71875
Training:: Loss: 0.7977 Acc: 0.7022
Validation Iteration #1650:: 0.5035414099693298 Acc: 0.84375
Validation:: Loss: 0.6121 Acc: 0.7161
Epoch 39/49
----------
Train Iteration #14850:: 0.6705248355865479 Acc: 0.75
Train Iteration #14900:: 0.9506088495254517 Acc: 0.5
Train Iteration #14950:: 0.812896192073822 Acc: 0.65625
Train Iteration #15000:: 0.746838390827179 Acc: 0.75
Train Iteration #15050:: 0.7669535875320435 Acc: 0.6875
Train Iteration #15100:: 0.7201231122016907 Acc: 0.75
Train Iteration #15150:: 0.856056272983551 Acc: 0.5625
Training:: Loss: 0.8038 Acc: 0.6970
Validation Iteration #1700:: 0.5665727853775024 Acc: 0.71875
Validation:: Loss: 0.6399 Acc: 0.6864
Epoch 40/49
----------
Train Iteration #15200:: 1.2571697235107422 Acc: 0.46875
Train Iteration #15250:: 0.6979920864105225 Acc: 0.78125
Train Iteration #15300:: 1.1353975534439087 Acc: 0.5
Train Iteration #15350:: 0.8658677339553833 Acc: 0.65625
Train Iteration #15400:: 0.9565153121948242 Acc: 0.65625
Train Iteration #15450:: 0.7666770219802856 Acc: 0.625
Train Iteration #15500:: 0.745764970779419 Acc: 0.71875
Train Iteration #15550:: 0.8039605617523193 Acc: 0.625
Training:: Loss: 0.8101 Acc: 0.6966
Validation Iteration #1750:: 0.6609455347061157 Acc: 0.59375
Validation:: Loss: 0.5805 Acc: 0.7546
Epoch 41/49
----------
Train Iteration #15600:: 0.8234130144119263 Acc: 0.625
Train Iteration #15650:: 0.5801172852516174 Acc: 0.8125
Train Iteration #15700:: 0.8282463550567627 Acc: 0.65625
Train Iteration #15750:: 0.6465561389923096 Acc: 0.65625
Train Iteration #15800:: 0.9058225154876709 Acc: 0.625
Train Iteration #15850:: 0.8406585454940796 Acc: 0.625
Train Iteration #15900:: 0.629644513130188 Acc: 0.8125
Train Iteration #15950:: 0.8802018165588379 Acc: 0.5
Training:: Loss: 0.8189 Acc: 0.6938
Validation Iteration #1800:: 0.8161592483520508 Acc: 0.46875
Validation:: Loss: 0.7015 Acc: 0.6390
Epoch 42/49
----------
Train Iteration #16000:: 0.8324865698814392 Acc: 0.75
Train Iteration #16050:: 0.8101036548614502 Acc: 0.6875
Train Iteration #16100:: 0.9410527944564819 Acc: 0.75
Train Iteration #16150:: 0.9489653706550598 Acc: 0.78125
Train Iteration #16200:: 0.7864258289337158 Acc: 0.65625
Train Iteration #16250:: 0.5523355007171631 Acc: 0.875
Train Iteration #16300:: 0.7930606603622437 Acc: 0.71875
Training:: Loss: 0.7984 Acc: 0.7053
Validation:: Loss: 0.6846 Acc: 0.6546
Epoch 43/49
----------
Train Iteration #16350:: 0.9036755561828613 Acc: 0.78125
Train Iteration #16400:: 0.5246387720108032 Acc: 0.875
Train Iteration #16450:: 0.5413336157798767 Acc: 0.8125
Train Iteration #16500:: 0.6976436376571655 Acc: 0.71875
Train Iteration #16550:: 0.8358991742134094 Acc: 0.75
Train Iteration #16600:: 0.8057551383972168 Acc: 0.65625
Train Iteration #16650:: 0.6617170572280884 Acc: 0.71875
Train Iteration #16700:: 0.5252462029457092 Acc: 0.6875
Training:: Loss: 0.8034 Acc: 0.6990
Validation Iteration #1850:: 0.9062355756759644 Acc: 0.5
Validation:: Loss: 0.8970 Acc: 0.5300
Epoch 44/49
----------
Train Iteration #16750:: 0.8533692359924316 Acc: 0.5625
Train Iteration #16800:: 0.6568595170974731 Acc: 0.71875
Train Iteration #16850:: 0.7916171550750732 Acc: 0.75
Train Iteration #16900:: 1.1182737350463867 Acc: 0.78125
Train Iteration #16950:: 0.8744608759880066 Acc: 0.59375
Train Iteration #17000:: 0.8774266242980957 Acc: 0.8125
Train Iteration #17050:: 1.251628041267395 Acc: 0.5
Training:: Loss: 0.8112 Acc: 0.6983
Validation Iteration #1900:: 0.7489396333694458 Acc: 0.625
Validation:: Loss: 0.6425 Acc: 0.6842
Epoch 45/49
----------
Train Iteration #17100:: 1.2419939041137695 Acc: 0.46875
Train Iteration #17150:: 0.8111205101013184 Acc: 0.625
Train Iteration #17200:: 0.8343117237091064 Acc: 0.78125
Train Iteration #17250:: 0.6360944509506226 Acc: 0.8125
Train Iteration #17300:: 1.029052495956421 Acc: 0.625
Train Iteration #17350:: 0.6597479581832886 Acc: 0.84375
Train Iteration #17400:: 0.822938859462738 Acc: 0.71875
Train Iteration #17450:: 0.9996768236160278 Acc: 0.5
Training:: Loss: 0.7952 Acc: 0.7032
Validation Iteration #1950:: 0.8917597532272339 Acc: 0.53125
Validation:: Loss: 0.8884 Acc: 0.5626
Epoch 46/49
----------
Train Iteration #17500:: 0.9115442037582397 Acc: 0.625
Train Iteration #17550:: 0.6451209187507629 Acc: 0.8125
Train Iteration #17600:: 0.8421409726142883 Acc: 0.6875
Train Iteration #17650:: 0.6803438663482666 Acc: 0.75
Train Iteration #17700:: 0.6157528162002563 Acc: 0.78125
Train Iteration #17750:: 0.7605173587799072 Acc: 0.75
Train Iteration #17800:: 0.7516422867774963 Acc: 0.71875
Train Iteration #17850:: 0.6461852788925171 Acc: 0.71875
Training:: Loss: 0.8122 Acc: 0.6988
Validation Iteration #2000:: 0.6799059510231018 Acc: 0.65625
Validation:: Loss: 0.8136 Acc: 0.5693
Epoch 47/49
----------
Train Iteration #17900:: 0.8888533115386963 Acc: 0.71875
Train Iteration #17950:: 0.8342132568359375 Acc: 0.65625
Train Iteration #18000:: 0.9425755739212036 Acc: 0.625
Train Iteration #18050:: 1.1321732997894287 Acc: 0.5625
Train Iteration #18100:: 0.8011579513549805 Acc: 0.6875
Train Iteration #18150:: 0.5924093723297119 Acc: 0.75
Train Iteration #18200:: 0.890526294708252 Acc: 0.625
Training:: Loss: 0.8079 Acc: 0.6941
Validation Iteration #2050:: 0.6254016757011414 Acc: 0.71875
Validation:: Loss: 0.7133 Acc: 0.6316
Epoch 48/49
----------
Train Iteration #18250:: 0.8095669746398926 Acc: 0.6875
Train Iteration #18300:: 0.6906663775444031 Acc: 0.71875
Train Iteration #18350:: 0.8661159873008728 Acc: 0.75
Train Iteration #18400:: 0.7374045848846436 Acc: 0.6875
Train Iteration #18450:: 0.9166947603225708 Acc: 0.625
Train Iteration #18500:: 0.7519323825836182 Acc: 0.71875
Train Iteration #18550:: 0.4869047701358795 Acc: 0.84375
Train Iteration #18600:: 0.7675812244415283 Acc: 0.75
Training:: Loss: 0.8080 Acc: 0.7036
Validation Iteration #2100:: 0.6951647996902466 Acc: 0.59375
Validation:: Loss: 0.6888 Acc: 0.6331
Epoch 49/49
----------
Train Iteration #18650:: 0.8626788854598999 Acc: 0.5625
Train Iteration #18700:: 0.6205401420593262 Acc: 0.78125
Train Iteration #18750:: 0.5470809936523438 Acc: 0.875
Train Iteration #18800:: 0.7579636573791504 Acc: 0.6875
Train Iteration #18850:: 0.8270341157913208 Acc: 0.6875
Train Iteration #18900:: 0.7146440148353577 Acc: 0.6875
Train Iteration #18950:: 0.7295405864715576 Acc: 0.71875
Training:: Loss: 0.7916 Acc: 0.7027
Validation:: Loss: 0.5475 Acc: 0.8258
Best Validation Acc: 0.825797
End time:2:20:29.975719
Program Complete
Average Train Loss:0.8126109149785247
Average Validation Loss:0.7191441554131554
Average Train Accuracy:0.6940532081377151
Average Validation Accuracy:0.6372868791697553
