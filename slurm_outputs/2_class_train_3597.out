cuda
Program started
Epoch 0/49
----------
Train Iteration #0:: 1.1061402559280396 Acc: 0.5625
Train Iteration #50:: 0.8723275065422058 Acc: 0.59375
Train Iteration #100:: 0.9857271909713745 Acc: 0.71875
Train Iteration #150:: 0.787503719329834 Acc: 0.625
Train Iteration #200:: 0.8121440410614014 Acc: 0.625
Train Iteration #250:: 0.5902457237243652 Acc: 0.6875
Train Iteration #300:: 0.595737636089325 Acc: 0.71875
Training:: Loss: 0.8204 Acc: 0.6338
Validation Iteration #0:: 0.8136104345321655 Acc: 0.5625
Validation Iteration #50:: 0.6990261673927307 Acc: 0.625
Validation:: Loss: 0.8076 Acc: 0.5451
Epoch 1/49
----------
Train Iteration #350:: 0.7381631135940552 Acc: 0.75
Train Iteration #400:: 0.531303882598877 Acc: 0.8125
Train Iteration #450:: 0.870405912399292 Acc: 0.59375
Train Iteration #500:: 0.7063593864440918 Acc: 0.6875
Train Iteration #550:: 0.5931419134140015 Acc: 0.71875
Train Iteration #600:: 0.5571819543838501 Acc: 0.71875
Training:: Loss: 0.6502 Acc: 0.7525
Validation Iteration #100:: 0.6304965019226074 Acc: 0.84375
Validation Iteration #150:: 0.9052963256835938 Acc: 0.4375
Validation:: Loss: 0.6847 Acc: 0.6929
Epoch 2/49
----------
Train Iteration #650:: 0.6617896556854248 Acc: 0.84375
Train Iteration #700:: 0.7201696634292603 Acc: 0.6875
Train Iteration #750:: 0.7429097890853882 Acc: 0.78125
Train Iteration #800:: 0.6478942632675171 Acc: 0.71875
Train Iteration #850:: 0.5461071729660034 Acc: 0.78125
Train Iteration #900:: 0.562511146068573 Acc: 0.65625
Train Iteration #950:: 0.48930084705352783 Acc: 0.75
Training:: Loss: 0.6229 Acc: 0.7730
Validation Iteration #200:: 0.6409139633178711 Acc: 0.71875
Validation:: Loss: 0.6272 Acc: 0.7468
Epoch 3/49
----------
Train Iteration #1000:: 0.3945627212524414 Acc: 0.90625
Train Iteration #1050:: 0.5497620701789856 Acc: 0.75
Train Iteration #1100:: 0.4521523118019104 Acc: 0.90625
Train Iteration #1150:: 0.45746517181396484 Acc: 0.84375
Train Iteration #1200:: 0.4007684290409088 Acc: 0.84375
Train Iteration #1250:: 0.6049730181694031 Acc: 0.6875
Training:: Loss: 0.6031 Acc: 0.7857
Validation Iteration #250:: 0.7268260717391968 Acc: 0.625
Validation Iteration #300:: 0.49032527208328247 Acc: 0.78125
Validation:: Loss: 0.6506 Acc: 0.7082
Epoch 4/49
----------
Train Iteration #1300:: 0.5264365077018738 Acc: 0.8125
Train Iteration #1350:: 0.9907299280166626 Acc: 0.625
Train Iteration #1400:: 0.5782458186149597 Acc: 0.71875
Train Iteration #1450:: 0.6799527406692505 Acc: 0.78125
Train Iteration #1500:: 0.687123715877533 Acc: 0.75
Train Iteration #1550:: 0.5311993360519409 Acc: 0.71875
Train Iteration #1600:: 0.7530385851860046 Acc: 0.78125
Training:: Loss: 0.5939 Acc: 0.7917
Validation Iteration #350:: 0.5711823105812073 Acc: 0.75
Validation Iteration #400:: 0.6041916012763977 Acc: 0.71875
Validation:: Loss: 0.5586 Acc: 0.8002
Epoch 5/49
----------
Train Iteration #1650:: 0.5235198140144348 Acc: 0.78125
Train Iteration #1700:: 0.5738481283187866 Acc: 0.75
Train Iteration #1750:: 0.5709717869758606 Acc: 0.8125
Train Iteration #1800:: 0.6565240621566772 Acc: 0.6875
Train Iteration #1850:: 0.5468564033508301 Acc: 0.84375
Train Iteration #1900:: 0.34038758277893066 Acc: 0.84375
Training:: Loss: 0.5848 Acc: 0.7896
Validation Iteration #450:: 0.5288294553756714 Acc: 0.75
Validation:: Loss: 0.5654 Acc: 0.7874
Epoch 6/49
----------
Train Iteration #1950:: 0.5126639604568481 Acc: 0.8125
Train Iteration #2000:: 0.5578396320343018 Acc: 0.78125
Train Iteration #2050:: 1.0043933391571045 Acc: 0.8125
Train Iteration #2100:: 0.5849886536598206 Acc: 0.75
Train Iteration #2150:: 0.6920275092124939 Acc: 0.75
Train Iteration #2200:: 0.5857239961624146 Acc: 0.78125
Training:: Loss: 0.5679 Acc: 0.8026
Validation Iteration #500:: 0.6647892594337463 Acc: 0.78125
Validation Iteration #550:: 0.5378957390785217 Acc: 0.625
Validation:: Loss: 0.5655 Acc: 0.7792
Epoch 7/49
----------
Train Iteration #2250:: 0.727972149848938 Acc: 0.59375
Train Iteration #2300:: 0.47641509771347046 Acc: 0.90625
Train Iteration #2350:: 0.5029208660125732 Acc: 0.75
Train Iteration #2400:: 0.6339126229286194 Acc: 0.8125
Train Iteration #2450:: 0.5851950645446777 Acc: 0.6875
Train Iteration #2500:: 0.6289056539535522 Acc: 0.90625
Train Iteration #2550:: 0.8930597901344299 Acc: 0.5625
Training:: Loss: 0.5745 Acc: 0.7980
Validation Iteration #600:: 0.6060476303100586 Acc: 0.71875
Validation:: Loss: 0.5455 Acc: 0.7893
Epoch 8/49
----------
Train Iteration #2600:: 0.5785340070724487 Acc: 0.875
Train Iteration #2650:: 0.4751291871070862 Acc: 0.75
Train Iteration #2700:: 0.6493946313858032 Acc: 0.75
Train Iteration #2750:: 0.8462617993354797 Acc: 0.71875
Train Iteration #2800:: 0.4894876778125763 Acc: 0.875
Train Iteration #2850:: 0.5649219155311584 Acc: 0.875
Training:: Loss: 0.5738 Acc: 0.8029
Validation Iteration #650:: 0.6102654933929443 Acc: 0.8125
Validation Iteration #700:: 0.5734716057777405 Acc: 0.84375
Validation:: Loss: 0.5331 Acc: 0.8053
Epoch 9/49
----------
Train Iteration #2900:: 0.3947206139564514 Acc: 0.875
Train Iteration #2950:: 0.7021605968475342 Acc: 0.84375
Train Iteration #3000:: 0.6719615459442139 Acc: 0.75
Train Iteration #3050:: 0.8630867004394531 Acc: 0.6875
Train Iteration #3100:: 0.6019931435585022 Acc: 0.875
Train Iteration #3150:: 0.4947982430458069 Acc: 0.8125
Train Iteration #3200:: 0.49238333106040955 Acc: 0.8125
Training:: Loss: 0.5767 Acc: 0.8012
Validation Iteration #750:: 0.5290637016296387 Acc: 0.84375
Validation Iteration #800:: 0.5384591817855835 Acc: 0.9375
Validation:: Loss: 0.5128 Acc: 0.8455
Epoch 10/49
----------
Train Iteration #3250:: 0.3698766529560089 Acc: 0.875
Train Iteration #3300:: 0.5688073039054871 Acc: 0.78125
Train Iteration #3350:: 0.5900252461433411 Acc: 0.875
Train Iteration #3400:: 0.6499380469322205 Acc: 0.71875
Train Iteration #3450:: 0.6171212196350098 Acc: 0.78125
Train Iteration #3500:: 0.6111553311347961 Acc: 0.84375
Training:: Loss: 0.5817 Acc: 0.7996
Validation Iteration #850:: 0.41041433811187744 Acc: 0.875
Validation:: Loss: 0.5049 Acc: 0.8400
Epoch 11/49
----------
Train Iteration #3550:: 0.5624898076057434 Acc: 0.8125
Train Iteration #3600:: 0.4092177152633667 Acc: 0.78125
Train Iteration #3650:: 0.43113774061203003 Acc: 0.875
Train Iteration #3700:: 0.6035826802253723 Acc: 0.71875
Train Iteration #3750:: 0.4165065586566925 Acc: 0.84375
Train Iteration #3800:: 0.49893397092819214 Acc: 0.78125
Train Iteration #3850:: 0.5339444875717163 Acc: 0.84375
Training:: Loss: 0.5467 Acc: 0.8118
Validation Iteration #900:: 0.6914570331573486 Acc: 0.75
Validation Iteration #950:: 0.595340371131897 Acc: 0.75
Validation:: Loss: 0.6192 Acc: 0.7238
Epoch 12/49
----------
Train Iteration #3900:: 0.8408323526382446 Acc: 0.78125
Train Iteration #3950:: 0.557200014591217 Acc: 0.84375
Train Iteration #4000:: 0.5670811533927917 Acc: 0.71875
Train Iteration #4050:: 0.4052790105342865 Acc: 0.875
Train Iteration #4100:: 0.31751659512519836 Acc: 0.90625
Train Iteration #4150:: 0.3900534212589264 Acc: 0.84375
Training:: Loss: 0.5443 Acc: 0.8164
Validation Iteration #1000:: 0.6005535125732422 Acc: 0.625
Validation Iteration #1050:: 0.5159056782722473 Acc: 0.78125
Validation:: Loss: 0.7266 Acc: 0.6516
Epoch 13/49
----------
Train Iteration #4200:: 0.35585498809814453 Acc: 0.84375
Train Iteration #4250:: 0.5491634607315063 Acc: 0.75
Train Iteration #4300:: 0.20984867215156555 Acc: 0.96875
Train Iteration #4350:: 0.782723605632782 Acc: 0.71875
Train Iteration #4400:: 0.5694199204444885 Acc: 0.75
Train Iteration #4450:: 0.672291100025177 Acc: 0.78125
Training:: Loss: 0.5644 Acc: 0.8093
Validation Iteration #1100:: 0.438889741897583 Acc: 0.875
Validation:: Loss: 0.5195 Acc: 0.8073
Epoch 14/49
----------
Train Iteration #4500:: 0.40929993987083435 Acc: 0.8125
Train Iteration #4550:: 0.392965704202652 Acc: 0.90625
Train Iteration #4600:: 0.31095290184020996 Acc: 0.9375
Train Iteration #4650:: 0.7383652925491333 Acc: 0.71875
Train Iteration #4700:: 0.6304867267608643 Acc: 0.90625
Train Iteration #4750:: 0.8147541284561157 Acc: 0.78125
Train Iteration #4800:: 0.6222472190856934 Acc: 0.8125
Training:: Loss: 0.5704 Acc: 0.7998
Validation Iteration #1150:: 0.377623587846756 Acc: 0.875
Validation Iteration #1200:: 0.43782761693000793 Acc: 0.84375
Validation:: Loss: 0.5251 Acc: 0.8037
Epoch 15/49
----------
Train Iteration #4850:: 0.6679104566574097 Acc: 0.75
Train Iteration #4900:: 0.5149953365325928 Acc: 0.8125
Train Iteration #4950:: 0.46000316739082336 Acc: 0.8125
Train Iteration #5000:: 0.5699796676635742 Acc: 0.84375
Train Iteration #5050:: 0.6888378262519836 Acc: 0.84375
Train Iteration #5100:: 0.4080568850040436 Acc: 0.9375
Training:: Loss: 0.5643 Acc: 0.8100
Validation Iteration #1250:: 0.5297713875770569 Acc: 0.8125
Validation:: Loss: 0.5174 Acc: 0.8037
Epoch 16/49
----------
Train Iteration #5150:: 0.6171255111694336 Acc: 0.71875
Train Iteration #5200:: 0.6163586974143982 Acc: 0.78125
Train Iteration #5250:: 0.4635029733181 Acc: 0.78125
Train Iteration #5300:: 0.6712020635604858 Acc: 0.90625
Train Iteration #5350:: 0.4342425763607025 Acc: 0.84375
Train Iteration #5400:: 0.5252355933189392 Acc: 0.78125
Train Iteration #5450:: 0.7392953634262085 Acc: 0.78125
Training:: Loss: 0.5515 Acc: 0.8151
Validation Iteration #1300:: 0.42131471633911133 Acc: 0.78125
Validation Iteration #1350:: 0.6049902439117432 Acc: 0.78125
Validation:: Loss: 0.5296 Acc: 0.7975
Epoch 17/49
----------
Train Iteration #5500:: 0.47530651092529297 Acc: 0.84375
Train Iteration #5550:: 0.34495243430137634 Acc: 0.875
Train Iteration #5600:: 0.4986056387424469 Acc: 0.8125
Train Iteration #5650:: 0.5607198476791382 Acc: 0.84375
Train Iteration #5700:: 0.481387734413147 Acc: 0.8125
Train Iteration #5750:: 0.3312091827392578 Acc: 0.90625
Training:: Loss: 0.5518 Acc: 0.8150
Validation Iteration #1400:: 0.4205927848815918 Acc: 0.9375
Validation Iteration #1450:: 0.35378164052963257 Acc: 0.90625
Validation:: Loss: 0.4888 Acc: 0.8513
Epoch 18/49
----------
Train Iteration #5800:: 0.4564303159713745 Acc: 0.84375
Train Iteration #5850:: 0.5090731382369995 Acc: 0.875
Train Iteration #5900:: 0.48014751076698303 Acc: 0.8125
Train Iteration #5950:: 0.7672696113586426 Acc: 0.71875
Train Iteration #6000:: 0.6028275489807129 Acc: 0.78125
Train Iteration #6050:: 0.8141118884086609 Acc: 0.84375
Training:: Loss: 0.5429 Acc: 0.8176
Validation Iteration #1500:: 0.6773959398269653 Acc: 0.6875
Validation:: Loss: 0.5612 Acc: 0.7702
Epoch 19/49
----------
Train Iteration #6100:: 0.7541295289993286 Acc: 0.6875
Train Iteration #6150:: 0.8988140821456909 Acc: 0.71875
Train Iteration #6200:: 0.3137524127960205 Acc: 0.875
Train Iteration #6250:: 0.7756460905075073 Acc: 0.71875
Train Iteration #6300:: 0.7801213264465332 Acc: 0.71875
Train Iteration #6350:: 0.4326571226119995 Acc: 0.78125
Train Iteration #6400:: 0.4351590871810913 Acc: 0.875
Training:: Loss: 0.5683 Acc: 0.8121
Validation Iteration #1550:: 0.389051616191864 Acc: 0.90625
Validation Iteration #1600:: 0.48411405086517334 Acc: 0.875
Validation:: Loss: 0.4822 Acc: 0.8506
Epoch 20/49
----------
Train Iteration #6450:: 0.6139026284217834 Acc: 0.78125
Train Iteration #6500:: 0.69827800989151 Acc: 0.8125
Train Iteration #6550:: 1.1485438346862793 Acc: 0.59375
Train Iteration #6600:: 0.9116295576095581 Acc: 0.8125
Train Iteration #6650:: 0.45446187257766724 Acc: 0.78125
Train Iteration #6700:: 0.7016239762306213 Acc: 0.65625
Training:: Loss: 0.5736 Acc: 0.8071
Validation Iteration #1650:: 0.3112335205078125 Acc: 0.9375
Validation Iteration #1700:: 0.16457371413707733 Acc: 1.0
Validation:: Loss: 0.4831 Acc: 0.8537
Epoch 21/49
----------
Train Iteration #6750:: 0.6078522205352783 Acc: 0.78125
Train Iteration #6800:: 0.4365421235561371 Acc: 0.875
Train Iteration #6850:: 0.7930132150650024 Acc: 0.8125
Train Iteration #6900:: 0.3994864523410797 Acc: 0.875
Train Iteration #6950:: 0.6789509654045105 Acc: 0.75
Train Iteration #7000:: 0.800761342048645 Acc: 0.625
Train Iteration #7050:: 0.6718469858169556 Acc: 0.6875
Training:: Loss: 0.5475 Acc: 0.8172
Validation Iteration #1750:: 0.3691222667694092 Acc: 0.875
Validation:: Loss: 0.5868 Acc: 0.7487
Epoch 22/49
----------
Train Iteration #7100:: 0.5524135231971741 Acc: 0.84375
Train Iteration #7150:: 0.46156221628189087 Acc: 0.84375
Train Iteration #7200:: 0.5172643065452576 Acc: 0.84375
Train Iteration #7250:: 0.5634623765945435 Acc: 0.84375
Train Iteration #7300:: 0.49982836842536926 Acc: 0.78125
Train Iteration #7350:: 0.558803379535675 Acc: 0.8125
Training:: Loss: 0.5712 Acc: 0.8132
Validation Iteration #1800:: 0.4063127040863037 Acc: 0.90625
Validation Iteration #1850:: 0.4062265157699585 Acc: 0.875
Validation:: Loss: 0.4838 Acc: 0.8435
Epoch 23/49
----------
Train Iteration #7400:: 0.6327734589576721 Acc: 0.875
Train Iteration #7450:: 0.5763261914253235 Acc: 0.84375
Train Iteration #7500:: 0.9935958981513977 Acc: 0.75
Train Iteration #7550:: 0.391321063041687 Acc: 0.9375
Train Iteration #7600:: 0.5455971956253052 Acc: 0.84375
Train Iteration #7650:: 0.8277255892753601 Acc: 0.6875
Train Iteration #7700:: 0.7281867265701294 Acc: 0.84375
Training:: Loss: 0.5689 Acc: 0.8111
Validation Iteration #1900:: 0.42457324266433716 Acc: 0.96875
Validation:: Loss: 0.4820 Acc: 0.8533
Epoch 24/49
----------
Train Iteration #7750:: 0.5362481474876404 Acc: 0.84375
Train Iteration #7800:: 0.29291847348213196 Acc: 0.9375
Train Iteration #7850:: 0.4137440323829651 Acc: 0.90625
Train Iteration #7900:: 0.2863937020301819 Acc: 0.9375
Train Iteration #7950:: 0.9192806482315063 Acc: 0.6875
Train Iteration #8000:: 0.36247268319129944 Acc: 0.875
Training:: Loss: 0.5687 Acc: 0.8096
Validation Iteration #1950:: 0.31663256883621216 Acc: 0.9375
Validation Iteration #2000:: 0.5040993094444275 Acc: 0.875
Validation:: Loss: 0.4850 Acc: 0.8584
Epoch 25/49
----------
Train Iteration #8050:: 0.4557666778564453 Acc: 0.78125
Train Iteration #8100:: 0.922012209892273 Acc: 0.8125
Train Iteration #8150:: 0.3954610824584961 Acc: 0.90625
Train Iteration #8200:: 0.28732040524482727 Acc: 0.84375
Train Iteration #8250:: 0.4418182075023651 Acc: 0.75
Train Iteration #8300:: 0.5935580134391785 Acc: 0.8125
Training:: Loss: 0.5518 Acc: 0.8101
Validation Iteration #2050:: 0.6527706384658813 Acc: 0.71875
Validation Iteration #2100:: 0.6394246816635132 Acc: 0.71875
Validation:: Loss: 0.5271 Acc: 0.7987
Epoch 26/49
----------
Train Iteration #8350:: 0.6490710377693176 Acc: 0.75
Train Iteration #8400:: 0.6445856094360352 Acc: 0.84375
Train Iteration #8450:: 0.6292001605033875 Acc: 0.78125
Train Iteration #8500:: 0.96181720495224 Acc: 0.5625
Train Iteration #8550:: 0.41152453422546387 Acc: 0.84375
Train Iteration #8600:: 0.5942808985710144 Acc: 0.75
Train Iteration #8650:: 0.7852834463119507 Acc: 0.78125
Training:: Loss: 0.5718 Acc: 0.8060
Validation Iteration #2150:: 0.5135847926139832 Acc: 0.8125
Validation:: Loss: 0.5024 Acc: 0.8174
Epoch 27/49
----------
Train Iteration #8700:: 0.6537522673606873 Acc: 0.75
Train Iteration #8750:: 0.4119355380535126 Acc: 0.875
Train Iteration #8800:: 0.5378422737121582 Acc: 0.8125
Train Iteration #8850:: 0.448906272649765 Acc: 0.84375
Train Iteration #8900:: 0.37407878041267395 Acc: 0.90625
Train Iteration #8950:: 0.3747212290763855 Acc: 0.875
Training:: Loss: 0.5516 Acc: 0.8171
Validation Iteration #2200:: 0.470325767993927 Acc: 0.84375
Validation Iteration #2250:: 0.6602555513381958 Acc: 0.65625
Validation:: Loss: 0.5919 Acc: 0.7433
Epoch 28/49
----------
Train Iteration #9000:: 0.6663613319396973 Acc: 0.78125
Train Iteration #9050:: 0.7642018795013428 Acc: 0.65625
Train Iteration #9100:: 0.6229313611984253 Acc: 0.78125
Train Iteration #9150:: 0.7735812664031982 Acc: 0.78125
Train Iteration #9200:: 0.733240008354187 Acc: 0.75
Train Iteration #9250:: 0.843949556350708 Acc: 0.75
Train Iteration #9300:: 0.4633311629295349 Acc: 0.75
Training:: Loss: 0.5352 Acc: 0.8205
Validation Iteration #2300:: 0.6758748292922974 Acc: 0.6875
Validation:: Loss: 0.5047 Acc: 0.8135
Epoch 29/49
----------
Train Iteration #9350:: 0.2661358118057251 Acc: 0.96875
Train Iteration #9400:: 0.48531821370124817 Acc: 0.90625
Train Iteration #9450:: 0.5914060473442078 Acc: 0.8125
Train Iteration #9500:: 0.8688555359840393 Acc: 0.8125
Train Iteration #9550:: 0.4771313965320587 Acc: 0.8125
Train Iteration #9600:: 0.6435728669166565 Acc: 0.59375
Training:: Loss: 0.5792 Acc: 0.8065
Validation Iteration #2350:: 0.27771303057670593 Acc: 0.84375
Validation Iteration #2400:: 0.5214930772781372 Acc: 0.8125
Validation:: Loss: 0.4831 Acc: 0.8451
Epoch 30/49
----------
Train Iteration #9650:: 0.316866397857666 Acc: 0.9375
Train Iteration #9700:: 0.5103879570960999 Acc: 0.84375
Train Iteration #9750:: 0.7443891167640686 Acc: 0.84375
Train Iteration #9800:: 0.5597828030586243 Acc: 0.78125
Train Iteration #9850:: 0.5279785990715027 Acc: 0.75
Train Iteration #9900:: 0.5683533549308777 Acc: 0.75
Train Iteration #9950:: 0.569213330745697 Acc: 0.75
Training:: Loss: 0.5631 Acc: 0.8115
Validation Iteration #2450:: 0.7066147923469543 Acc: 0.71875
Validation Iteration #2500:: 0.5625867247581482 Acc: 0.8125
Validation:: Loss: 0.5225 Acc: 0.7987
Epoch 31/49
----------
Train Iteration #10000:: 0.6482167840003967 Acc: 0.84375
Train Iteration #10050:: 0.7293308973312378 Acc: 0.8125
Train Iteration #10100:: 0.34243595600128174 Acc: 0.9375
Train Iteration #10150:: 0.6809873580932617 Acc: 0.71875
Train Iteration #10200:: 1.2382688522338867 Acc: 0.71875
Train Iteration #10250:: 0.8035828471183777 Acc: 0.6875
Training:: Loss: 0.6051 Acc: 0.7958
Validation Iteration #2550:: 0.4677720069885254 Acc: 0.84375
Validation:: Loss: 0.4955 Acc: 0.8197
Epoch 32/49
----------
Train Iteration #10300:: 0.7802975177764893 Acc: 0.6875
Train Iteration #10350:: 0.4842004179954529 Acc: 0.84375
Train Iteration #10400:: 0.44867900013923645 Acc: 0.84375
Train Iteration #10450:: 0.7750544548034668 Acc: 0.6875
Train Iteration #10500:: 0.4877479076385498 Acc: 0.8125
Train Iteration #10550:: 0.5796338319778442 Acc: 0.84375
Training:: Loss: 0.5694 Acc: 0.8133
Validation Iteration #2600:: 0.5397491455078125 Acc: 0.84375
Validation Iteration #2650:: 0.4303995668888092 Acc: 0.84375
Validation:: Loss: 0.4769 Acc: 0.8490
Epoch 33/49
----------
Train Iteration #10600:: 0.8839950561523438 Acc: 0.6875
Train Iteration #10650:: 0.33397209644317627 Acc: 0.9375
Train Iteration #10700:: 0.6660830974578857 Acc: 0.71875
Train Iteration #10750:: 0.41957756876945496 Acc: 0.8125
Train Iteration #10800:: 0.6439698934555054 Acc: 0.78125
Train Iteration #10850:: 0.3279034495353699 Acc: 0.90625
Train Iteration #10900:: 0.6468205451965332 Acc: 0.84375
Training:: Loss: 0.5667 Acc: 0.8061
Validation Iteration #2700:: 0.43349361419677734 Acc: 0.78125
Validation Iteration #2750:: 0.743829071521759 Acc: 0.6875
Validation:: Loss: 0.4966 Acc: 0.8186
Epoch 34/49
----------
Train Iteration #10950:: 0.5547077059745789 Acc: 0.84375
Train Iteration #11000:: 0.575682520866394 Acc: 0.78125
Train Iteration #11050:: 0.42614442110061646 Acc: 0.875
Train Iteration #11100:: 0.6680537462234497 Acc: 0.75
Train Iteration #11150:: 0.395729660987854 Acc: 0.84375
Train Iteration #11200:: 0.4081568419933319 Acc: 0.90625
Training:: Loss: 0.5589 Acc: 0.8077
Validation Iteration #2800:: 0.5000902414321899 Acc: 0.84375
Validation:: Loss: 0.5022 Acc: 0.8147
Epoch 35/49
----------
Train Iteration #11250:: 0.3809930384159088 Acc: 0.90625
Train Iteration #11300:: 0.791597843170166 Acc: 0.71875
Train Iteration #11350:: 0.8757965564727783 Acc: 0.875
Train Iteration #11400:: 0.5588344931602478 Acc: 0.84375
Train Iteration #11450:: 0.3985837697982788 Acc: 0.78125
Train Iteration #11500:: 0.5833052396774292 Acc: 0.78125
Train Iteration #11550:: 0.8630619049072266 Acc: 0.59375
Training:: Loss: 0.5969 Acc: 0.7958
Validation Iteration #2850:: 0.6238277554512024 Acc: 0.78125
Validation Iteration #2900:: 0.461753785610199 Acc: 0.8125
Validation:: Loss: 0.5037 Acc: 0.8119
Epoch 36/49
----------
Train Iteration #11600:: 0.5210294723510742 Acc: 0.84375
Train Iteration #11650:: 0.5385613441467285 Acc: 0.8125
Train Iteration #11700:: 0.5662949681282043 Acc: 0.8125
Train Iteration #11750:: 0.4638371467590332 Acc: 0.84375
Train Iteration #11800:: 0.5687376260757446 Acc: 0.75
Train Iteration #11850:: 0.6798272132873535 Acc: 0.6875
Training:: Loss: 0.5682 Acc: 0.8115
Validation Iteration #2950:: 0.5288533568382263 Acc: 0.78125
Validation:: Loss: 0.4773 Acc: 0.8373
Epoch 37/49
----------
Train Iteration #11900:: 0.39323896169662476 Acc: 0.90625
Train Iteration #11950:: 0.5564011335372925 Acc: 0.75
Train Iteration #12000:: 0.38659167289733887 Acc: 0.875
Train Iteration #12050:: 0.42657792568206787 Acc: 0.90625
Train Iteration #12100:: 0.47636744379997253 Acc: 0.84375
Train Iteration #12150:: 0.5439926385879517 Acc: 0.8125
Training:: Loss: 0.5750 Acc: 0.8063
Validation Iteration #3000:: 0.7654863595962524 Acc: 0.59375
Validation Iteration #3050:: 0.5765785574913025 Acc: 0.71875
Validation:: Loss: 0.5877 Acc: 0.7440
Epoch 38/49
----------
Train Iteration #12200:: 1.0422933101654053 Acc: 0.6875
Train Iteration #12250:: 0.5164509415626526 Acc: 0.8125
Train Iteration #12300:: 0.6084290742874146 Acc: 0.84375
Train Iteration #12350:: 0.5886482000350952 Acc: 0.78125
Train Iteration #12400:: 0.6631960868835449 Acc: 0.75
Train Iteration #12450:: 0.8426371216773987 Acc: 0.625
Train Iteration #12500:: 0.6596514582633972 Acc: 0.6875
Training:: Loss: 0.5552 Acc: 0.8101
Validation Iteration #3100:: 0.526304304599762 Acc: 0.8125
Validation Iteration #3150:: 0.4129340648651123 Acc: 0.875
Validation:: Loss: 0.4948 Acc: 0.8229
Epoch 39/49
----------
Train Iteration #12550:: 0.7633387446403503 Acc: 0.84375
Train Iteration #12600:: 0.45365744829177856 Acc: 0.84375
Train Iteration #12650:: 0.6548086404800415 Acc: 0.71875
Train Iteration #12700:: 0.5719320178031921 Acc: 0.8125
Train Iteration #12750:: 0.6286979913711548 Acc: 0.75
Train Iteration #12800:: 0.3555905222892761 Acc: 0.90625
Training:: Loss: 0.5600 Acc: 0.8129
Validation Iteration #3200:: 0.4443468451499939 Acc: 0.875
Validation:: Loss: 0.4931 Acc: 0.8264
Epoch 40/49
----------
Train Iteration #12850:: 0.6506985425949097 Acc: 0.84375
Train Iteration #12900:: 0.7229642271995544 Acc: 0.71875
Train Iteration #12950:: 0.7163606286048889 Acc: 0.65625
Train Iteration #13000:: 0.2693227529525757 Acc: 0.9375
Train Iteration #13050:: 0.38711073994636536 Acc: 0.8125
Train Iteration #13100:: 0.743972897529602 Acc: 0.625
Train Iteration #13150:: 0.460671991109848 Acc: 0.84375
Training:: Loss: 0.5578 Acc: 0.8136
Validation Iteration #3250:: 0.802472710609436 Acc: 0.625
Validation Iteration #3300:: 0.4349782466888428 Acc: 0.78125
Validation:: Loss: 0.6952 Acc: 0.6781
Epoch 41/49
----------
Train Iteration #13200:: 0.4207627773284912 Acc: 0.8125
Train Iteration #13250:: 0.46498942375183105 Acc: 0.84375
Train Iteration #13300:: 0.9174854755401611 Acc: 0.65625
Train Iteration #13350:: 0.5400916337966919 Acc: 0.875
Train Iteration #13400:: 0.4827169179916382 Acc: 0.9375
Train Iteration #13450:: 0.6100823879241943 Acc: 0.8125
Training:: Loss: 0.5659 Acc: 0.8106
Validation Iteration #3350:: 0.531186580657959 Acc: 0.84375
Validation Iteration #3400:: 0.5050523281097412 Acc: 0.875
Validation:: Loss: 0.4748 Acc: 0.8552
Epoch 42/49
----------
Train Iteration #13500:: 0.41255369782447815 Acc: 0.84375
Train Iteration #13550:: 0.599510908126831 Acc: 0.9375
Train Iteration #13600:: 0.4472448229789734 Acc: 0.8125
Train Iteration #13650:: 0.43430277705192566 Acc: 0.84375
Train Iteration #13700:: 0.4354943633079529 Acc: 0.90625
Train Iteration #13750:: 0.44287198781967163 Acc: 0.90625
Train Iteration #13800:: 0.5046964287757874 Acc: 0.71875
Training:: Loss: 0.5562 Acc: 0.8126
Validation Iteration #3450:: 0.8347958326339722 Acc: 0.625
Validation:: Loss: 0.6708 Acc: 0.6906
Epoch 43/49
----------
Train Iteration #13850:: 0.39384859800338745 Acc: 0.8125
Train Iteration #13900:: 0.4933762550354004 Acc: 0.90625
Train Iteration #13950:: 0.5926638841629028 Acc: 0.875
Train Iteration #14000:: 0.6098632216453552 Acc: 0.78125
Train Iteration #14050:: 0.74788498878479 Acc: 0.65625
Train Iteration #14100:: 0.2658134996891022 Acc: 0.90625
Training:: Loss: 0.5502 Acc: 0.8174
Validation Iteration #3500:: 0.5320965051651001 Acc: 0.8125
Validation Iteration #3550:: 0.41900554299354553 Acc: 0.875
Validation:: Loss: 0.5119 Acc: 0.8096
Epoch 44/49
----------
Train Iteration #14150:: 0.5051983594894409 Acc: 0.84375
Train Iteration #14200:: 0.21645918488502502 Acc: 0.9375
Train Iteration #14250:: 0.4297056794166565 Acc: 0.90625
Train Iteration #14300:: 0.5247641205787659 Acc: 0.8125
Train Iteration #14350:: 0.41729748249053955 Acc: 0.875
Train Iteration #14400:: 0.48164501786231995 Acc: 0.8125
Training:: Loss: 0.5619 Acc: 0.8130
Validation Iteration #3600:: 0.5062535405158997 Acc: 0.8125
Validation:: Loss: 0.4874 Acc: 0.8248
Epoch 45/49
----------
Train Iteration #14450:: 0.6901236176490784 Acc: 0.84375
Train Iteration #14500:: 0.461883008480072 Acc: 0.78125
Train Iteration #14550:: 0.6371437311172485 Acc: 0.71875
Train Iteration #14600:: 0.5177033543586731 Acc: 0.78125
Train Iteration #14650:: 0.5756776332855225 Acc: 0.78125
Train Iteration #14700:: 0.3778461813926697 Acc: 0.9375
Train Iteration #14750:: 0.5505217909812927 Acc: 0.71875
Training:: Loss: 0.5849 Acc: 0.8053
Validation Iteration #3650:: 0.6626054048538208 Acc: 0.75
Validation Iteration #3700:: 0.4777691662311554 Acc: 0.78125
Validation:: Loss: 0.4973 Acc: 0.8162
Epoch 46/49
----------
Train Iteration #14800:: 0.3150356113910675 Acc: 0.9375
Train Iteration #14850:: 0.6158567070960999 Acc: 0.875
Train Iteration #14900:: 0.5402134656906128 Acc: 0.78125
Train Iteration #14950:: 0.7139100432395935 Acc: 0.65625
Train Iteration #15000:: 0.6400324702262878 Acc: 0.75
Train Iteration #15050:: 0.7204544544219971 Acc: 0.75
Training:: Loss: 0.5799 Acc: 0.8065
Validation Iteration #3750:: 0.4980216324329376 Acc: 0.875
Validation Iteration #3800:: 0.36506083607673645 Acc: 0.875
Validation:: Loss: 0.4954 Acc: 0.8634
Epoch 47/49
----------
Train Iteration #15100:: 0.3543304204940796 Acc: 0.90625
Train Iteration #15150:: 0.6719952821731567 Acc: 0.71875
Train Iteration #15200:: 0.2539657950401306 Acc: 0.90625
Train Iteration #15250:: 0.29611703753471375 Acc: 0.9375
Train Iteration #15300:: 0.37210583686828613 Acc: 0.84375
Train Iteration #15350:: 0.3512488901615143 Acc: 0.90625
Train Iteration #15400:: 0.3796985149383545 Acc: 0.8125
Training:: Loss: 0.5612 Acc: 0.8111
Validation Iteration #3850:: 0.6025786399841309 Acc: 0.84375
Validation:: Loss: 0.5137 Acc: 0.8607
Epoch 48/49
----------
Train Iteration #15450:: 0.3009614646434784 Acc: 0.90625
Train Iteration #15500:: 0.4069461226463318 Acc: 0.875
Train Iteration #15550:: 0.4100649952888489 Acc: 0.90625
Train Iteration #15600:: 0.4300094544887543 Acc: 0.84375
Train Iteration #15650:: 0.5633378624916077 Acc: 0.84375
Train Iteration #15700:: 0.5422961711883545 Acc: 0.8125
Training:: Loss: 0.5709 Acc: 0.8106
Validation Iteration #3900:: 0.7305939197540283 Acc: 0.59375
Validation Iteration #3950:: 0.734861433506012 Acc: 0.6875
Validation:: Loss: 0.6356 Acc: 0.7167
Epoch 49/49
----------
Train Iteration #15750:: 0.6788255572319031 Acc: 0.78125
Train Iteration #15800:: 0.34917426109313965 Acc: 1.0
Train Iteration #15850:: 0.24969056248664856 Acc: 0.90625
Train Iteration #15900:: 0.6618852615356445 Acc: 0.78125
Train Iteration #15950:: 0.7637192010879517 Acc: 0.8125
Train Iteration #16000:: 0.7404695749282837 Acc: 0.65625
Training:: Loss: 0.5724 Acc: 0.8061
Validation Iteration #4000:: 0.5720714330673218 Acc: 0.71875
Validation:: Loss: 0.4753 Acc: 0.8400
Best Validation Acc: 0.863441
End time:2:26:33.225298
Program Complete
Average Train Loss:0.5750752320768217
Average Validation Loss:0.5432556245948391
Average Train Accuracy:0.8026804525946156
Average Validation Accuracy:0.7934763948497857
