cuda
Program started
Epoch 0/99
----------
Train Iteration #0:: 1.10520601272583 Acc: 0.65625
Train Iteration #50:: 0.9344142079353333 Acc: 0.5625
Train Iteration #100:: 1.031951904296875 Acc: 0.5
Train Iteration #150:: 0.8875769972801208 Acc: 0.5625
Train Iteration #200:: 0.8924285173416138 Acc: 0.5625
Train Iteration #250:: 0.7583470344543457 Acc: 0.59375
Train Iteration #300:: 0.8303450345993042 Acc: 0.59375
Training:: Loss: 0.9397 Acc: 0.5648
Validation Iteration #0:: 0.875076413154602 Acc: 0.46875
Validation Iteration #50:: 0.8147445917129517 Acc: 0.59375
Validation:: Loss: 0.8949 Acc: 0.4370
Epoch 1/99
----------
Train Iteration #350:: 0.773347020149231 Acc: 0.71875
Train Iteration #400:: 0.9080215692520142 Acc: 0.65625
Train Iteration #450:: 1.0699918270111084 Acc: 0.5625
Train Iteration #500:: 0.8558629751205444 Acc: 0.59375
Train Iteration #550:: 0.8963544368743896 Acc: 0.59375
Train Iteration #600:: 0.8425319194793701 Acc: 0.625
Training:: Loss: 0.8344 Acc: 0.6457
Validation Iteration #100:: 0.5589290857315063 Acc: 0.8125
Validation Iteration #150:: 0.8443886041641235 Acc: 0.4375
Validation:: Loss: 0.7122 Acc: 0.6356
Epoch 2/99
----------
Train Iteration #650:: 0.8936166167259216 Acc: 0.75
Train Iteration #700:: 0.7684476375579834 Acc: 0.6875
Train Iteration #750:: 1.0559539794921875 Acc: 0.5
Train Iteration #800:: 0.8460512757301331 Acc: 0.625
Train Iteration #850:: 0.758243203163147 Acc: 0.71875
Train Iteration #900:: 0.5470796227455139 Acc: 0.71875
Train Iteration #950:: 0.8198956847190857 Acc: 0.6875
Training:: Loss: 0.8206 Acc: 0.6691
Validation Iteration #200:: 0.7328304648399353 Acc: 0.6875
Validation:: Loss: 0.6775 Acc: 0.6625
Epoch 3/99
----------
Train Iteration #1000:: 0.6145054697990417 Acc: 0.78125
Train Iteration #1050:: 1.017831802368164 Acc: 0.625
Train Iteration #1100:: 0.7694336175918579 Acc: 0.84375
Train Iteration #1150:: 0.7217350006103516 Acc: 0.8125
Train Iteration #1200:: 0.811109185218811 Acc: 0.65625
Train Iteration #1250:: 0.7552422285079956 Acc: 0.625
Training:: Loss: 0.7996 Acc: 0.6783
Validation Iteration #250:: 0.8504581451416016 Acc: 0.5625
Validation Iteration #300:: 0.5149435997009277 Acc: 0.71875
Validation:: Loss: 0.7577 Acc: 0.5817
Epoch 4/99
----------
Train Iteration #1300:: 0.682874321937561 Acc: 0.59375
Train Iteration #1350:: 0.9571523070335388 Acc: 0.59375
Train Iteration #1400:: 0.8569337129592896 Acc: 0.59375
Train Iteration #1450:: 0.8716127276420593 Acc: 0.625
Train Iteration #1500:: 0.8715381622314453 Acc: 0.625
Train Iteration #1550:: 0.9486547112464905 Acc: 0.5625
Train Iteration #1600:: 1.113499641418457 Acc: 0.71875
Training:: Loss: 0.7869 Acc: 0.6909
Validation Iteration #350:: 0.6703566312789917 Acc: 0.59375
Validation Iteration #400:: 0.7544820308685303 Acc: 0.59375
Validation:: Loss: 0.6504 Acc: 0.6886
Epoch 5/99
----------
Train Iteration #1650:: 0.703516960144043 Acc: 0.71875
Train Iteration #1700:: 0.6552736759185791 Acc: 0.75
Train Iteration #1750:: 0.8012673258781433 Acc: 0.5625
Train Iteration #1800:: 0.9688230156898499 Acc: 0.5
Train Iteration #1850:: 0.8786832094192505 Acc: 0.5625
Train Iteration #1900:: 0.5665616989135742 Acc: 0.8125
Training:: Loss: 0.7948 Acc: 0.6922
Validation Iteration #450:: 0.5581548810005188 Acc: 0.75
Validation:: Loss: 0.6164 Acc: 0.7202
Epoch 6/99
----------
Train Iteration #1950:: 0.5673288106918335 Acc: 0.71875
Train Iteration #2000:: 0.8394372463226318 Acc: 0.5
Train Iteration #2050:: 1.2185074090957642 Acc: 0.625
Train Iteration #2100:: 0.878506064414978 Acc: 0.6875
Train Iteration #2150:: 0.8518258333206177 Acc: 0.65625
Train Iteration #2200:: 1.1679903268814087 Acc: 0.59375
Training:: Loss: 0.7779 Acc: 0.7015
Validation Iteration #500:: 0.7804986238479614 Acc: 0.59375
Validation Iteration #550:: 0.8278520107269287 Acc: 0.46875
Validation:: Loss: 0.7016 Acc: 0.6344
Epoch 7/99
----------
Train Iteration #2250:: 0.6778108477592468 Acc: 0.59375
Train Iteration #2300:: 0.5865432024002075 Acc: 0.78125
Train Iteration #2350:: 0.6266566514968872 Acc: 0.75
Train Iteration #2400:: 0.7587507963180542 Acc: 0.71875
Train Iteration #2450:: 0.7169041037559509 Acc: 0.625
Train Iteration #2500:: 0.8649016618728638 Acc: 0.8125
Train Iteration #2550:: 0.9428629279136658 Acc: 0.625
Training:: Loss: 0.7835 Acc: 0.6975
Validation Iteration #600:: 0.5149577856063843 Acc: 0.84375
Validation:: Loss: 0.5420 Acc: 0.8022
Epoch 8/99
----------
Train Iteration #2600:: 0.864395260810852 Acc: 0.78125
Train Iteration #2650:: 0.801897406578064 Acc: 0.625
Train Iteration #2700:: 0.7815401554107666 Acc: 0.59375
Train Iteration #2750:: 0.9599095582962036 Acc: 0.59375
Train Iteration #2800:: 0.5987443923950195 Acc: 0.75
Train Iteration #2850:: 0.8505957126617432 Acc: 0.71875
Training:: Loss: 0.7903 Acc: 0.6941
Validation Iteration #650:: 0.6206845641136169 Acc: 0.78125
Validation Iteration #700:: 0.5179252624511719 Acc: 0.75
Validation:: Loss: 0.5849 Acc: 0.7429
Epoch 9/99
----------
Train Iteration #2900:: 0.5694562196731567 Acc: 0.84375
Train Iteration #2950:: 0.9180288910865784 Acc: 0.59375
Train Iteration #3000:: 0.9111596345901489 Acc: 0.65625
Train Iteration #3050:: 0.9182285070419312 Acc: 0.5625
Train Iteration #3100:: 0.8248231410980225 Acc: 0.78125
Train Iteration #3150:: 0.6500912308692932 Acc: 0.78125
Train Iteration #3200:: 0.6012111902236938 Acc: 0.75
Training:: Loss: 0.7827 Acc: 0.7007
Validation Iteration #750:: 0.546056866645813 Acc: 0.75
Validation Iteration #800:: 0.4713391065597534 Acc: 0.90625
Validation:: Loss: 0.5089 Acc: 0.8474
Epoch 10/99
----------
Train Iteration #3250:: 0.8654093742370605 Acc: 0.65625
Train Iteration #3300:: 0.7761993408203125 Acc: 0.6875
Train Iteration #3350:: 0.8774608373641968 Acc: 0.65625
Train Iteration #3400:: 0.9117854833602905 Acc: 0.59375
Train Iteration #3450:: 0.8903267979621887 Acc: 0.71875
Train Iteration #3500:: 0.7220343351364136 Acc: 0.6875
Training:: Loss: 0.7946 Acc: 0.6979
Validation Iteration #850:: 0.3811628222465515 Acc: 0.875
Validation:: Loss: 0.5479 Acc: 0.7827
Epoch 11/99
----------
Train Iteration #3550:: 0.778861939907074 Acc: 0.65625
Train Iteration #3600:: 0.5466708540916443 Acc: 0.78125
Train Iteration #3650:: 0.6895737051963806 Acc: 0.75
Train Iteration #3700:: 0.6630610227584839 Acc: 0.78125
Train Iteration #3750:: 0.671228289604187 Acc: 0.8125
Train Iteration #3800:: 0.889938473701477 Acc: 0.625
Train Iteration #3850:: 0.7166212797164917 Acc: 0.8125
Training:: Loss: 0.7631 Acc: 0.7128
Validation Iteration #900:: 0.7197878360748291 Acc: 0.625
Validation Iteration #950:: 0.7117977142333984 Acc: 0.65625
Validation:: Loss: 0.7329 Acc: 0.6192
Epoch 12/99
----------
Train Iteration #3900:: 0.9369189739227295 Acc: 0.65625
Train Iteration #3950:: 0.5901743173599243 Acc: 0.75
Train Iteration #4000:: 0.8659318685531616 Acc: 0.53125
Train Iteration #4050:: 0.5976077914237976 Acc: 0.78125
Train Iteration #4100:: 0.6280084252357483 Acc: 0.6875
Train Iteration #4150:: 0.8046524524688721 Acc: 0.6875
Training:: Loss: 0.7684 Acc: 0.7070
Validation Iteration #1000:: 0.6547403335571289 Acc: 0.625
Validation Iteration #1050:: 0.6703841686248779 Acc: 0.59375
Validation:: Loss: 0.7686 Acc: 0.5973
Epoch 13/99
----------
Train Iteration #4200:: 0.5251063108444214 Acc: 0.84375
Train Iteration #4250:: 0.7611484527587891 Acc: 0.625
Train Iteration #4300:: 0.4758176803588867 Acc: 0.84375
Train Iteration #4350:: 0.7110049724578857 Acc: 0.75
Train Iteration #4400:: 0.7682600021362305 Acc: 0.6875
Train Iteration #4450:: 0.6481249332427979 Acc: 0.75
Training:: Loss: 0.7727 Acc: 0.7073
Validation Iteration #1100:: 0.5209864377975464 Acc: 0.75
Validation:: Loss: 0.6141 Acc: 0.7078
Epoch 14/99
----------
Train Iteration #4500:: 0.7403160333633423 Acc: 0.6875
Train Iteration #4550:: 0.6128003597259521 Acc: 0.78125
Train Iteration #4600:: 0.6989694833755493 Acc: 0.8125
Train Iteration #4650:: 0.7347614169120789 Acc: 0.75
Train Iteration #4700:: 0.548363447189331 Acc: 0.90625
Train Iteration #4750:: 0.8106739521026611 Acc: 0.6875
Train Iteration #4800:: 0.6732115745544434 Acc: 0.8125
Training:: Loss: 0.7841 Acc: 0.7083
Validation Iteration #1150:: 0.424274742603302 Acc: 0.78125
Validation Iteration #1200:: 0.5008442401885986 Acc: 0.84375
Validation:: Loss: 0.5737 Acc: 0.7542
Epoch 15/99
----------
Train Iteration #4850:: 0.9564547538757324 Acc: 0.6875
Train Iteration #4900:: 0.6859409809112549 Acc: 0.6875
Train Iteration #4950:: 0.8806491494178772 Acc: 0.6875
Train Iteration #5000:: 0.8379095792770386 Acc: 0.6875
Train Iteration #5050:: 0.8200861215591431 Acc: 0.71875
Train Iteration #5100:: 0.786965012550354 Acc: 0.78125
Training:: Loss: 0.7876 Acc: 0.7063
Validation Iteration #1250:: 0.5916317701339722 Acc: 0.78125
Validation:: Loss: 0.5601 Acc: 0.7593
Epoch 16/99
----------
Train Iteration #5150:: 0.8475584983825684 Acc: 0.65625
Train Iteration #5200:: 0.5607328414916992 Acc: 0.78125
Train Iteration #5250:: 0.7523452043533325 Acc: 0.71875
Train Iteration #5300:: 0.7741391658782959 Acc: 0.71875
Train Iteration #5350:: 0.8986943364143372 Acc: 0.6875
Train Iteration #5400:: 0.8583061099052429 Acc: 0.5625
Train Iteration #5450:: 0.7886056900024414 Acc: 0.59375
Training:: Loss: 0.7787 Acc: 0.7096
Validation Iteration #1300:: 0.509598970413208 Acc: 0.8125
Validation Iteration #1350:: 0.5840014219284058 Acc: 0.75
Validation:: Loss: 0.5128 Acc: 0.8123
Epoch 17/99
----------
Train Iteration #5500:: 0.5515069365501404 Acc: 0.78125
Train Iteration #5550:: 0.6305584907531738 Acc: 0.8125
Train Iteration #5600:: 0.6436817646026611 Acc: 0.78125
Train Iteration #5650:: 0.9226204752922058 Acc: 0.71875
Train Iteration #5700:: 0.9530225992202759 Acc: 0.65625
Train Iteration #5750:: 0.4243626296520233 Acc: 0.90625
Training:: Loss: 0.7613 Acc: 0.7127
Validation Iteration #1400:: 0.5516403913497925 Acc: 0.71875
Validation Iteration #1450:: 0.5268595218658447 Acc: 0.75
Validation:: Loss: 0.5843 Acc: 0.7335
Epoch 18/99
----------
Train Iteration #5800:: 0.8252187371253967 Acc: 0.71875
Train Iteration #5850:: 0.8355309367179871 Acc: 0.65625
Train Iteration #5900:: 0.7235316038131714 Acc: 0.5625
Train Iteration #5950:: 0.818615198135376 Acc: 0.65625
Train Iteration #6000:: 0.8092739582061768 Acc: 0.6875
Train Iteration #6050:: 0.6439388394355774 Acc: 0.8125
Training:: Loss: 0.7560 Acc: 0.7140
Validation Iteration #1500:: 0.723611056804657 Acc: 0.625
Validation:: Loss: 0.6380 Acc: 0.6933
Epoch 19/99
----------
Train Iteration #6100:: 0.7392911911010742 Acc: 0.71875
Train Iteration #6150:: 0.9920758605003357 Acc: 0.59375
Train Iteration #6200:: 0.6515215039253235 Acc: 0.71875
Train Iteration #6250:: 0.9729034900665283 Acc: 0.71875
Train Iteration #6300:: 1.0208144187927246 Acc: 0.6875
Train Iteration #6350:: 0.7042015194892883 Acc: 0.75
Train Iteration #6400:: 0.5457996726036072 Acc: 0.8125
Training:: Loss: 0.7827 Acc: 0.7095
Validation Iteration #1550:: 0.42038214206695557 Acc: 0.9375
Validation Iteration #1600:: 0.4587998688220978 Acc: 0.9375
Validation:: Loss: 0.4939 Acc: 0.8486
Epoch 20/99
----------
Train Iteration #6450:: 1.0251092910766602 Acc: 0.5625
Train Iteration #6500:: 0.635959267616272 Acc: 0.78125
Train Iteration #6550:: 1.117113471031189 Acc: 0.5
Train Iteration #6600:: 0.6944140195846558 Acc: 0.75
Train Iteration #6650:: 0.9322987794876099 Acc: 0.65625
Train Iteration #6700:: 0.8413709402084351 Acc: 0.59375
Training:: Loss: 0.7882 Acc: 0.7088
Validation Iteration #1650:: 0.3718068599700928 Acc: 0.84375
Validation Iteration #1700:: 0.21238963305950165 Acc: 1.0
Validation:: Loss: 0.5165 Acc: 0.8088
Epoch 21/99
----------
Train Iteration #6750:: 0.6888214349746704 Acc: 0.75
Train Iteration #6800:: 0.5792897939682007 Acc: 0.8125
Train Iteration #6850:: 0.6858381628990173 Acc: 0.8125
Train Iteration #6900:: 0.538677990436554 Acc: 0.875
Train Iteration #6950:: 0.9505276679992676 Acc: 0.65625
Train Iteration #7000:: 1.052839994430542 Acc: 0.46875
Train Iteration #7050:: 0.8169245719909668 Acc: 0.65625
Training:: Loss: 0.7622 Acc: 0.7183
Validation Iteration #1750:: 0.5699309706687927 Acc: 0.71875
Validation:: Loss: 0.7260 Acc: 0.6309
Epoch 22/99
----------
Train Iteration #7100:: 0.6457135677337646 Acc: 0.71875
Train Iteration #7150:: 0.8050059080123901 Acc: 0.6875
Train Iteration #7200:: 0.567562997341156 Acc: 0.75
Train Iteration #7250:: 0.791261613368988 Acc: 0.46875
Train Iteration #7300:: 0.7515923976898193 Acc: 0.6875
Train Iteration #7350:: 0.7780816555023193 Acc: 0.75
Training:: Loss: 0.7732 Acc: 0.7118
Validation Iteration #1800:: 0.42094606161117554 Acc: 0.84375
Validation Iteration #1850:: 0.5430365800857544 Acc: 0.71875
Validation:: Loss: 0.5616 Acc: 0.7561
Epoch 23/99
----------
Train Iteration #7400:: 0.6003636717796326 Acc: 0.75
Train Iteration #7450:: 0.6059597730636597 Acc: 0.75
Train Iteration #7500:: 0.8002864122390747 Acc: 0.75
Train Iteration #7550:: 0.6220728754997253 Acc: 0.84375
Train Iteration #7600:: 0.6941043734550476 Acc: 0.78125
Train Iteration #7650:: 1.1018376350402832 Acc: 0.59375
Train Iteration #7700:: 0.7476761341094971 Acc: 0.8125
Training:: Loss: 0.7796 Acc: 0.7123
Validation Iteration #1900:: 0.46798911690711975 Acc: 0.8125
Validation:: Loss: 0.5178 Acc: 0.8041
Epoch 24/99
----------
Train Iteration #7750:: 0.5676800012588501 Acc: 0.8125
Train Iteration #7800:: 0.5509787797927856 Acc: 0.875
Train Iteration #7850:: 0.7576445937156677 Acc: 0.71875
Train Iteration #7900:: 0.6487051844596863 Acc: 0.75
Train Iteration #7950:: 1.0129101276397705 Acc: 0.53125
Train Iteration #8000:: 0.7534085512161255 Acc: 0.8125
Training:: Loss: 0.7734 Acc: 0.7080
Validation Iteration #1950:: 0.3955746293067932 Acc: 0.90625
Validation Iteration #2000:: 0.46876418590545654 Acc: 0.875
Validation:: Loss: 0.4896 Acc: 0.8502
Epoch 25/99
----------
Train Iteration #8050:: 0.9923770427703857 Acc: 0.5625
Train Iteration #8100:: 0.8756960034370422 Acc: 0.75
Train Iteration #8150:: 0.7683870792388916 Acc: 0.625
Train Iteration #8200:: 0.5877624154090881 Acc: 0.71875
Train Iteration #8250:: 0.6305512189865112 Acc: 0.65625
Train Iteration #8300:: 0.8200505971908569 Acc: 0.6875
Training:: Loss: 0.7673 Acc: 0.7098
Validation Iteration #2050:: 0.6929852366447449 Acc: 0.71875
Validation Iteration #2100:: 0.6319345831871033 Acc: 0.65625
Validation:: Loss: 0.5557 Acc: 0.7620
Epoch 26/99
----------
Train Iteration #8350:: 0.7588950395584106 Acc: 0.78125
Train Iteration #8400:: 0.823830783367157 Acc: 0.6875
Train Iteration #8450:: 0.7592076063156128 Acc: 0.75
Train Iteration #8500:: 0.8434741497039795 Acc: 0.625
Train Iteration #8550:: 0.8302223682403564 Acc: 0.75
Train Iteration #8600:: 0.9527864456176758 Acc: 0.5625
Train Iteration #8650:: 0.9375833868980408 Acc: 0.6875
Training:: Loss: 0.7875 Acc: 0.7085
Validation Iteration #2150:: 0.5264959335327148 Acc: 0.8125
Validation:: Loss: 0.6116 Acc: 0.7148
Epoch 27/99
----------
Train Iteration #8700:: 0.9926242232322693 Acc: 0.71875
Train Iteration #8750:: 0.6731329560279846 Acc: 0.75
Train Iteration #8800:: 0.8303974866867065 Acc: 0.59375
Train Iteration #8850:: 0.7496602535247803 Acc: 0.71875
Train Iteration #8900:: 0.8110960721969604 Acc: 0.71875
Train Iteration #8950:: 1.0537009239196777 Acc: 0.625
Training:: Loss: 0.7820 Acc: 0.7062
Validation Iteration #2200:: 0.5308699607849121 Acc: 0.8125
Validation Iteration #2250:: 0.7635334134101868 Acc: 0.625
Validation:: Loss: 0.6725 Acc: 0.6637
Epoch 28/99
----------
Train Iteration #9000:: 0.7278808355331421 Acc: 0.71875
Train Iteration #9050:: 0.8627245426177979 Acc: 0.59375
Train Iteration #9100:: 0.6800421476364136 Acc: 0.71875
Train Iteration #9150:: 0.9839744567871094 Acc: 0.71875
Train Iteration #9200:: 0.8454619646072388 Acc: 0.6875
Train Iteration #9250:: 0.8363112211227417 Acc: 0.65625
Train Iteration #9300:: 0.6363509893417358 Acc: 0.71875
Training:: Loss: 0.7586 Acc: 0.7179
Validation Iteration #2300:: 0.8009977340698242 Acc: 0.59375
Validation:: Loss: 0.5858 Acc: 0.7366
Epoch 29/99
----------
Train Iteration #9350:: 0.7364997863769531 Acc: 0.75
Train Iteration #9400:: 0.9282032251358032 Acc: 0.8125
Train Iteration #9450:: 0.8125213384628296 Acc: 0.71875
Train Iteration #9500:: 1.0113874673843384 Acc: 0.65625
Train Iteration #9550:: 0.8265801668167114 Acc: 0.625
Train Iteration #9600:: 0.6657220721244812 Acc: 0.71875
Training:: Loss: 0.7964 Acc: 0.7065
Validation Iteration #2350:: 0.543724775314331 Acc: 0.71875
Validation Iteration #2400:: 0.6437033414840698 Acc: 0.75
Validation:: Loss: 0.6025 Acc: 0.7199
Epoch 30/99
----------
Train Iteration #9650:: 0.5457953214645386 Acc: 0.875
Train Iteration #9700:: 0.7555949091911316 Acc: 0.625
Train Iteration #9750:: 0.6753296256065369 Acc: 0.84375
Train Iteration #9800:: 0.7599928379058838 Acc: 0.6875
Train Iteration #9850:: 0.8268027901649475 Acc: 0.59375
Train Iteration #9900:: 0.6628930568695068 Acc: 0.75
Train Iteration #9950:: 0.8238865733146667 Acc: 0.6666666666666666
Training:: Loss: 0.7765 Acc: 0.7134
Validation Iteration #2450:: 0.8455038070678711 Acc: 0.59375
Validation Iteration #2500:: 0.6365882158279419 Acc: 0.71875
Validation:: Loss: 0.6801 Acc: 0.6707
Epoch 31/99
----------
Train Iteration #10000:: 0.6716085076332092 Acc: 0.78125
Train Iteration #10050:: 0.956900417804718 Acc: 0.6875
Train Iteration #10100:: 0.6906801462173462 Acc: 0.59375
Train Iteration #10150:: 0.890413224697113 Acc: 0.75
Train Iteration #10200:: 0.8383837938308716 Acc: 0.71875
Train Iteration #10250:: 0.7851735949516296 Acc: 0.65625
Training:: Loss: 0.7896 Acc: 0.7046
Validation Iteration #2550:: 0.45345669984817505 Acc: 0.8125
Validation:: Loss: 0.5333 Acc: 0.7936
Epoch 32/99
----------
Train Iteration #10300:: 1.1463428735733032 Acc: 0.5
Train Iteration #10350:: 0.842368483543396 Acc: 0.625
Train Iteration #10400:: 0.7747878432273865 Acc: 0.71875
Train Iteration #10450:: 0.9225633144378662 Acc: 0.5
Train Iteration #10500:: 0.5303635597229004 Acc: 0.75
Train Iteration #10550:: 0.8046708703041077 Acc: 0.71875
Training:: Loss: 0.7898 Acc: 0.7117
Validation Iteration #2600:: 0.46225133538246155 Acc: 0.8125
Validation Iteration #2650:: 0.5327614545822144 Acc: 0.75
Validation:: Loss: 0.5903 Acc: 0.7284
Epoch 33/99
----------
Train Iteration #10600:: 0.9220529794692993 Acc: 0.59375
Train Iteration #10650:: 0.46041974425315857 Acc: 0.71875
Train Iteration #10700:: 0.6179028749465942 Acc: 0.6875
Train Iteration #10750:: 0.524712324142456 Acc: 0.8125
Train Iteration #10800:: 0.6290953159332275 Acc: 0.71875
Train Iteration #10850:: 0.6358566284179688 Acc: 0.8125
Train Iteration #10900:: 0.7922617197036743 Acc: 0.71875
Training:: Loss: 0.7704 Acc: 0.7134
Validation Iteration #2700:: 0.5135380029678345 Acc: 0.75
Validation Iteration #2750:: 0.7056905031204224 Acc: 0.65625
Validation:: Loss: 0.5753 Acc: 0.7362
Epoch 34/99
----------
Train Iteration #10950:: 0.7308838367462158 Acc: 0.78125
Train Iteration #11000:: 0.7836605906486511 Acc: 0.8125
Train Iteration #11050:: 0.7108597755432129 Acc: 0.75
Train Iteration #11100:: 0.601954996585846 Acc: 0.8125
Train Iteration #11150:: 0.9024896025657654 Acc: 0.59375
Train Iteration #11200:: 0.7227307558059692 Acc: 0.71875
Training:: Loss: 0.7763 Acc: 0.7106
Validation Iteration #2800:: 0.49550938606262207 Acc: 0.84375
Validation:: Loss: 0.5402 Acc: 0.7757
Epoch 35/99
----------
Train Iteration #11250:: 0.7903749346733093 Acc: 0.71875
Train Iteration #11300:: 0.9577146172523499 Acc: 0.5625
Train Iteration #11350:: 1.0870370864868164 Acc: 0.8125
Train Iteration #11400:: 0.8144845366477966 Acc: 0.6875
Train Iteration #11450:: 0.946966826915741 Acc: 0.5
Train Iteration #11500:: 0.8771630525588989 Acc: 0.625
Train Iteration #11550:: 0.8893090486526489 Acc: 0.65625
Training:: Loss: 0.8039 Acc: 0.6987
Validation Iteration #2850:: 0.6136273145675659 Acc: 0.71875
Validation Iteration #2900:: 0.49542945623397827 Acc: 0.78125
Validation:: Loss: 0.5368 Acc: 0.7741
Epoch 36/99
----------
Train Iteration #11600:: 0.5654507875442505 Acc: 0.90625
Train Iteration #11650:: 0.7787845134735107 Acc: 0.71875
Train Iteration #11700:: 0.9150220155715942 Acc: 0.59375
Train Iteration #11750:: 0.6264494061470032 Acc: 0.875
Train Iteration #11800:: 0.7381943464279175 Acc: 0.6875
Train Iteration #11850:: 0.922480583190918 Acc: 0.5625
Training:: Loss: 0.7766 Acc: 0.7079
Validation Iteration #2950:: 0.5561183094978333 Acc: 0.6875
Validation:: Loss: 0.5368 Acc: 0.7753
Epoch 37/99
----------
Train Iteration #11900:: 0.5676485896110535 Acc: 0.84375
Train Iteration #11950:: 0.7559451460838318 Acc: 0.6875
Train Iteration #12000:: 0.7044202089309692 Acc: 0.75
Train Iteration #12050:: 0.506530225276947 Acc: 0.90625
Train Iteration #12100:: 0.6575337648391724 Acc: 0.8125
Train Iteration #12150:: 0.6312574148178101 Acc: 0.75
Training:: Loss: 0.7936 Acc: 0.7047
Validation Iteration #3000:: 0.8978443741798401 Acc: 0.53125
Validation Iteration #3050:: 0.832878053188324 Acc: 0.59375
Validation:: Loss: 0.7755 Acc: 0.6001
Epoch 38/99
----------
Train Iteration #12200:: 0.9076282978057861 Acc: 0.6875
Train Iteration #12250:: 0.9222949743270874 Acc: 0.625
Train Iteration #12300:: 0.7163338661193848 Acc: 0.8125
Train Iteration #12350:: 0.5359036922454834 Acc: 0.75
Train Iteration #12400:: 0.7310624122619629 Acc: 0.65625
Train Iteration #12450:: 1.115790605545044 Acc: 0.5
Train Iteration #12500:: 0.7797943353652954 Acc: 0.6875
Training:: Loss: 0.7722 Acc: 0.7105
Validation Iteration #3100:: 0.5785790681838989 Acc: 0.75
Validation Iteration #3150:: 0.46014469861984253 Acc: 0.8125
Validation:: Loss: 0.5516 Acc: 0.7632
Epoch 39/99
----------
Train Iteration #12550:: 1.0712590217590332 Acc: 0.65625
Train Iteration #12600:: 0.6703787446022034 Acc: 0.71875
Train Iteration #12650:: 0.73647141456604 Acc: 0.6875
Train Iteration #12700:: 0.5268238186836243 Acc: 0.875
Train Iteration #12750:: 0.7746458053588867 Acc: 0.6875
Train Iteration #12800:: 0.7135335206985474 Acc: 0.75
Training:: Loss: 0.7850 Acc: 0.7076
Validation Iteration #3200:: 0.671474814414978 Acc: 0.75
Validation:: Loss: 0.6148 Acc: 0.7128
Epoch 40/99
----------
Train Iteration #12850:: 0.6462308764457703 Acc: 0.75
Train Iteration #12900:: 0.7338064908981323 Acc: 0.78125
Train Iteration #12950:: 0.8033784627914429 Acc: 0.625
Train Iteration #13000:: 0.5327101349830627 Acc: 0.8125
Train Iteration #13050:: 0.7011615633964539 Acc: 0.6875
Train Iteration #13100:: 1.0062944889068604 Acc: 0.5625
Train Iteration #13150:: 0.5986212491989136 Acc: 0.84375
Training:: Loss: 0.7674 Acc: 0.7174
Validation Iteration #3250:: 0.8643227815628052 Acc: 0.59375
Validation Iteration #3300:: 0.6948782801628113 Acc: 0.59375
Validation:: Loss: 0.8901 Acc: 0.5302
Epoch 41/99
----------
Train Iteration #13200:: 0.6461697816848755 Acc: 0.65625
Train Iteration #13250:: 0.7347496747970581 Acc: 0.75
Train Iteration #13300:: 0.9895668625831604 Acc: 0.46875
Train Iteration #13350:: 0.6363107562065125 Acc: 0.78125
Train Iteration #13400:: 0.6168900728225708 Acc: 0.84375
Train Iteration #13450:: 0.7600381374359131 Acc: 0.75
Training:: Loss: 0.7851 Acc: 0.7095
Validation Iteration #3350:: 0.5182181000709534 Acc: 0.8125
Validation Iteration #3400:: 0.545346736907959 Acc: 0.71875
Validation:: Loss: 0.5134 Acc: 0.8073
Epoch 42/99
----------
Train Iteration #13500:: 0.6577288508415222 Acc: 0.75
Train Iteration #13550:: 0.6535608768463135 Acc: 0.8125
Train Iteration #13600:: 0.7463857531547546 Acc: 0.75
Train Iteration #13650:: 0.5781306624412537 Acc: 0.8125
Train Iteration #13700:: 0.8252020478248596 Acc: 0.65625
Train Iteration #13750:: 1.0851659774780273 Acc: 0.59375
Train Iteration #13800:: 0.6373428106307983 Acc: 0.6875
Training:: Loss: 0.7750 Acc: 0.7110
Validation Iteration #3450:: 0.8982365727424622 Acc: 0.46875
Validation:: Loss: 0.6867 Acc: 0.6633
Epoch 43/99
----------
Train Iteration #13850:: 0.5924274921417236 Acc: 0.84375
Train Iteration #13900:: 0.5786087512969971 Acc: 0.84375
Train Iteration #13950:: 0.9209579825401306 Acc: 0.6875
Train Iteration #14000:: 0.8148152232170105 Acc: 0.65625
Train Iteration #14050:: 0.9879153966903687 Acc: 0.59375
Train Iteration #14100:: 0.5408066511154175 Acc: 0.8125
Training:: Loss: 0.7790 Acc: 0.7096
Validation Iteration #3500:: 0.7725351452827454 Acc: 0.53125
Validation Iteration #3550:: 0.6588699221611023 Acc: 0.625
Validation:: Loss: 0.7005 Acc: 0.6422
Epoch 44/99
----------
Train Iteration #14150:: 0.6517722606658936 Acc: 0.84375
Train Iteration #14200:: 0.5658777952194214 Acc: 0.71875
Train Iteration #14250:: 0.5115121603012085 Acc: 0.8125
Train Iteration #14300:: 0.7244665622711182 Acc: 0.71875
Train Iteration #14350:: 0.9234992861747742 Acc: 0.71875
Train Iteration #14400:: 0.7224191427230835 Acc: 0.65625
Training:: Loss: 0.7850 Acc: 0.7107
Validation Iteration #3600:: 0.5746159553527832 Acc: 0.75
Validation:: Loss: 0.5898 Acc: 0.7277
Epoch 45/99
----------
Train Iteration #14450:: 0.664879322052002 Acc: 0.8125
Train Iteration #14500:: 0.8493149280548096 Acc: 0.71875
Train Iteration #14550:: 0.6826076507568359 Acc: 0.75
Train Iteration #14600:: 0.5632247924804688 Acc: 0.78125
Train Iteration #14650:: 0.7300089001655579 Acc: 0.71875
Train Iteration #14700:: 0.7165473699569702 Acc: 0.75
Train Iteration #14750:: 0.6348412036895752 Acc: 0.6875
Training:: Loss: 0.7783 Acc: 0.7083
Validation Iteration #3650:: 1.0293936729431152 Acc: 0.53125
Validation Iteration #3700:: 0.8752945065498352 Acc: 0.5
Validation:: Loss: 0.7575 Acc: 0.6028
Epoch 46/99
----------
Train Iteration #14800:: 0.5032995939254761 Acc: 0.90625
Train Iteration #14850:: 1.0058225393295288 Acc: 0.875
Train Iteration #14900:: 0.724364161491394 Acc: 0.75
Train Iteration #14950:: 0.9303659200668335 Acc: 0.625
Train Iteration #15000:: 0.9001460075378418 Acc: 0.59375
Train Iteration #15050:: 0.8451709747314453 Acc: 0.65625
Training:: Loss: 0.7903 Acc: 0.7059
Validation Iteration #3750:: 0.5943440794944763 Acc: 0.8125
Validation Iteration #3800:: 0.42579036951065063 Acc: 0.875
Validation:: Loss: 0.4955 Acc: 0.8283
Epoch 47/99
----------
Train Iteration #15100:: 0.6128438711166382 Acc: 0.8125
Train Iteration #15150:: 0.8299565315246582 Acc: 0.65625
Train Iteration #15200:: 0.6281017065048218 Acc: 0.71875
Train Iteration #15250:: 0.7366980314254761 Acc: 0.65625
Train Iteration #15300:: 0.6080148220062256 Acc: 0.78125
Train Iteration #15350:: 0.7511097192764282 Acc: 0.75
Train Iteration #15400:: 0.5977131724357605 Acc: 0.71875
Training:: Loss: 0.7656 Acc: 0.7136
Validation Iteration #3850:: 0.5799540281295776 Acc: 0.75
Validation:: Loss: 0.4826 Acc: 0.8662
Epoch 48/99
----------
Train Iteration #15450:: 0.5376209616661072 Acc: 0.78125
Train Iteration #15500:: 0.6721283197402954 Acc: 0.78125
Train Iteration #15550:: 0.5776396989822388 Acc: 0.84375
Train Iteration #15600:: 0.7624074816703796 Acc: 0.65625
Train Iteration #15650:: 0.7467266917228699 Acc: 0.78125
Train Iteration #15700:: 0.7075390815734863 Acc: 0.8125
Training:: Loss: 0.7774 Acc: 0.7085
Validation Iteration #3900:: 0.9215361475944519 Acc: 0.53125
Validation Iteration #3950:: 0.7479410171508789 Acc: 0.65625
Validation:: Loss: 0.7090 Acc: 0.6403
Epoch 49/99
----------
Train Iteration #15750:: 0.6986668109893799 Acc: 0.71875
Train Iteration #15800:: 0.8911942839622498 Acc: 0.75
Train Iteration #15850:: 0.7179505825042725 Acc: 0.65625
Train Iteration #15900:: 0.7526719570159912 Acc: 0.75
Train Iteration #15950:: 1.050858736038208 Acc: 0.65625
Train Iteration #16000:: 0.8399399518966675 Acc: 0.5625
Training:: Loss: 0.7757 Acc: 0.7123
Validation Iteration #4000:: 0.5973430871963501 Acc: 0.75
Validation:: Loss: 0.5376 Acc: 0.7831
Epoch 50/99
----------
Train Iteration #16050:: 0.8446488976478577 Acc: 0.78125
Train Iteration #16100:: 0.6748533248901367 Acc: 0.625
Train Iteration #16150:: 0.96051025390625 Acc: 0.65625
Train Iteration #16200:: 0.8723064661026001 Acc: 0.6875
Train Iteration #16250:: 0.9065988063812256 Acc: 0.625
Train Iteration #16300:: 0.851868212223053 Acc: 0.625
Train Iteration #16350:: 0.7467841506004333 Acc: 0.65625
Training:: Loss: 0.7952 Acc: 0.7026
Validation Iteration #4050:: 0.5752967596054077 Acc: 0.8125
Validation Iteration #4100:: 0.5336201190948486 Acc: 0.8125
Validation:: Loss: 0.5499 Acc: 0.7628
Epoch 51/99
----------
Train Iteration #16400:: 0.5077066421508789 Acc: 0.875
Train Iteration #16450:: 0.7152527570724487 Acc: 0.65625
Train Iteration #16500:: 0.8299844264984131 Acc: 0.59375
Train Iteration #16550:: 1.1123709678649902 Acc: 0.59375
Train Iteration #16600:: 0.5077183246612549 Acc: 0.75
Train Iteration #16650:: 0.7489672899246216 Acc: 0.6875
Training:: Loss: 0.7734 Acc: 0.7140
Validation Iteration #4150:: 0.40231257677078247 Acc: 0.84375
Validation Iteration #4200:: 0.7702881693840027 Acc: 0.625
Validation:: Loss: 0.5875 Acc: 0.7339
Epoch 52/99
----------
Train Iteration #16700:: 0.7198760509490967 Acc: 0.59375
Train Iteration #16750:: 0.8952287435531616 Acc: 0.6875
Train Iteration #16800:: 0.5472707748413086 Acc: 0.8125
Train Iteration #16850:: 0.862173855304718 Acc: 0.625
Train Iteration #16900:: 0.6942212581634521 Acc: 0.84375
Train Iteration #16950:: 0.7444562911987305 Acc: 0.65625
Train Iteration #17000:: 0.6813367605209351 Acc: 0.71875
Training:: Loss: 0.7734 Acc: 0.7109
Validation Iteration #4250:: 0.6926480531692505 Acc: 0.71875
Validation:: Loss: 0.6027 Acc: 0.7195
Epoch 53/99
----------
Train Iteration #17050:: 0.8970105051994324 Acc: 0.625
Train Iteration #17100:: 0.7640670537948608 Acc: 0.6875
Train Iteration #17150:: 0.8593972325325012 Acc: 0.71875
Train Iteration #17200:: 0.888198971748352 Acc: 0.5625
Train Iteration #17250:: 0.46594902873039246 Acc: 0.875
Train Iteration #17300:: 0.9596806168556213 Acc: 0.5625
Training:: Loss: 0.7759 Acc: 0.7077
Validation Iteration #4300:: 0.861469566822052 Acc: 0.59375
Validation Iteration #4350:: 0.4286644458770752 Acc: 0.8125
Validation:: Loss: 0.7220 Acc: 0.6286
Epoch 54/99
----------
Train Iteration #17350:: 0.8061000108718872 Acc: 0.625
Train Iteration #17400:: 0.8491426110267639 Acc: 0.84375
Train Iteration #17450:: 0.7065410017967224 Acc: 0.625
Train Iteration #17500:: 0.7438806295394897 Acc: 0.84375
Train Iteration #17550:: 0.7058149576187134 Acc: 0.6875
Train Iteration #17600:: 0.8117166757583618 Acc: 0.6875
Train Iteration #17650:: 0.7435780167579651 Acc: 0.71875
Training:: Loss: 0.7899 Acc: 0.7064
Validation Iteration #4400:: 0.6802467107772827 Acc: 0.65625
Validation Iteration #4450:: 0.7572593688964844 Acc: 0.53125
Validation:: Loss: 0.6689 Acc: 0.6691
Epoch 55/99
----------
Train Iteration #17700:: 1.1134862899780273 Acc: 0.5625
Train Iteration #17750:: 0.6375223994255066 Acc: 0.71875
Train Iteration #17800:: 0.8041626214981079 Acc: 0.65625
Train Iteration #17850:: 0.9352192282676697 Acc: 0.53125
Train Iteration #17900:: 0.6336276531219482 Acc: 0.75
Train Iteration #17950:: 1.01995050907135 Acc: 0.53125
Training:: Loss: 0.7716 Acc: 0.7123
Validation Iteration #4500:: 0.4499623775482178 Acc: 0.8125
Validation:: Loss: 0.5251 Acc: 0.7920
Epoch 56/99
----------
Train Iteration #18000:: 0.7116742134094238 Acc: 0.78125
Train Iteration #18050:: 0.6761492490768433 Acc: 0.875
Train Iteration #18100:: 0.579714834690094 Acc: 0.75
Train Iteration #18150:: 0.48993051052093506 Acc: 0.78125
Train Iteration #18200:: 0.736125648021698 Acc: 0.625
Train Iteration #18250:: 0.5503324866294861 Acc: 0.71875
Training:: Loss: 0.7815 Acc: 0.7095
Validation Iteration #4550:: 0.8091967701911926 Acc: 0.59375
Validation Iteration #4600:: 0.9298141002655029 Acc: 0.4375
Validation:: Loss: 0.7284 Acc: 0.6278
Epoch 57/99
----------
Train Iteration #18300:: 0.8501817584037781 Acc: 0.75
Train Iteration #18350:: 0.6666012406349182 Acc: 0.78125
Train Iteration #18400:: 0.6964261531829834 Acc: 0.71875
Train Iteration #18450:: 1.326125979423523 Acc: 0.5
Train Iteration #18500:: 0.9707738161087036 Acc: 0.6875
Train Iteration #18550:: 0.7483823299407959 Acc: 0.75
Train Iteration #18600:: 0.5688474178314209 Acc: 0.71875
Training:: Loss: 0.7759 Acc: 0.7084
Validation Iteration #4650:: 0.6654066443443298 Acc: 0.59375
Validation:: Loss: 0.6562 Acc: 0.6762
Epoch 58/99
----------
Train Iteration #18650:: 1.063902735710144 Acc: 0.5
Train Iteration #18700:: 0.9487953186035156 Acc: 0.65625
Train Iteration #18750:: 0.8201638460159302 Acc: 0.625
Train Iteration #18800:: 0.7286460399627686 Acc: 0.71875
Train Iteration #18850:: 0.7099201679229736 Acc: 0.71875
Train Iteration #18900:: 0.987893283367157 Acc: 0.625
Training:: Loss: 0.7679 Acc: 0.7118
Validation Iteration #4700:: 0.5770163536071777 Acc: 0.8125
Validation Iteration #4750:: 0.47187113761901855 Acc: 0.78125
Validation:: Loss: 0.5382 Acc: 0.7760
Epoch 59/99
----------
Train Iteration #18950:: 0.7271062135696411 Acc: 0.625
Train Iteration #19000:: 0.4040364623069763 Acc: 0.875
Train Iteration #19050:: 0.9897310733795166 Acc: 0.59375
Train Iteration #19100:: 0.9879865050315857 Acc: 0.59375
Train Iteration #19150:: 0.7656123638153076 Acc: 0.78125
Train Iteration #19200:: 0.723884105682373 Acc: 0.71875
Train Iteration #19250:: 0.6514108180999756 Acc: 0.65625
Training:: Loss: 0.7923 Acc: 0.7043
Validation Iteration #4800:: 0.8515175580978394 Acc: 0.59375
Validation Iteration #4850:: 0.5844634175300598 Acc: 0.6875
Validation:: Loss: 0.7248 Acc: 0.6286
Epoch 60/99
----------
Train Iteration #19300:: 0.8836758136749268 Acc: 0.6875
Train Iteration #19350:: 0.7997218370437622 Acc: 0.78125
Train Iteration #19400:: 0.783279299736023 Acc: 0.71875
Train Iteration #19450:: 0.7019808292388916 Acc: 0.6875
Train Iteration #19500:: 0.8577054738998413 Acc: 0.6875
Train Iteration #19550:: 0.834026575088501 Acc: 0.75
Training:: Loss: 0.7599 Acc: 0.7163
Validation Iteration #4900:: 0.3685452342033386 Acc: 0.875
Validation:: Loss: 0.5579 Acc: 0.7667
Epoch 61/99
----------
Train Iteration #19600:: 0.9440168142318726 Acc: 0.6875
Train Iteration #19650:: 0.5756722092628479 Acc: 0.75
Train Iteration #19700:: 0.9957493543624878 Acc: 0.5
Train Iteration #19750:: 0.700211763381958 Acc: 0.78125
Train Iteration #19800:: 1.0568656921386719 Acc: 0.71875
Train Iteration #19850:: 1.244079351425171 Acc: 0.5625
Train Iteration #19900:: 1.07779860496521 Acc: 0.46875
Training:: Loss: 0.7899 Acc: 0.7020
Validation Iteration #4950:: 0.6751554012298584 Acc: 0.6875
Validation Iteration #5000:: 0.6747308969497681 Acc: 0.75
Validation:: Loss: 0.6813 Acc: 0.6551
Epoch 62/99
----------
Train Iteration #19950:: 1.1434671878814697 Acc: 0.625
Train Iteration #20000:: 0.9908718466758728 Acc: 0.5
Train Iteration #20050:: 0.5941199064254761 Acc: 0.75
Train Iteration #20100:: 0.9184682369232178 Acc: 0.5
Train Iteration #20150:: 1.0643668174743652 Acc: 0.4375
Train Iteration #20200:: 1.1781456470489502 Acc: 0.53125
Training:: Loss: 0.7696 Acc: 0.7146
Validation Iteration #5050:: 0.4049749970436096 Acc: 0.875
Validation Iteration #5100:: 0.5216854810714722 Acc: 0.875
Validation:: Loss: 0.4973 Acc: 0.8272
Epoch 63/99
----------
Train Iteration #20250:: 0.885047197341919 Acc: 0.75
Train Iteration #20300:: 0.9407656192779541 Acc: 0.6875
Train Iteration #20350:: 0.6295197606086731 Acc: 0.78125
Train Iteration #20400:: 0.7200060486793518 Acc: 0.75
Train Iteration #20450:: 0.6182299852371216 Acc: 0.71875
Train Iteration #20500:: 0.7397931814193726 Acc: 0.6875
Training:: Loss: 0.7747 Acc: 0.7140
Validation Iteration #5150:: 0.6864522695541382 Acc: 0.625
Validation:: Loss: 0.7824 Acc: 0.5911
Epoch 64/99
----------
Train Iteration #20550:: 0.6791763305664062 Acc: 0.71875
Train Iteration #20600:: 0.8898072242736816 Acc: 0.625
Train Iteration #20650:: 0.8699861764907837 Acc: 0.71875
Train Iteration #20700:: 0.7832928895950317 Acc: 0.71875
Train Iteration #20750:: 0.6081703305244446 Acc: 0.71875
Train Iteration #20800:: 0.8295835852622986 Acc: 0.65625
Train Iteration #20850:: 0.7365404367446899 Acc: 0.8125
Training:: Loss: 0.7894 Acc: 0.7048
Validation Iteration #5200:: 0.3839718699455261 Acc: 0.78125
Validation Iteration #5250:: 0.4826655685901642 Acc: 0.90625
Validation:: Loss: 0.5350 Acc: 0.7858
Epoch 65/99
----------
Train Iteration #20900:: 0.902173638343811 Acc: 0.65625
Train Iteration #20950:: 0.5166415572166443 Acc: 0.71875
Train Iteration #21000:: 0.935828685760498 Acc: 0.75
Train Iteration #21050:: 0.7581624984741211 Acc: 0.625
Train Iteration #21100:: 0.9724112749099731 Acc: 0.5625
Train Iteration #21150:: 0.5661873817443848 Acc: 0.875
Training:: Loss: 0.7865 Acc: 0.7083
Validation Iteration #5300:: 0.5482000708580017 Acc: 0.75
Validation:: Loss: 0.5082 Acc: 0.8123
Epoch 66/99
----------
Train Iteration #21200:: 0.5899478197097778 Acc: 0.8125
Train Iteration #21250:: 0.9335286617279053 Acc: 0.71875
Train Iteration #21300:: 0.9023253917694092 Acc: 0.8125
Train Iteration #21350:: 0.7646312117576599 Acc: 0.53125
Train Iteration #21400:: 0.6560581922531128 Acc: 0.84375
Train Iteration #21450:: 0.9531639814376831 Acc: 0.59375
Train Iteration #21500:: 0.8159377574920654 Acc: 0.71875
Training:: Loss: 0.7758 Acc: 0.7097
Validation Iteration #5350:: 0.4590091407299042 Acc: 0.90625
Validation Iteration #5400:: 0.5217593312263489 Acc: 0.84375
Validation:: Loss: 0.4905 Acc: 0.8790
Epoch 67/99
----------
Train Iteration #21550:: 0.8207573890686035 Acc: 0.6875
Train Iteration #21600:: 0.9749359488487244 Acc: 0.75
Train Iteration #21650:: 0.7924479246139526 Acc: 0.6875
Train Iteration #21700:: 0.541081428527832 Acc: 0.8125
Train Iteration #21750:: 0.5864496231079102 Acc: 0.78125
Train Iteration #21800:: 0.5957319736480713 Acc: 0.875
Training:: Loss: 0.7949 Acc: 0.7007
Validation Iteration #5450:: 0.5625183582305908 Acc: 0.6875
Validation Iteration #5500:: 0.5222426652908325 Acc: 0.78125
Validation:: Loss: 0.5628 Acc: 0.7589
Epoch 68/99
----------
Train Iteration #21850:: 0.8736682534217834 Acc: 0.65625
Train Iteration #21900:: 1.0181512832641602 Acc: 0.65625
Train Iteration #21950:: 0.7295659780502319 Acc: 0.71875
Train Iteration #22000:: 0.8981449604034424 Acc: 0.59375
Train Iteration #22050:: 0.7358176708221436 Acc: 0.71875
Train Iteration #22100:: 0.8815853595733643 Acc: 0.78125
Training:: Loss: 0.7669 Acc: 0.7154
Validation Iteration #5550:: 0.6432960033416748 Acc: 0.625
Validation:: Loss: 0.5708 Acc: 0.7487
Epoch 69/99
----------
Train Iteration #22150:: 1.0942323207855225 Acc: 0.4375
Train Iteration #22200:: 0.8249082565307617 Acc: 0.65625
Train Iteration #22250:: 0.7869656085968018 Acc: 0.6875
Train Iteration #22300:: 0.9185805320739746 Acc: 0.65625
Train Iteration #22350:: 0.9860794544219971 Acc: 0.625
Train Iteration #22400:: 0.5711949467658997 Acc: 0.84375
Train Iteration #22450:: 1.0103462934494019 Acc: 0.5625
Training:: Loss: 0.7809 Acc: 0.7051
Validation Iteration #5600:: 0.45618686079978943 Acc: 0.875
Validation Iteration #5650:: 0.4377138018608093 Acc: 0.9375
Validation:: Loss: 0.5175 Acc: 0.8041
Epoch 70/99
----------
Train Iteration #22500:: 0.5848339796066284 Acc: 0.875
Train Iteration #22550:: 0.6687695384025574 Acc: 0.71875
Train Iteration #22600:: 0.5916503667831421 Acc: 0.78125
Train Iteration #22650:: 0.9453155994415283 Acc: 0.71875
Train Iteration #22700:: 0.6878196001052856 Acc: 0.78125
Train Iteration #22750:: 0.6460608243942261 Acc: 0.78125
Training:: Loss: 0.7886 Acc: 0.7078
Validation Iteration #5700:: 0.513026237487793 Acc: 0.71875
Validation Iteration #5750:: 0.3966515064239502 Acc: 1.0
Validation:: Loss: 0.6479 Acc: 0.6781
Epoch 71/99
----------
Train Iteration #22800:: 0.6327905058860779 Acc: 0.78125
Train Iteration #22850:: 0.840985894203186 Acc: 0.59375
Train Iteration #22900:: 0.8325483798980713 Acc: 0.6875
Train Iteration #22950:: 0.7353432774543762 Acc: 0.6875
Train Iteration #23000:: 0.7702232599258423 Acc: 0.6875
Train Iteration #23050:: 0.7627847790718079 Acc: 0.65625
Train Iteration #23100:: 0.5412894487380981 Acc: 0.78125
Training:: Loss: 0.7729 Acc: 0.7141
Validation Iteration #5800:: 0.398642361164093 Acc: 0.84375
Validation:: Loss: 0.5438 Acc: 0.7721
Epoch 72/99
----------
Train Iteration #23150:: 0.5417993664741516 Acc: 0.84375
Train Iteration #23200:: 0.6028627157211304 Acc: 0.78125
Train Iteration #23250:: 0.7136116027832031 Acc: 0.65625
Train Iteration #23300:: 0.5087587237358093 Acc: 0.75
Train Iteration #23350:: 0.9809638857841492 Acc: 0.65625
Train Iteration #23400:: 0.7859350442886353 Acc: 0.78125
Training:: Loss: 0.7755 Acc: 0.7092
Validation Iteration #5850:: 0.37666386365890503 Acc: 0.90625
Validation Iteration #5900:: 0.48922884464263916 Acc: 0.75
Validation:: Loss: 0.5119 Acc: 0.8112
Epoch 73/99
----------
Train Iteration #23450:: 0.9060067534446716 Acc: 0.71875
Train Iteration #23500:: 0.49725645780563354 Acc: 0.78125
Train Iteration #23550:: 0.9277060031890869 Acc: 0.5625
Train Iteration #23600:: 0.723310649394989 Acc: 0.75
Train Iteration #23650:: 0.8262178897857666 Acc: 0.65625
Train Iteration #23700:: 0.8848550319671631 Acc: 0.625
Train Iteration #23750:: 0.8165756464004517 Acc: 0.75
Training:: Loss: 0.7793 Acc: 0.7114
Validation Iteration #5950:: 0.6063820123672485 Acc: 0.6875
Validation:: Loss: 0.7132 Acc: 0.6352
Epoch 74/99
----------
Train Iteration #23800:: 0.8512535691261292 Acc: 0.65625
Train Iteration #23850:: 0.5364949703216553 Acc: 0.875
Train Iteration #23900:: 0.8632240891456604 Acc: 0.65625
Train Iteration #23950:: 0.7601919174194336 Acc: 0.625
Train Iteration #24000:: 0.5124784111976624 Acc: 0.8125
Train Iteration #24050:: 0.8979726433753967 Acc: 0.65625
Training:: Loss: 0.7792 Acc: 0.7067
Validation Iteration #6000:: 0.4863760769367218 Acc: 0.84375
Validation Iteration #6050:: 0.6076187491416931 Acc: 0.75
Validation:: Loss: 0.6123 Acc: 0.7109
Epoch 75/99
----------
Train Iteration #24100:: 0.8866913914680481 Acc: 0.5
Train Iteration #24150:: 1.063482403755188 Acc: 0.53125
Train Iteration #24200:: 0.6940319538116455 Acc: 0.78125
Train Iteration #24250:: 0.5579240322113037 Acc: 0.78125
Train Iteration #24300:: 0.5471842288970947 Acc: 0.875
Train Iteration #24350:: 0.6276015043258667 Acc: 0.84375
Training:: Loss: 0.7733 Acc: 0.7073
Validation Iteration #6100:: 0.7129005193710327 Acc: 0.65625
Validation Iteration #6150:: 0.6806554794311523 Acc: 0.6875
Validation:: Loss: 0.5731 Acc: 0.7440
Epoch 76/99
----------
Train Iteration #24400:: 0.9472284913063049 Acc: 0.78125
Train Iteration #24450:: 0.5575087070465088 Acc: 0.71875
Train Iteration #24500:: 0.6377297043800354 Acc: 0.75
Train Iteration #24550:: 0.5436040163040161 Acc: 0.875
Train Iteration #24600:: 0.7554029822349548 Acc: 0.71875
Train Iteration #24650:: 0.6573059558868408 Acc: 0.71875
Train Iteration #24700:: 0.5667831897735596 Acc: 0.875
Training:: Loss: 0.7956 Acc: 0.7064
Validation Iteration #6200:: 0.5268024206161499 Acc: 0.8125
Validation:: Loss: 0.5259 Acc: 0.7905
Epoch 77/99
----------
Train Iteration #24750:: 0.7865628004074097 Acc: 0.65625
Train Iteration #24800:: 0.8156198859214783 Acc: 0.71875
Train Iteration #24850:: 0.9966417551040649 Acc: 0.59375
Train Iteration #24900:: 0.6161081790924072 Acc: 0.84375
Train Iteration #24950:: 0.8583192825317383 Acc: 0.6875
Train Iteration #25000:: 0.630964994430542 Acc: 0.71875
Training:: Loss: 0.7710 Acc: 0.7106
Validation Iteration #6250:: 0.5393581390380859 Acc: 0.8125
Validation Iteration #6300:: 0.8459570407867432 Acc: 0.53125
Validation:: Loss: 0.7352 Acc: 0.6196
Epoch 78/99
----------
Train Iteration #25050:: 0.5805670619010925 Acc: 0.84375
Train Iteration #25100:: 0.7830996513366699 Acc: 0.65625
Train Iteration #25150:: 0.7951374053955078 Acc: 0.59375
Train Iteration #25200:: 0.688083827495575 Acc: 0.6875
Train Iteration #25250:: 0.8261274099349976 Acc: 0.75
Train Iteration #25300:: 0.8515630960464478 Acc: 0.71875
Train Iteration #25350:: 0.6346918344497681 Acc: 0.75
Training:: Loss: 0.7847 Acc: 0.7103
Validation Iteration #6350:: 0.6999117136001587 Acc: 0.6875
Validation:: Loss: 0.5126 Acc: 0.8084
Epoch 79/99
----------
Train Iteration #25400:: 0.8995158672332764 Acc: 0.71875
Train Iteration #25450:: 0.7497284412384033 Acc: 0.8125
Train Iteration #25500:: 0.5725923180580139 Acc: 0.625
Train Iteration #25550:: 0.7205994129180908 Acc: 0.65625
Train Iteration #25600:: 0.731575608253479 Acc: 0.71875
Train Iteration #25650:: 0.8485137224197388 Acc: 0.6875
Training:: Loss: 0.7959 Acc: 0.6992
Validation Iteration #6400:: 0.47489672899246216 Acc: 0.71875
Validation Iteration #6450:: 0.6216187477111816 Acc: 0.75
Validation:: Loss: 0.5550 Acc: 0.7600
Epoch 80/99
----------
Train Iteration #25700:: 0.661867618560791 Acc: 0.75
Train Iteration #25750:: 0.7729722261428833 Acc: 0.71875
Train Iteration #25800:: 0.6205690503120422 Acc: 0.75
Train Iteration #25850:: 0.7050732374191284 Acc: 0.8125
Train Iteration #25900:: 0.8574715256690979 Acc: 0.78125
Train Iteration #25950:: 0.9382990002632141 Acc: 0.6875
Train Iteration #26000:: 0.5532485246658325 Acc: 0.6666666666666666
Training:: Loss: 0.7620 Acc: 0.7121
Validation Iteration #6500:: 0.7832421064376831 Acc: 0.59375
Validation Iteration #6550:: 0.5842210650444031 Acc: 0.78125
Validation:: Loss: 0.6277 Acc: 0.6961
Epoch 81/99
----------
Train Iteration #26050:: 0.6608433723449707 Acc: 0.6875
Train Iteration #26100:: 0.791873574256897 Acc: 0.71875
Train Iteration #26150:: 0.9572903513908386 Acc: 0.71875
Train Iteration #26200:: 0.8922501802444458 Acc: 0.5625
Train Iteration #26250:: 0.5054495334625244 Acc: 0.84375
Train Iteration #26300:: 0.6892101764678955 Acc: 0.6875
Training:: Loss: 0.7785 Acc: 0.7137
Validation Iteration #6600:: 0.46223610639572144 Acc: 0.8125
Validation:: Loss: 0.5210 Acc: 0.7956
Epoch 82/99
----------
Train Iteration #26350:: 1.193196415901184 Acc: 0.71875
Train Iteration #26400:: 0.9062029123306274 Acc: 0.53125
Train Iteration #26450:: 0.7407653331756592 Acc: 0.8125
Train Iteration #26500:: 0.9293994903564453 Acc: 0.84375
Train Iteration #26550:: 0.8107268810272217 Acc: 0.84375
Train Iteration #26600:: 0.7139962911605835 Acc: 0.78125
Training:: Loss: 0.7816 Acc: 0.7101
Validation Iteration #6650:: 0.4428201913833618 Acc: 0.8125
Validation Iteration #6700:: 0.5133711099624634 Acc: 0.75
Validation:: Loss: 0.5786 Acc: 0.7394
Epoch 83/99
----------
Train Iteration #26650:: 0.645810604095459 Acc: 0.84375
Train Iteration #26700:: 1.1740741729736328 Acc: 0.59375
Train Iteration #26750:: 0.6922476291656494 Acc: 0.75
Train Iteration #26800:: 0.8633619546890259 Acc: 0.59375
Train Iteration #26850:: 0.5570245981216431 Acc: 0.8125
Train Iteration #26900:: 1.1370929479599 Acc: 0.5625
Train Iteration #26950:: 0.6779748797416687 Acc: 0.78125
Training:: Loss: 0.7912 Acc: 0.7068
Validation Iteration #6750:: 0.4044997990131378 Acc: 0.84375
Validation Iteration #6800:: 0.6295844912528992 Acc: 0.75
Validation:: Loss: 0.4925 Acc: 0.8330
Epoch 84/99
----------
Train Iteration #27000:: 0.8496825098991394 Acc: 0.5625
Train Iteration #27050:: 0.5708592534065247 Acc: 0.78125
Train Iteration #27100:: 0.7204498648643494 Acc: 0.75
Train Iteration #27150:: 0.8628334999084473 Acc: 0.6875
Train Iteration #27200:: 1.0210235118865967 Acc: 0.65625
Train Iteration #27250:: 0.8484386205673218 Acc: 0.65625
Training:: Loss: 0.7922 Acc: 0.7048
Validation Iteration #6850:: 0.4918522834777832 Acc: 0.84375
Validation:: Loss: 0.5310 Acc: 0.7827
Epoch 85/99
----------
Train Iteration #27300:: 0.5784577131271362 Acc: 0.84375
Train Iteration #27350:: 0.9656401872634888 Acc: 0.59375
Train Iteration #27400:: 0.6932568550109863 Acc: 0.71875
Train Iteration #27450:: 0.690176248550415 Acc: 0.6875
Train Iteration #27500:: 0.572177529335022 Acc: 0.75
Train Iteration #27550:: 0.9664524793624878 Acc: 0.625
Train Iteration #27600:: 0.8561275005340576 Acc: 0.71875
Training:: Loss: 0.7946 Acc: 0.7027
Validation Iteration #6900:: 0.6021756529808044 Acc: 0.75
Validation Iteration #6950:: 0.45216238498687744 Acc: 0.78125
Validation:: Loss: 0.5014 Acc: 0.8225
Epoch 86/99
----------
Train Iteration #27650:: 1.0276108980178833 Acc: 0.71875
Train Iteration #27700:: 0.7769098281860352 Acc: 0.59375
Train Iteration #27750:: 0.8847246170043945 Acc: 0.625
Train Iteration #27800:: 0.9844009876251221 Acc: 0.625
Train Iteration #27850:: 1.1520907878875732 Acc: 0.59375
Train Iteration #27900:: 0.5436000227928162 Acc: 0.8125
Training:: Loss: 0.7852 Acc: 0.7024
Validation Iteration #7000:: 0.5675512552261353 Acc: 0.71875
Validation:: Loss: 0.5330 Acc: 0.7877
Epoch 87/99
----------
Train Iteration #27950:: 0.802815854549408 Acc: 0.625
Train Iteration #28000:: 0.7073471546173096 Acc: 0.78125
Train Iteration #28050:: 0.7552145719528198 Acc: 0.78125
Train Iteration #28100:: 1.0153311491012573 Acc: 0.46875
Train Iteration #28150:: 0.852414608001709 Acc: 0.6875
Train Iteration #28200:: 0.5157171487808228 Acc: 0.71875
Training:: Loss: 0.7685 Acc: 0.7097
Validation Iteration #7050:: 0.8994388580322266 Acc: 0.5625
Validation Iteration #7100:: 0.8494688272476196 Acc: 0.59375
Validation:: Loss: 0.7673 Acc: 0.6083
Epoch 88/99
----------
Train Iteration #28250:: 0.7540712356567383 Acc: 0.53125
Train Iteration #28300:: 0.805436372756958 Acc: 0.625
Train Iteration #28350:: 0.6539186239242554 Acc: 0.75
Train Iteration #28400:: 0.9848586916923523 Acc: 0.53125
Train Iteration #28450:: 0.6243563890457153 Acc: 0.75
Train Iteration #28500:: 0.7442789077758789 Acc: 0.78125
Train Iteration #28550:: 0.7821435928344727 Acc: 0.71875
Training:: Loss: 0.7918 Acc: 0.7004
Validation Iteration #7150:: 0.7705972194671631 Acc: 0.59375
Validation Iteration #7200:: 0.5444227457046509 Acc: 0.8125
Validation:: Loss: 0.6977 Acc: 0.6473
Epoch 89/99
----------
Train Iteration #28600:: 0.7681350708007812 Acc: 0.78125
Train Iteration #28650:: 0.5545858144760132 Acc: 0.875
Train Iteration #28700:: 0.7464951276779175 Acc: 0.75
Train Iteration #28750:: 0.5003519058227539 Acc: 0.8125
Train Iteration #28800:: 0.876602053642273 Acc: 0.59375
Train Iteration #28850:: 0.7338044047355652 Acc: 0.8125
Training:: Loss: 0.7852 Acc: 0.7050
Validation Iteration #7250:: 0.8106622695922852 Acc: 0.59375
Validation:: Loss: 0.7604 Acc: 0.6001
Epoch 90/99
----------
Train Iteration #28900:: 0.6176122426986694 Acc: 0.875
Train Iteration #28950:: 0.9433542490005493 Acc: 0.71875
Train Iteration #29000:: 0.6183512210845947 Acc: 0.78125
Train Iteration #29050:: 0.614630937576294 Acc: 0.71875
Train Iteration #29100:: 0.6030175685882568 Acc: 0.78125
Train Iteration #29150:: 0.8268482089042664 Acc: 0.65625
Train Iteration #29200:: 0.891040563583374 Acc: 0.71875
Training:: Loss: 0.7730 Acc: 0.7151
Validation Iteration #7300:: 0.5004184246063232 Acc: 0.84375
Validation Iteration #7350:: 0.3813163638114929 Acc: 0.90625
Validation:: Loss: 0.5263 Acc: 0.8002
Epoch 91/99
----------
Train Iteration #29250:: 0.702733039855957 Acc: 0.75
Train Iteration #29300:: 0.5185531377792358 Acc: 0.875
Train Iteration #29350:: 0.4442536234855652 Acc: 0.9375
Train Iteration #29400:: 0.8556064367294312 Acc: 0.65625
Train Iteration #29450:: 0.8117423057556152 Acc: 0.625
Train Iteration #29500:: 0.6432254314422607 Acc: 0.6875
Training:: Loss: 0.7665 Acc: 0.7122
Validation Iteration #7400:: 0.5424771904945374 Acc: 0.8125
Validation Iteration #7450:: 0.6254105567932129 Acc: 0.6875
Validation:: Loss: 0.5849 Acc: 0.7312
Epoch 92/99
----------
Train Iteration #29550:: 0.5240447521209717 Acc: 0.8125
Train Iteration #29600:: 0.770647406578064 Acc: 0.8125
Train Iteration #29650:: 1.0871658325195312 Acc: 0.53125
Train Iteration #29700:: 0.7325901389122009 Acc: 0.625
Train Iteration #29750:: 0.8164892196655273 Acc: 0.625
Train Iteration #29800:: 0.7356810569763184 Acc: 0.65625
Train Iteration #29850:: 0.9545215368270874 Acc: 0.75
Training:: Loss: 0.7536 Acc: 0.7221
Validation Iteration #7500:: 0.7171680927276611 Acc: 0.75
Validation:: Loss: 0.5236 Acc: 0.7987
Epoch 93/99
----------
Train Iteration #29900:: 0.5294442176818848 Acc: 0.75
Train Iteration #29950:: 0.7419053316116333 Acc: 0.71875
Train Iteration #30000:: 0.6956765055656433 Acc: 0.75
Train Iteration #30050:: 0.6481976509094238 Acc: 0.75
Train Iteration #30100:: 0.6269992589950562 Acc: 0.71875
Train Iteration #30150:: 0.6460955739021301 Acc: 0.8125
Training:: Loss: 0.7795 Acc: 0.7067
Validation Iteration #7550:: 0.8131129145622253 Acc: 0.5625
Validation Iteration #7600:: 0.712407648563385 Acc: 0.59375
Validation:: Loss: 0.7309 Acc: 0.6278
Epoch 94/99
----------
Train Iteration #30200:: 0.8958581686019897 Acc: 0.65625
Train Iteration #30250:: 0.808358907699585 Acc: 0.71875
Train Iteration #30300:: 0.8476556539535522 Acc: 0.625
Train Iteration #30350:: 0.7194744348526001 Acc: 0.59375
Train Iteration #30400:: 0.5339652299880981 Acc: 0.8125
Train Iteration #30450:: 0.8136788606643677 Acc: 0.625
Training:: Loss: 0.7738 Acc: 0.7141
Validation Iteration #7650:: 0.5267776250839233 Acc: 0.84375
Validation:: Loss: 0.5099 Acc: 0.8178
Epoch 95/99
----------
Train Iteration #30500:: 0.9261758327484131 Acc: 0.65625
Train Iteration #30550:: 0.961246132850647 Acc: 0.53125
Train Iteration #30600:: 0.821546196937561 Acc: 0.71875
Train Iteration #30650:: 0.5557236671447754 Acc: 0.78125
Train Iteration #30700:: 0.9455689191818237 Acc: 0.59375
Train Iteration #30750:: 0.7930523157119751 Acc: 0.5625
Train Iteration #30800:: 0.7280865907669067 Acc: 0.78125
Training:: Loss: 0.7867 Acc: 0.7088
Validation Iteration #7700:: 0.8672986030578613 Acc: 0.5625
Validation Iteration #7750:: 0.6619645357131958 Acc: 0.65625
Validation:: Loss: 0.6170 Acc: 0.7070
Epoch 96/99
----------
Train Iteration #30850:: 0.5542190670967102 Acc: 0.875
Train Iteration #30900:: 0.7624001502990723 Acc: 0.625
Train Iteration #30950:: 0.6351840496063232 Acc: 0.75
Train Iteration #31000:: 1.0225244760513306 Acc: 0.75
Train Iteration #31050:: 0.7209802269935608 Acc: 0.6875
Train Iteration #31100:: 0.851164698600769 Acc: 0.6875
Training:: Loss: 0.7942 Acc: 0.7019
Validation Iteration #7800:: 0.8342638611793518 Acc: 0.53125
Validation Iteration #7850:: 0.6696223020553589 Acc: 0.65625
Validation:: Loss: 0.6893 Acc: 0.6473
Epoch 97/99
----------
Train Iteration #31150:: 0.7023476362228394 Acc: 0.78125
Train Iteration #31200:: 0.8181278705596924 Acc: 0.71875
Train Iteration #31250:: 0.8751507997512817 Acc: 0.75
Train Iteration #31300:: 0.6857495903968811 Acc: 0.8125
Train Iteration #31350:: 1.0564162731170654 Acc: 0.71875
Train Iteration #31400:: 0.7488853931427002 Acc: 0.75
Train Iteration #31450:: 0.9458006620407104 Acc: 0.625
Training:: Loss: 0.7648 Acc: 0.7145
Validation Iteration #7900:: 0.6491343975067139 Acc: 0.625
Validation:: Loss: 0.5639 Acc: 0.7480
Epoch 98/99
----------
Train Iteration #31500:: 0.7550808191299438 Acc: 0.71875
Train Iteration #31550:: 0.8909841775894165 Acc: 0.625
Train Iteration #31600:: 0.5302873849868774 Acc: 0.75
Train Iteration #31650:: 0.9475364089012146 Acc: 0.6875
Train Iteration #31700:: 0.7651888132095337 Acc: 0.6875
Train Iteration #31750:: 1.1463185548782349 Acc: 0.5625
Training:: Loss: 0.7652 Acc: 0.7171
Validation Iteration #7950:: 0.8451633453369141 Acc: 0.625
Validation Iteration #8000:: 0.4711971879005432 Acc: 0.84375
Validation:: Loss: 0.5077 Acc: 0.8112
Epoch 99/99
----------
Train Iteration #31800:: 0.7494618892669678 Acc: 0.75
Train Iteration #31850:: 0.5672646760940552 Acc: 0.71875
Train Iteration #31900:: 0.7542396187782288 Acc: 0.65625
Train Iteration #31950:: 0.7265332341194153 Acc: 0.78125
Train Iteration #32000:: 0.5166198015213013 Acc: 0.875
Train Iteration #32050:: 0.8923479318618774 Acc: 0.6875
Training:: Loss: 0.7712 Acc: 0.7182
Validation Iteration #8050:: 0.5986469388008118 Acc: 0.71875
Validation:: Loss: 0.5158 Acc: 0.8041
Best Validation Acc: 0.879048
End time:10:20:01.782272
Program Complete
Average Train Loss:0.7820150799142911
Average Validation Loss:0.6052815471052937
Average Train Accuracy:0.7057891143191575
Average Validation Accuracy:0.7270854467420992
