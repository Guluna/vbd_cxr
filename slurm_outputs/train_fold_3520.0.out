Cerberus running for fold: 0
cuda
Program started
Epoch 0/49
----------
Train Iteration #0:: 1.2456707954406738 Acc: 0.40625
Train Iteration #50:: 1.0457415580749512 Acc: 0.4375
Train Iteration #100:: 0.9882764220237732 Acc: 0.28125
Train Iteration #150:: 0.7395642995834351 Acc: 0.5625
Train Iteration #200:: 0.7234547138214111 Acc: 0.6875
Train Iteration #250:: 0.7262610793113708 Acc: 0.625
Train Iteration #300:: 0.5699114203453064 Acc: 0.875
Training:: Loss: 0.8599 Acc: 0.5810
Validation Iteration #0:: 0.6167861223220825 Acc: 0.75
Validation Iteration #50:: 0.6563477516174316 Acc: 0.71875
Validation:: Loss: 0.7149 Acc: 0.7167
Epoch 1/49
----------
Train Iteration #350:: 0.6892441511154175 Acc: 0.84375
Train Iteration #400:: 0.6475397348403931 Acc: 0.6875
Train Iteration #450:: 0.694260835647583 Acc: 0.8125
Train Iteration #500:: 0.5671889781951904 Acc: 0.71875
Train Iteration #550:: 0.5585134029388428 Acc: 0.75
Train Iteration #600:: 0.44048547744750977 Acc: 0.90625
Training:: Loss: 0.6592 Acc: 0.7501
Validation Iteration #100:: 0.4774716794490814 Acc: 0.875
Validation Iteration #150:: 0.7772634029388428 Acc: 0.8125
Validation:: Loss: 0.5983 Acc: 0.8275
Epoch 2/49
----------
Train Iteration #650:: 0.6745689511299133 Acc: 0.71875
Train Iteration #700:: 0.56455397605896 Acc: 0.8125
Train Iteration #750:: 0.7979405522346497 Acc: 0.78125
Train Iteration #800:: 0.4690974950790405 Acc: 0.90625
Train Iteration #850:: 0.5383138656616211 Acc: 0.84375
Train Iteration #900:: 0.4197879731655121 Acc: 0.75
Train Iteration #950:: 0.5153297185897827 Acc: 0.84375
Training:: Loss: 0.5917 Acc: 0.7921
Validation Iteration #200:: 0.6502029895782471 Acc: 0.75
Validation:: Loss: 0.5963 Acc: 0.7663
Epoch 3/49
----------
Train Iteration #1000:: 0.4703558087348938 Acc: 0.90625
Train Iteration #1050:: 0.5556478500366211 Acc: 0.8125
Train Iteration #1100:: 0.5066999793052673 Acc: 0.84375
Train Iteration #1150:: 0.5699625015258789 Acc: 0.75
Train Iteration #1200:: 0.4807012379169464 Acc: 0.75
Train Iteration #1250:: 0.47707319259643555 Acc: 0.8125
Training:: Loss: 0.5538 Acc: 0.8156
Validation Iteration #250:: 0.5947729349136353 Acc: 0.6875
Validation Iteration #300:: 0.6099832057952881 Acc: 0.65625
Validation:: Loss: 0.6218 Acc: 0.7206
Epoch 4/49
----------
Train Iteration #1300:: 0.628717303276062 Acc: 0.71875
Train Iteration #1350:: 0.6179024577140808 Acc: 0.78125
Train Iteration #1400:: 0.4560824930667877 Acc: 0.875
Train Iteration #1450:: 0.4627572000026703 Acc: 0.84375
Train Iteration #1500:: 0.4351276755332947 Acc: 0.90625
Train Iteration #1550:: 0.3775193393230438 Acc: 0.84375
Train Iteration #1600:: 0.459307461977005 Acc: 0.84375
Training:: Loss: 0.5185 Acc: 0.8308
Validation Iteration #350:: 0.5935255289077759 Acc: 0.59375
Validation Iteration #400:: 0.32968735694885254 Acc: 0.9375
Validation:: Loss: 0.5143 Acc: 0.8268
Epoch 5/49
----------
Train Iteration #1650:: 0.5714789628982544 Acc: 0.8125
Train Iteration #1700:: 0.7322611808776855 Acc: 0.71875
Train Iteration #1750:: 0.6623097062110901 Acc: 0.8125
Train Iteration #1800:: 0.49747979640960693 Acc: 0.875
Train Iteration #1850:: 0.5009753704071045 Acc: 0.8125
Train Iteration #1900:: 0.5270206928253174 Acc: 0.84375
Training:: Loss: 0.5147 Acc: 0.8329
Validation Iteration #450:: 0.5196956992149353 Acc: 0.8125
Validation:: Loss: 0.5772 Acc: 0.7538
Epoch 6/49
----------
Train Iteration #1950:: 0.5681165456771851 Acc: 0.75
Train Iteration #2000:: 0.3773219585418701 Acc: 0.9375
Train Iteration #2050:: 0.48362836241722107 Acc: 0.84375
Train Iteration #2100:: 0.6028611660003662 Acc: 0.65625
Train Iteration #2150:: 0.4193897247314453 Acc: 0.875
Train Iteration #2200:: 0.5012139081954956 Acc: 0.75
Training:: Loss: 0.4918 Acc: 0.8422
Validation Iteration #500:: 0.7492325305938721 Acc: 0.71875
Validation Iteration #550:: 0.5094519257545471 Acc: 0.8125
Validation:: Loss: 0.5254 Acc: 0.8010
Epoch 7/49
----------
Train Iteration #2250:: 0.22120076417922974 Acc: 1.0
Train Iteration #2300:: 0.3626801371574402 Acc: 0.9375
Train Iteration #2350:: 0.5238056182861328 Acc: 0.65625
Train Iteration #2400:: 0.4163599908351898 Acc: 0.8125
Train Iteration #2450:: 0.4362081289291382 Acc: 0.90625
Train Iteration #2500:: 0.578937292098999 Acc: 0.9375
Train Iteration #2550:: 0.6434385776519775 Acc: 0.6875
Training:: Loss: 0.4897 Acc: 0.8421
Validation Iteration #600:: 0.44112083315849304 Acc: 0.84375
Validation:: Loss: 0.4759 Acc: 0.8580
Epoch 8/49
----------
Train Iteration #2600:: 0.4652591347694397 Acc: 0.84375
Train Iteration #2650:: 0.703384518623352 Acc: 0.6875
Train Iteration #2700:: 0.4365687072277069 Acc: 0.84375
Train Iteration #2750:: 0.42252790927886963 Acc: 0.84375
Train Iteration #2800:: 0.38414689898490906 Acc: 0.875
Train Iteration #2850:: 0.6180517673492432 Acc: 0.78125
Training:: Loss: 0.4762 Acc: 0.8439
Validation Iteration #650:: 0.3973761796951294 Acc: 0.84375
Validation Iteration #700:: 0.6968423128128052 Acc: 0.75
Validation:: Loss: 0.4767 Acc: 0.8424
Epoch 9/49
----------
Train Iteration #2900:: 0.35553306341171265 Acc: 0.875
Train Iteration #2950:: 0.4406479001045227 Acc: 0.84375
Train Iteration #3000:: 0.44344383478164673 Acc: 0.84375
Train Iteration #3050:: 0.3522118330001831 Acc: 0.9375
Train Iteration #3100:: 0.5539895296096802 Acc: 0.6875
Train Iteration #3150:: 0.3256581425666809 Acc: 0.96875
Train Iteration #3200:: 0.5689289569854736 Acc: 0.71875
Training:: Loss: 0.4546 Acc: 0.8523
Validation Iteration #750:: 0.7147949934005737 Acc: 0.75
Validation Iteration #800:: 0.4102925956249237 Acc: 0.8125
Validation:: Loss: 0.4761 Acc: 0.8369
Epoch 10/49
----------
Train Iteration #3250:: 0.3365616500377655 Acc: 0.96875
Train Iteration #3300:: 0.553195595741272 Acc: 0.84375
Train Iteration #3350:: 0.6298636198043823 Acc: 0.71875
Train Iteration #3400:: 0.8029810190200806 Acc: 0.84375
Train Iteration #3450:: 0.45607292652130127 Acc: 0.84375
Train Iteration #3500:: 0.3889894485473633 Acc: 0.96875
Training:: Loss: 0.4638 Acc: 0.8518
Validation Iteration #850:: 0.3253355622291565 Acc: 0.90625
Validation:: Loss: 0.4670 Acc: 0.8533
Epoch 11/49
----------
Train Iteration #3550:: 0.2608991265296936 Acc: 0.90625
Train Iteration #3600:: 0.39486056566238403 Acc: 0.875
Train Iteration #3650:: 0.4957864582538605 Acc: 0.78125
Train Iteration #3700:: 0.39527037739753723 Acc: 0.9375
Train Iteration #3750:: 0.32436686754226685 Acc: 0.96875
Train Iteration #3800:: 0.4110173285007477 Acc: 0.875
Train Iteration #3850:: 0.5729142427444458 Acc: 0.75
Training:: Loss: 0.4502 Acc: 0.8569
Validation Iteration #900:: 0.35879647731781006 Acc: 0.84375
Validation Iteration #950:: 0.5861020088195801 Acc: 0.71875
Validation:: Loss: 0.4866 Acc: 0.8221
Epoch 12/49
----------
Train Iteration #3900:: 0.7909782528877258 Acc: 0.78125
Train Iteration #3950:: 0.44915875792503357 Acc: 0.90625
Train Iteration #4000:: 0.44916823506355286 Acc: 0.78125
Train Iteration #4050:: 0.36798515915870667 Acc: 0.84375
Train Iteration #4100:: 0.40001145005226135 Acc: 0.875
Train Iteration #4150:: 0.6239286661148071 Acc: 0.84375
Training:: Loss: 0.4488 Acc: 0.8605
Validation Iteration #1000:: 0.5220176577568054 Acc: 0.8125
Validation Iteration #1050:: 0.40523436665534973 Acc: 0.90625
Validation:: Loss: 0.4568 Acc: 0.8556
Epoch 13/49
----------
Train Iteration #4200:: 0.6261162757873535 Acc: 0.78125
Train Iteration #4250:: 0.7845708131790161 Acc: 0.84375
Train Iteration #4300:: 0.26935315132141113 Acc: 0.96875
Train Iteration #4350:: 0.3678128123283386 Acc: 0.875
Train Iteration #4400:: 0.29097890853881836 Acc: 0.90625
Train Iteration #4450:: 0.3138201832771301 Acc: 0.90625
Training:: Loss: 0.4677 Acc: 0.8472
Validation Iteration #1100:: 0.370471715927124 Acc: 0.84375
Validation:: Loss: 0.4627 Acc: 0.8400
Epoch 14/49
----------
Train Iteration #4500:: 0.31560826301574707 Acc: 0.875
Train Iteration #4550:: 0.40005016326904297 Acc: 0.9375
Train Iteration #4600:: 0.32587629556655884 Acc: 0.90625
Train Iteration #4650:: 0.751471996307373 Acc: 0.875
Train Iteration #4700:: 0.5171759128570557 Acc: 0.9375
Train Iteration #4750:: 0.6099433898925781 Acc: 0.78125
Train Iteration #4800:: 0.32844290137290955 Acc: 0.90625
Training:: Loss: 0.4524 Acc: 0.8538
Validation Iteration #1150:: 0.5089370012283325 Acc: 0.8125
Validation Iteration #1200:: 0.35025548934936523 Acc: 0.875
Validation:: Loss: 0.4660 Acc: 0.8330
Epoch 15/49
----------
Train Iteration #4850:: 0.5241047143936157 Acc: 0.90625
Train Iteration #4900:: 0.35581445693969727 Acc: 0.90625
Train Iteration #4950:: 0.5482994318008423 Acc: 0.8125
Train Iteration #5000:: 0.3921024799346924 Acc: 0.90625
Train Iteration #5050:: 0.40497055649757385 Acc: 0.8125
Train Iteration #5100:: 0.3349721431732178 Acc: 0.875
Training:: Loss: 0.4516 Acc: 0.8584
Validation Iteration #1250:: 0.5536845326423645 Acc: 0.84375
Validation:: Loss: 0.5002 Acc: 0.8084
Epoch 16/49
----------
Train Iteration #5150:: 0.28708964586257935 Acc: 0.96875
Train Iteration #5200:: 0.3224679231643677 Acc: 0.90625
Train Iteration #5250:: 0.3810250163078308 Acc: 0.90625
Train Iteration #5300:: 0.37416037917137146 Acc: 0.84375
Train Iteration #5350:: 0.34193509817123413 Acc: 0.90625
Train Iteration #5400:: 0.31825506687164307 Acc: 0.90625
Train Iteration #5450:: 0.6283287405967712 Acc: 0.78125
Training:: Loss: 0.4347 Acc: 0.8605
Validation Iteration #1300:: 0.5585702657699585 Acc: 0.78125
Validation Iteration #1350:: 0.4518473148345947 Acc: 0.8125
Validation:: Loss: 0.4868 Acc: 0.8162
Epoch 17/49
----------
Train Iteration #5500:: 0.4476119577884674 Acc: 0.84375
Train Iteration #5550:: 0.40732699632644653 Acc: 0.875
Train Iteration #5600:: 0.2907029390335083 Acc: 0.90625
Train Iteration #5650:: 0.5595550537109375 Acc: 0.8125
Train Iteration #5700:: 0.3465433716773987 Acc: 0.875
Train Iteration #5750:: 0.3418065309524536 Acc: 0.78125
Training:: Loss: 0.4328 Acc: 0.8644
Validation Iteration #1400:: 0.47710639238357544 Acc: 0.78125
Validation Iteration #1450:: 0.35960277915000916 Acc: 0.90625
Validation:: Loss: 0.4575 Acc: 0.8408
Epoch 18/49
----------
Train Iteration #5800:: 0.7891809940338135 Acc: 0.8125
Train Iteration #5850:: 0.4028432369232178 Acc: 0.8125
Train Iteration #5900:: 0.27814382314682007 Acc: 0.875
Train Iteration #5950:: 0.49666303396224976 Acc: 0.84375
Train Iteration #6000:: 0.29732316732406616 Acc: 0.9375
Train Iteration #6050:: 0.36444196105003357 Acc: 0.8125
Training:: Loss: 0.4432 Acc: 0.8580
Validation Iteration #1500:: 0.2570973038673401 Acc: 0.96875
Validation:: Loss: 0.4526 Acc: 0.8829
Epoch 19/49
----------
Train Iteration #6100:: 0.5246118903160095 Acc: 0.875
Train Iteration #6150:: 0.47424906492233276 Acc: 0.8125
Train Iteration #6200:: 0.33124542236328125 Acc: 0.84375
Train Iteration #6250:: 0.45858028531074524 Acc: 0.90625
Train Iteration #6300:: 0.6184265613555908 Acc: 0.84375
Train Iteration #6350:: 0.501845121383667 Acc: 0.96875
Train Iteration #6400:: 0.4054590165615082 Acc: 0.8125
Training:: Loss: 0.4489 Acc: 0.8578
Validation Iteration #1550:: 0.4025806784629822 Acc: 0.8125
Validation Iteration #1600:: 0.5207856297492981 Acc: 0.75
Validation:: Loss: 0.5585 Acc: 0.7608
Epoch 20/49
----------
Train Iteration #6450:: 0.49895116686820984 Acc: 0.78125
Train Iteration #6500:: 0.3743261694908142 Acc: 0.8125
Train Iteration #6550:: 0.25591933727264404 Acc: 0.9375
Train Iteration #6600:: 0.29110386967658997 Acc: 0.84375
Train Iteration #6650:: 0.30968403816223145 Acc: 0.8125
Train Iteration #6700:: 0.48931649327278137 Acc: 0.84375
Training:: Loss: 0.4336 Acc: 0.8625
Validation Iteration #1650:: 0.27426695823669434 Acc: 0.90625
Validation Iteration #1700:: 0.1529769003391266 Acc: 1.0
Validation:: Loss: 0.4386 Acc: 0.8787
Epoch 21/49
----------
Train Iteration #6750:: 0.44207078218460083 Acc: 0.84375
Train Iteration #6800:: 0.3149362802505493 Acc: 0.9375
Train Iteration #6850:: 0.23137305676937103 Acc: 0.9375
Train Iteration #6900:: 0.5411625504493713 Acc: 0.78125
Train Iteration #6950:: 0.3870723843574524 Acc: 0.9375
Train Iteration #7000:: 0.46937763690948486 Acc: 0.78125
Train Iteration #7050:: 0.2535725235939026 Acc: 0.90625
Training:: Loss: 0.4237 Acc: 0.8659
Validation Iteration #1750:: 0.5480238199234009 Acc: 0.78125
Validation:: Loss: 0.4393 Acc: 0.8744
Epoch 22/49
----------
Train Iteration #7100:: 0.2663983702659607 Acc: 0.84375
Train Iteration #7150:: 0.6672784090042114 Acc: 0.75
Train Iteration #7200:: 0.5754164457321167 Acc: 0.75
Train Iteration #7250:: 0.37903285026550293 Acc: 0.90625
Train Iteration #7300:: 0.9044042825698853 Acc: 0.78125
Train Iteration #7350:: 0.672675609588623 Acc: 0.8125
Training:: Loss: 0.4342 Acc: 0.8618
Validation Iteration #1800:: 0.4153980016708374 Acc: 0.9375
Validation Iteration #1850:: 0.5768677592277527 Acc: 0.875
Validation:: Loss: 0.4339 Acc: 0.8677
Epoch 23/49
----------
Train Iteration #7400:: 0.40951722860336304 Acc: 0.875
Train Iteration #7450:: 0.4574117958545685 Acc: 0.8125
Train Iteration #7500:: 0.34577125310897827 Acc: 0.875
Train Iteration #7550:: 0.495846152305603 Acc: 0.875
Train Iteration #7600:: 0.5248183012008667 Acc: 0.84375
Train Iteration #7650:: 0.4412307143211365 Acc: 0.75
Train Iteration #7700:: 0.2826516628265381 Acc: 0.875
Training:: Loss: 0.4269 Acc: 0.8640
Validation Iteration #1900:: 0.5684775114059448 Acc: 0.84375
Validation:: Loss: 0.4371 Acc: 0.8712
Epoch 24/49
----------
Train Iteration #7750:: 0.7481594681739807 Acc: 0.75
Train Iteration #7800:: 0.5574827194213867 Acc: 0.78125
Train Iteration #7850:: 0.34945106506347656 Acc: 0.84375
Train Iteration #7900:: 0.4599565267562866 Acc: 0.84375
Train Iteration #7950:: 0.65387362241745 Acc: 0.71875
Train Iteration #8000:: 0.4081462025642395 Acc: 0.8125
Training:: Loss: 0.4236 Acc: 0.8686
Validation Iteration #1950:: 0.3709980845451355 Acc: 0.875
Validation Iteration #2000:: 0.20142079889774323 Acc: 0.96875
Validation:: Loss: 0.4536 Acc: 0.8408
Epoch 25/49
----------
Train Iteration #8050:: 0.33264875411987305 Acc: 0.96875
Train Iteration #8100:: 0.4781751036643982 Acc: 0.84375
Train Iteration #8150:: 0.34224534034729004 Acc: 0.90625
Train Iteration #8200:: 0.3883548974990845 Acc: 0.90625
Train Iteration #8250:: 0.3793397545814514 Acc: 0.84375
Train Iteration #8300:: 0.4053300619125366 Acc: 0.90625
Training:: Loss: 0.4313 Acc: 0.8673
Validation Iteration #2050:: 0.5412798523902893 Acc: 0.84375
Validation Iteration #2100:: 0.5908172130584717 Acc: 0.84375
Validation:: Loss: 0.4609 Acc: 0.8365
Epoch 26/49
----------
Train Iteration #8350:: 0.19545534253120422 Acc: 0.9375
Train Iteration #8400:: 0.5840073823928833 Acc: 0.75
Train Iteration #8450:: 0.28141042590141296 Acc: 0.9375
Train Iteration #8500:: 0.25523045659065247 Acc: 0.90625
Train Iteration #8550:: 0.2777408957481384 Acc: 0.90625
Train Iteration #8600:: 0.20477645099163055 Acc: 0.96875
Train Iteration #8650:: 0.34014520049095154 Acc: 0.90625
Training:: Loss: 0.4123 Acc: 0.8700
Validation Iteration #2150:: 0.31693199276924133 Acc: 0.9375
Validation:: Loss: 0.4545 Acc: 0.8404
Epoch 27/49
----------
Train Iteration #8700:: 0.5340402126312256 Acc: 0.8125
Train Iteration #8750:: 0.7376348972320557 Acc: 0.875
Train Iteration #8800:: 0.5694305896759033 Acc: 0.875
Train Iteration #8850:: 0.7925393581390381 Acc: 0.78125
Train Iteration #8900:: 0.3471393585205078 Acc: 0.8125
Train Iteration #8950:: 0.3361268639564514 Acc: 0.875
Training:: Loss: 0.4217 Acc: 0.8649
Validation Iteration #2200:: 0.576941967010498 Acc: 0.84375
Validation Iteration #2250:: 0.3482626974582672 Acc: 0.90625
Validation:: Loss: 0.4397 Acc: 0.8814
Epoch 28/49
----------
Train Iteration #9000:: 0.6384279727935791 Acc: 0.84375
Train Iteration #9050:: 0.4041372239589691 Acc: 0.9375
Train Iteration #9100:: 0.4575739800930023 Acc: 0.875
Train Iteration #9150:: 0.37905555963516235 Acc: 0.875
Train Iteration #9200:: 0.2958618700504303 Acc: 0.96875
Train Iteration #9250:: 0.25935083627700806 Acc: 0.96875
Train Iteration #9300:: 0.3287891447544098 Acc: 0.90625
Training:: Loss: 0.4242 Acc: 0.8677
Validation Iteration #2300:: 0.26008331775665283 Acc: 0.96875
Validation:: Loss: 0.4323 Acc: 0.8681
Epoch 29/49
----------
Train Iteration #9350:: 0.40484124422073364 Acc: 0.9375
Train Iteration #9400:: 0.5716522932052612 Acc: 0.84375
Train Iteration #9450:: 0.4156862497329712 Acc: 0.8125
Train Iteration #9500:: 0.4366665184497833 Acc: 0.875
Train Iteration #9550:: 0.4281938970088959 Acc: 0.90625
Train Iteration #9600:: 0.2648868262767792 Acc: 0.9375
Training:: Loss: 0.4199 Acc: 0.8686
Validation Iteration #2350:: 0.3196275234222412 Acc: 0.8125
Validation Iteration #2400:: 0.5389624238014221 Acc: 0.8125
Validation:: Loss: 0.4791 Acc: 0.8174
Epoch 30/49
----------
Train Iteration #9650:: 0.40558212995529175 Acc: 0.875
Train Iteration #9700:: 0.3068532347679138 Acc: 0.9375
Train Iteration #9750:: 0.29999101161956787 Acc: 0.9375
Train Iteration #9800:: 0.5465702414512634 Acc: 0.71875
Train Iteration #9850:: 0.485659658908844 Acc: 0.84375
Train Iteration #9900:: 0.2402656078338623 Acc: 0.9375
Train Iteration #9950:: 0.14303043484687805 Acc: 1.0
Training:: Loss: 0.4271 Acc: 0.8644
Validation Iteration #2450:: 0.38584229350090027 Acc: 0.875
Validation Iteration #2500:: 0.5987412929534912 Acc: 0.75
Validation:: Loss: 0.4477 Acc: 0.8432
Epoch 31/49
----------
Train Iteration #10000:: 0.6853029131889343 Acc: 0.84375
Train Iteration #10050:: 0.7141764163970947 Acc: 0.78125
Train Iteration #10100:: 0.49955835938453674 Acc: 0.875
Train Iteration #10150:: 0.39626967906951904 Acc: 0.84375
Train Iteration #10200:: 0.2830043435096741 Acc: 0.9375
Train Iteration #10250:: 0.41828542947769165 Acc: 0.90625
Training:: Loss: 0.4120 Acc: 0.8681
Validation Iteration #2550:: 0.4440751075744629 Acc: 0.78125
Validation:: Loss: 0.4387 Acc: 0.8506
Epoch 32/49
----------
Train Iteration #10300:: 0.5060219168663025 Acc: 0.90625
Train Iteration #10350:: 0.41368168592453003 Acc: 0.90625
Train Iteration #10400:: 0.28067120909690857 Acc: 1.0
Train Iteration #10450:: 0.3907385468482971 Acc: 0.875
Train Iteration #10500:: 0.27730363607406616 Acc: 0.875
Train Iteration #10550:: 0.34647420048713684 Acc: 0.90625
Training:: Loss: 0.4271 Acc: 0.8649
Validation Iteration #2600:: 0.44573214650154114 Acc: 0.8125
Validation Iteration #2650:: 0.6927906274795532 Acc: 0.78125
Validation:: Loss: 0.5087 Acc: 0.7956
Epoch 33/49
----------
Train Iteration #10600:: 0.15049763023853302 Acc: 1.0
Train Iteration #10650:: 0.4863702058792114 Acc: 0.78125
Train Iteration #10700:: 0.3888700008392334 Acc: 0.90625
Train Iteration #10750:: 0.32424068450927734 Acc: 0.90625
Train Iteration #10800:: 0.43600377440452576 Acc: 0.875
Train Iteration #10850:: 0.8128573298454285 Acc: 0.84375
Train Iteration #10900:: 0.41670775413513184 Acc: 0.84375
Training:: Loss: 0.4117 Acc: 0.8720
Validation Iteration #2700:: 0.6698163747787476 Acc: 0.8125
Validation Iteration #2750:: 0.42471495270729065 Acc: 0.875
Validation:: Loss: 0.4512 Acc: 0.8416
Epoch 34/49
----------
Train Iteration #10950:: 0.3913147747516632 Acc: 0.9375
Train Iteration #11000:: 0.511883020401001 Acc: 0.84375
Train Iteration #11050:: 0.38393810391426086 Acc: 0.875
Train Iteration #11100:: 0.5853270292282104 Acc: 0.75
Train Iteration #11150:: 0.33674487471580505 Acc: 0.9375
Train Iteration #11200:: 0.5823326110839844 Acc: 0.84375
Training:: Loss: 0.4031 Acc: 0.8740
Validation Iteration #2800:: 0.2799733579158783 Acc: 0.875
Validation:: Loss: 0.4349 Acc: 0.8545
Epoch 35/49
----------
Train Iteration #11250:: 0.29028552770614624 Acc: 0.875
Train Iteration #11300:: 0.27792373299598694 Acc: 0.9375
Train Iteration #11350:: 0.36123254895210266 Acc: 0.90625
Train Iteration #11400:: 0.3328853249549866 Acc: 0.90625
Train Iteration #11450:: 0.6396998167037964 Acc: 0.875
Train Iteration #11500:: 0.22077703475952148 Acc: 0.9375
Train Iteration #11550:: 0.474959135055542 Acc: 0.875
Training:: Loss: 0.4204 Acc: 0.8694
Validation Iteration #2850:: 0.37892061471939087 Acc: 0.84375
Validation Iteration #2900:: 0.672619640827179 Acc: 0.84375
Validation:: Loss: 0.4304 Acc: 0.8634
Epoch 36/49
----------
Train Iteration #11600:: 0.27817854285240173 Acc: 0.84375
Train Iteration #11650:: 0.7678041458129883 Acc: 0.65625
Train Iteration #11700:: 0.3165454864501953 Acc: 0.90625
Train Iteration #11750:: 0.2534817159175873 Acc: 0.90625
Train Iteration #11800:: 0.35664433240890503 Acc: 0.90625
Train Iteration #11850:: 0.1952359527349472 Acc: 0.9375
Training:: Loss: 0.4104 Acc: 0.8695
Validation Iteration #2950:: 0.2610980272293091 Acc: 0.9375
Validation:: Loss: 0.4347 Acc: 0.8615
Epoch 37/49
----------
Train Iteration #11900:: 0.8025591373443604 Acc: 0.84375
Train Iteration #11950:: 0.21464847028255463 Acc: 0.9375
Train Iteration #12000:: 0.2713751494884491 Acc: 0.96875
Train Iteration #12050:: 0.30807730555534363 Acc: 0.96875
Train Iteration #12100:: 0.6084001064300537 Acc: 0.8125
Train Iteration #12150:: 0.32433605194091797 Acc: 0.9375
Training:: Loss: 0.4119 Acc: 0.8697
Validation Iteration #3000:: 0.5524624586105347 Acc: 0.8125
Validation Iteration #3050:: 0.587890625 Acc: 0.78125
Validation:: Loss: 0.4337 Acc: 0.8568
Epoch 38/49
----------
Train Iteration #12200:: 0.21283110976219177 Acc: 0.9375
Train Iteration #12250:: 0.32008299231529236 Acc: 0.90625
Train Iteration #12300:: 0.43548154830932617 Acc: 0.875
Train Iteration #12350:: 0.22251774370670319 Acc: 0.9375
Train Iteration #12400:: 0.4595319628715515 Acc: 0.9375
Train Iteration #12450:: 0.4831155836582184 Acc: 0.8125
Train Iteration #12500:: 0.4714388847351074 Acc: 0.8125
Training:: Loss: 0.4155 Acc: 0.8696
Validation Iteration #3100:: 0.4359135031700134 Acc: 0.84375
Validation Iteration #3150:: 0.43334221839904785 Acc: 0.9375
Validation:: Loss: 0.4295 Acc: 0.8705
Epoch 39/49
----------
Train Iteration #12550:: 0.3640561103820801 Acc: 0.875
Train Iteration #12600:: 0.41284236311912537 Acc: 0.90625
Train Iteration #12650:: 0.26310646533966064 Acc: 0.9375
Train Iteration #12700:: 0.3552072048187256 Acc: 0.875
Train Iteration #12750:: 0.4959433674812317 Acc: 0.75
Train Iteration #12800:: 0.5171511173248291 Acc: 0.8125
Training:: Loss: 0.4230 Acc: 0.8631
Validation Iteration #3200:: 0.4361877739429474 Acc: 0.84375
Validation:: Loss: 0.4309 Acc: 0.8822
Epoch 40/49
----------
Train Iteration #12850:: 0.27007603645324707 Acc: 0.90625
Train Iteration #12900:: 0.42972368001937866 Acc: 0.8125
Train Iteration #12950:: 0.33644258975982666 Acc: 0.9375
Train Iteration #13000:: 0.16791558265686035 Acc: 0.96875
Train Iteration #13050:: 0.23369452357292175 Acc: 0.90625
Train Iteration #13100:: 0.6718451380729675 Acc: 0.84375
Train Iteration #13150:: 0.43409401178359985 Acc: 0.90625
Training:: Loss: 0.4290 Acc: 0.8636
Validation Iteration #3250:: 0.5266372561454773 Acc: 0.84375
Validation Iteration #3300:: 0.3929155468940735 Acc: 0.875
Validation:: Loss: 0.4331 Acc: 0.8513
Epoch 41/49
----------
Train Iteration #13200:: 0.22381538152694702 Acc: 0.9375
Train Iteration #13250:: 0.3511626124382019 Acc: 0.875
Train Iteration #13300:: 0.4769904911518097 Acc: 0.71875
Train Iteration #13350:: 0.22922922670841217 Acc: 0.96875
Train Iteration #13400:: 0.5141717195510864 Acc: 0.78125
Train Iteration #13450:: 0.43732720613479614 Acc: 0.875
Training:: Loss: 0.3967 Acc: 0.8742
Validation Iteration #3350:: 0.5729764699935913 Acc: 0.75
Validation Iteration #3400:: 0.46528083086013794 Acc: 0.875
Validation:: Loss: 0.4269 Acc: 0.8904
Epoch 42/49
----------
Train Iteration #13500:: 0.4865776300430298 Acc: 0.8125
Train Iteration #13550:: 0.264412522315979 Acc: 0.90625
Train Iteration #13600:: 0.5771234035491943 Acc: 0.75
Train Iteration #13650:: 0.7495783567428589 Acc: 0.6875
Train Iteration #13700:: 0.475864440202713 Acc: 0.78125
Train Iteration #13750:: 0.5812102556228638 Acc: 0.78125
Train Iteration #13800:: 0.5550999641418457 Acc: 0.875
Training:: Loss: 0.4162 Acc: 0.8714
Validation Iteration #3450:: 0.5304443836212158 Acc: 0.8125
Validation:: Loss: 0.4417 Acc: 0.8474
Epoch 43/49
----------
Train Iteration #13850:: 0.4086471498012543 Acc: 0.90625
Train Iteration #13900:: 0.18566134572029114 Acc: 0.96875
Train Iteration #13950:: 0.38053393363952637 Acc: 0.875
Train Iteration #14000:: 0.5223219394683838 Acc: 0.875
Train Iteration #14050:: 0.4413822293281555 Acc: 0.90625
Train Iteration #14100:: 0.48039132356643677 Acc: 0.875
Training:: Loss: 0.3968 Acc: 0.8777
Validation Iteration #3500:: 0.632335901260376 Acc: 0.84375
Validation Iteration #3550:: 0.6029409170150757 Acc: 0.75
Validation:: Loss: 0.4278 Acc: 0.8716
Epoch 44/49
----------
Train Iteration #14150:: 0.252086877822876 Acc: 0.96875
Train Iteration #14200:: 0.7157557010650635 Acc: 0.75
Train Iteration #14250:: 0.5084063410758972 Acc: 0.8125
Train Iteration #14300:: 0.43975263833999634 Acc: 0.90625
Train Iteration #14350:: 0.5267600417137146 Acc: 0.9375
Train Iteration #14400:: 0.2956295311450958 Acc: 0.84375
Training:: Loss: 0.3874 Acc: 0.8799
Validation Iteration #3600:: 0.3119221329689026 Acc: 0.9375
Validation:: Loss: 0.4358 Acc: 0.8529
Epoch 45/49
----------
Train Iteration #14450:: 0.2042001634836197 Acc: 0.9375
Train Iteration #14500:: 0.5046172142028809 Acc: 0.90625
Train Iteration #14550:: 0.5204035043716431 Acc: 0.8125
Train Iteration #14600:: 0.4233317971229553 Acc: 0.78125
Train Iteration #14650:: 0.5954372882843018 Acc: 0.84375
Train Iteration #14700:: 0.3420827090740204 Acc: 0.84375
Train Iteration #14750:: 0.3545151948928833 Acc: 0.90625
Training:: Loss: 0.4069 Acc: 0.8738
Validation Iteration #3650:: 0.3140782415866852 Acc: 0.9375
Validation Iteration #3700:: 0.37229710817337036 Acc: 0.875
Validation:: Loss: 0.4313 Acc: 0.8705
Epoch 46/49
----------
Train Iteration #14800:: 0.32144373655319214 Acc: 0.875
Train Iteration #14850:: 0.5293992757797241 Acc: 0.78125
Train Iteration #14900:: 0.4012783169746399 Acc: 0.8125
Train Iteration #14950:: 0.45454293489456177 Acc: 0.875
Train Iteration #15000:: 0.44652825593948364 Acc: 0.875
Train Iteration #15050:: 0.46280866861343384 Acc: 0.875
Training:: Loss: 0.4079 Acc: 0.8719
Validation Iteration #3750:: 0.798967719078064 Acc: 0.78125
Validation Iteration #3800:: 0.2650780975818634 Acc: 0.96875
Validation:: Loss: 0.4304 Acc: 0.8787
Epoch 47/49
----------
Train Iteration #15100:: 0.6909336447715759 Acc: 0.75
Train Iteration #15150:: 0.47164714336395264 Acc: 0.84375
Train Iteration #15200:: 0.2642683684825897 Acc: 0.9375
Train Iteration #15250:: 0.4544679522514343 Acc: 0.90625
Train Iteration #15300:: 0.39968371391296387 Acc: 0.8125
Train Iteration #15350:: 0.3925122916698456 Acc: 0.9375
Train Iteration #15400:: 0.33031702041625977 Acc: 0.90625
Training:: Loss: 0.3965 Acc: 0.8779
Validation Iteration #3850:: 0.45492687821388245 Acc: 0.8125
Validation:: Loss: 0.4319 Acc: 0.8591
Epoch 48/49
----------
Train Iteration #15450:: 0.5091018080711365 Acc: 0.96875
Train Iteration #15500:: 0.4454265236854553 Acc: 0.875
Train Iteration #15550:: 0.4308265745639801 Acc: 0.84375
Train Iteration #15600:: 0.2639753818511963 Acc: 0.9375
Train Iteration #15650:: 0.4241047501564026 Acc: 0.8125
Train Iteration #15700:: 0.15132193267345428 Acc: 1.0
Training:: Loss: 0.4076 Acc: 0.8727
Validation Iteration #3900:: 0.292003333568573 Acc: 0.90625
Validation Iteration #3950:: 0.2892712950706482 Acc: 0.90625
Validation:: Loss: 0.4232 Acc: 0.8826
Epoch 49/49
----------
Train Iteration #15750:: 0.32812994718551636 Acc: 0.84375
Train Iteration #15800:: 0.34610414505004883 Acc: 0.9375
Train Iteration #15850:: 0.3563319444656372 Acc: 0.875
Train Iteration #15900:: 0.45811617374420166 Acc: 0.875
Train Iteration #15950:: 0.2557828724384308 Acc: 0.9375
Train Iteration #16000:: 0.5386930704116821 Acc: 0.78125
Training:: Loss: 0.4016 Acc: 0.8767
Validation Iteration #4000:: 0.4696057438850403 Acc: 0.84375
Validation:: Loss: 0.4537 Acc: 0.8389
Best Validation Acc: 0.890363
End time:3:11:19.550994
Program Complete
Average Train Loss:0.45128869354062096
Average Validation Loss:0.47233736763423045
Average Train Accuracy:0.8527643386656262
Average Validation Accuracy:0.8400624268435428
