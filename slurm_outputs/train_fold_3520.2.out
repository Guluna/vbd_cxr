Cerberus running for fold: 2
cuda
Program started
Epoch 0/49
----------
Train Iteration #0:: 1.2981165647506714 Acc: 0.3125
Train Iteration #50:: 1.2302274703979492 Acc: 0.375
Train Iteration #100:: 0.8262545466423035 Acc: 0.59375
Train Iteration #150:: 0.813238263130188 Acc: 0.625
Train Iteration #200:: 0.9071595668792725 Acc: 0.5
Train Iteration #250:: 0.8645150661468506 Acc: 0.40625
Train Iteration #300:: 0.7774174213409424 Acc: 0.8125
Training:: Loss: 0.8437 Acc: 0.5955
Validation Iteration #0:: 0.6981666684150696 Acc: 0.625
Validation Iteration #50:: 0.7582154273986816 Acc: 0.5625
Validation:: Loss: 0.7355 Acc: 0.6570
Epoch 1/49
----------
Train Iteration #350:: 0.811989426612854 Acc: 0.8125
Train Iteration #400:: 0.6933179497718811 Acc: 0.8125
Train Iteration #450:: 0.6737054586410522 Acc: 0.8125
Train Iteration #500:: 0.7959415912628174 Acc: 0.84375
Train Iteration #550:: 0.47251102328300476 Acc: 0.875
Train Iteration #600:: 0.5568615794181824 Acc: 0.78125
Training:: Loss: 0.6398 Acc: 0.7631
Validation Iteration #100:: 0.5435084700584412 Acc: 0.8125
Validation Iteration #150:: 0.7659332752227783 Acc: 0.71875
Validation:: Loss: 0.7566 Acc: 0.6091
Epoch 2/49
----------
Train Iteration #650:: 0.6333533525466919 Acc: 0.9375
Train Iteration #700:: 0.5531617403030396 Acc: 0.84375
Train Iteration #750:: 0.4808748960494995 Acc: 0.8125
Train Iteration #800:: 0.7958710193634033 Acc: 0.71875
Train Iteration #850:: 0.4362415671348572 Acc: 0.90625
Train Iteration #900:: 0.611442506313324 Acc: 0.78125
Train Iteration #950:: 0.5176496505737305 Acc: 0.875
Training:: Loss: 0.5706 Acc: 0.8037
Validation Iteration #200:: 0.6442670822143555 Acc: 0.78125
Validation:: Loss: 0.6257 Acc: 0.7331
Epoch 3/49
----------
Train Iteration #1000:: 0.5382471084594727 Acc: 0.8125
Train Iteration #1050:: 0.4374571442604065 Acc: 0.8125
Train Iteration #1100:: 0.36194029450416565 Acc: 0.875
Train Iteration #1150:: 0.6650977730751038 Acc: 0.71875
Train Iteration #1200:: 0.6254633665084839 Acc: 0.59375
Train Iteration #1250:: 0.5258502960205078 Acc: 0.875
Training:: Loss: 0.5325 Acc: 0.8207
Validation Iteration #250:: 0.5368201732635498 Acc: 0.8125
Validation Iteration #300:: 0.34963321685791016 Acc: 0.96875
Validation:: Loss: 0.5945 Acc: 0.7593
Epoch 4/49
----------
Train Iteration #1300:: 0.597791850566864 Acc: 0.75
Train Iteration #1350:: 0.449762225151062 Acc: 0.84375
Train Iteration #1400:: 0.4303944706916809 Acc: 0.875
Train Iteration #1450:: 0.62549889087677 Acc: 0.75
Train Iteration #1500:: 0.7734413146972656 Acc: 0.71875
Train Iteration #1550:: 0.4657546877861023 Acc: 0.75
Train Iteration #1600:: 0.4069136083126068 Acc: 0.875
Training:: Loss: 0.5095 Acc: 0.8342
Validation Iteration #350:: 0.8613210320472717 Acc: 0.59375
Validation Iteration #400:: 0.48038747906684875 Acc: 0.875
Validation:: Loss: 0.6602 Acc: 0.7007
Epoch 5/49
----------
Train Iteration #1650:: 0.5107123851776123 Acc: 0.8125
Train Iteration #1700:: 0.5238948464393616 Acc: 0.84375
Train Iteration #1750:: 0.454961359500885 Acc: 0.96875
Train Iteration #1800:: 0.6457489132881165 Acc: 0.78125
Train Iteration #1850:: 0.5230650901794434 Acc: 0.9375
Train Iteration #1900:: 0.41948193311691284 Acc: 0.90625
Training:: Loss: 0.5098 Acc: 0.8313
Validation Iteration #450:: 0.46181875467300415 Acc: 0.84375
Validation:: Loss: 0.5227 Acc: 0.8256
Epoch 6/49
----------
Train Iteration #1950:: 0.4545733332633972 Acc: 0.9375
Train Iteration #2000:: 0.4092371463775635 Acc: 0.84375
Train Iteration #2050:: 0.40818506479263306 Acc: 0.90625
Train Iteration #2100:: 0.5355803370475769 Acc: 0.8125
Train Iteration #2150:: 0.3403756618499756 Acc: 0.90625
Train Iteration #2200:: 0.30801111459732056 Acc: 0.9375
Training:: Loss: 0.4811 Acc: 0.8456
Validation Iteration #500:: 0.5095118880271912 Acc: 0.78125
Validation Iteration #550:: 0.6202768683433533 Acc: 0.71875
Validation:: Loss: 0.6030 Acc: 0.7417
Epoch 7/49
----------
Train Iteration #2250:: 0.4386325478553772 Acc: 0.90625
Train Iteration #2300:: 0.3353254199028015 Acc: 0.90625
Train Iteration #2350:: 0.4605926275253296 Acc: 0.8125
Train Iteration #2400:: 0.44598209857940674 Acc: 0.78125
Train Iteration #2450:: 0.3702300786972046 Acc: 0.875
Train Iteration #2500:: 0.4240853190422058 Acc: 0.8125
Train Iteration #2550:: 0.5663596987724304 Acc: 0.59375
Training:: Loss: 0.4755 Acc: 0.8472
Validation Iteration #600:: 0.3294846713542938 Acc: 0.90625
Validation:: Loss: 0.5104 Acc: 0.8209
Epoch 8/49
----------
Train Iteration #2600:: 0.42330682277679443 Acc: 0.8125
Train Iteration #2650:: 0.4174357056617737 Acc: 0.84375
Train Iteration #2700:: 0.5095169544219971 Acc: 0.78125
Train Iteration #2750:: 0.4126136004924774 Acc: 0.84375
Train Iteration #2800:: 0.3263007700443268 Acc: 0.84375
Train Iteration #2850:: 0.6878180503845215 Acc: 0.90625
Training:: Loss: 0.4657 Acc: 0.8478
Validation Iteration #650:: 0.5152482986450195 Acc: 0.8125
Validation Iteration #700:: 0.610116720199585 Acc: 0.84375
Validation:: Loss: 0.5108 Acc: 0.8162
Epoch 9/49
----------
Train Iteration #2900:: 0.4440333843231201 Acc: 0.78125
Train Iteration #2950:: 0.2652931213378906 Acc: 0.875
Train Iteration #3000:: 0.49209660291671753 Acc: 0.8125
Train Iteration #3050:: 0.42551442980766296 Acc: 0.875
Train Iteration #3100:: 0.30150648951530457 Acc: 0.90625
Train Iteration #3150:: 0.5522463917732239 Acc: 0.8125
Train Iteration #3200:: 0.45314404368400574 Acc: 0.84375
Training:: Loss: 0.4514 Acc: 0.8560
Validation Iteration #750:: 0.42472365498542786 Acc: 0.78125
Validation Iteration #800:: 0.6053190231323242 Acc: 0.8125
Validation:: Loss: 0.5137 Acc: 0.8115
Epoch 10/49
----------
Train Iteration #3250:: 0.6469817161560059 Acc: 0.625
Train Iteration #3300:: 0.535119891166687 Acc: 0.84375
Train Iteration #3350:: 0.5908632278442383 Acc: 0.75
Train Iteration #3400:: 0.3856109380722046 Acc: 0.90625
Train Iteration #3450:: 0.38746166229248047 Acc: 0.84375
Train Iteration #3500:: 0.6920874118804932 Acc: 0.625
Training:: Loss: 0.4656 Acc: 0.8465
Validation Iteration #850:: 0.4220958948135376 Acc: 0.84375
Validation:: Loss: 0.4881 Acc: 0.8428
Epoch 11/49
----------
Train Iteration #3550:: 0.5090900659561157 Acc: 0.75
Train Iteration #3600:: 0.5665689706802368 Acc: 0.78125
Train Iteration #3650:: 0.3907868564128876 Acc: 0.9375
Train Iteration #3700:: 0.7536365389823914 Acc: 0.75
Train Iteration #3750:: 0.4998256266117096 Acc: 0.75
Train Iteration #3800:: 0.601536214351654 Acc: 0.875
Train Iteration #3850:: 0.37560784816741943 Acc: 0.8125
Training:: Loss: 0.4512 Acc: 0.8532
Validation Iteration #900:: 0.435742050409317 Acc: 0.78125
Validation Iteration #950:: 0.48195815086364746 Acc: 0.8125
Validation:: Loss: 0.5006 Acc: 0.8217
Epoch 12/49
----------
Train Iteration #3900:: 0.3157191276550293 Acc: 0.90625
Train Iteration #3950:: 0.6821874380111694 Acc: 0.875
Train Iteration #4000:: 0.44562673568725586 Acc: 0.9375
Train Iteration #4050:: 0.8567982912063599 Acc: 0.875
Train Iteration #4100:: 0.5290234088897705 Acc: 0.84375
Train Iteration #4150:: 0.5493144392967224 Acc: 0.84375
Training:: Loss: 0.4377 Acc: 0.8622
Validation Iteration #1000:: 0.42270001769065857 Acc: 0.90625
Validation Iteration #1050:: 0.5562994480133057 Acc: 0.84375
Validation:: Loss: 0.5016 Acc: 0.8166
Epoch 13/49
----------
Train Iteration #4200:: 0.29368144273757935 Acc: 0.96875
Train Iteration #4250:: 0.44155293703079224 Acc: 0.875
Train Iteration #4300:: 0.41948914527893066 Acc: 0.90625
Train Iteration #4350:: 0.28453660011291504 Acc: 0.9375
Train Iteration #4400:: 0.45839428901672363 Acc: 0.84375
Train Iteration #4450:: 0.33360719680786133 Acc: 0.875
Training:: Loss: 0.4424 Acc: 0.8579
Validation Iteration #1100:: 0.5499362349510193 Acc: 0.75
Validation:: Loss: 0.4801 Acc: 0.8478
Epoch 14/49
----------
Train Iteration #4500:: 1.0517518520355225 Acc: 0.71875
Train Iteration #4550:: 0.2943943440914154 Acc: 1.0
Train Iteration #4600:: 0.5040158629417419 Acc: 0.8125
Train Iteration #4650:: 0.6090000867843628 Acc: 0.78125
Train Iteration #4700:: 0.3796142339706421 Acc: 0.84375
Train Iteration #4750:: 0.29421135783195496 Acc: 0.96875
Train Iteration #4800:: 0.5503772497177124 Acc: 0.875
Training:: Loss: 0.4582 Acc: 0.8572
Validation Iteration #1150:: 0.3210766613483429 Acc: 0.90625
Validation Iteration #1200:: 0.3905501961708069 Acc: 0.84375
Validation:: Loss: 0.4825 Acc: 0.8408
Epoch 15/49
----------
Train Iteration #4850:: 0.7271429300308228 Acc: 0.78125
Train Iteration #4900:: 0.38778650760650635 Acc: 0.875
Train Iteration #4950:: 0.4356606602668762 Acc: 0.8125
Train Iteration #5000:: 0.7547584772109985 Acc: 0.84375
Train Iteration #5050:: 0.5477564930915833 Acc: 0.9375
Train Iteration #5100:: 0.7733888030052185 Acc: 0.78125
Training:: Loss: 0.4425 Acc: 0.8594
Validation Iteration #1250:: 0.39293402433395386 Acc: 0.90625
Validation:: Loss: 0.5032 Acc: 0.8123
Epoch 16/49
----------
Train Iteration #5150:: 0.6000231504440308 Acc: 0.75
Train Iteration #5200:: 0.2019859254360199 Acc: 1.0
Train Iteration #5250:: 0.4304814338684082 Acc: 0.8125
Train Iteration #5300:: 0.2507079541683197 Acc: 0.90625
Train Iteration #5350:: 0.4191504716873169 Acc: 0.875
Train Iteration #5400:: 0.44727545976638794 Acc: 0.875
Train Iteration #5450:: 0.20072397589683533 Acc: 0.9375
Training:: Loss: 0.4244 Acc: 0.8642
Validation Iteration #1300:: 0.6331502795219421 Acc: 0.75
Validation Iteration #1350:: 0.44939446449279785 Acc: 0.84375
Validation:: Loss: 0.5292 Acc: 0.7932
Epoch 17/49
----------
Train Iteration #5500:: 0.6929827928543091 Acc: 0.71875
Train Iteration #5550:: 0.4991033673286438 Acc: 0.84375
Train Iteration #5600:: 0.42071232199668884 Acc: 0.875
Train Iteration #5650:: 0.3433830142021179 Acc: 0.9375
Train Iteration #5700:: 0.6102380752563477 Acc: 0.875
Train Iteration #5750:: 0.22024217247962952 Acc: 0.9375
Training:: Loss: 0.4346 Acc: 0.8652
Validation Iteration #1400:: 0.4059809446334839 Acc: 0.90625
Validation Iteration #1450:: 0.4008719325065613 Acc: 0.8125
Validation:: Loss: 0.4934 Acc: 0.8205
Epoch 18/49
----------
Train Iteration #5800:: 0.39039620757102966 Acc: 0.90625
Train Iteration #5850:: 0.44567567110061646 Acc: 0.8125
Train Iteration #5900:: 0.29264646768569946 Acc: 0.90625
Train Iteration #5950:: 0.47296953201293945 Acc: 0.78125
Train Iteration #6000:: 0.3282851576805115 Acc: 0.96875
Train Iteration #6050:: 0.3546028733253479 Acc: 0.875
Training:: Loss: 0.4162 Acc: 0.8680
Validation Iteration #1500:: 0.6057382822036743 Acc: 0.6875
Validation:: Loss: 0.5361 Acc: 0.7940
Epoch 19/49
----------
Train Iteration #6100:: 0.5831056833267212 Acc: 0.6875
Train Iteration #6150:: 0.34407177567481995 Acc: 0.9375
Train Iteration #6200:: 0.43346643447875977 Acc: 0.90625
Train Iteration #6250:: 0.32653284072875977 Acc: 0.9375
Train Iteration #6300:: 0.33883899450302124 Acc: 0.90625
Train Iteration #6350:: 0.23655742406845093 Acc: 0.96875
Train Iteration #6400:: 0.4657391309738159 Acc: 0.875
Training:: Loss: 0.4233 Acc: 0.8667
Validation Iteration #1550:: 0.5301970839500427 Acc: 0.8125
Validation Iteration #1600:: 0.3146146833896637 Acc: 0.9375
Validation:: Loss: 0.4994 Acc: 0.8139
Epoch 20/49
----------
Train Iteration #6450:: 0.42252352833747864 Acc: 0.9375
Train Iteration #6500:: 0.38482820987701416 Acc: 0.9375
Train Iteration #6550:: 0.310016930103302 Acc: 0.96875
Train Iteration #6600:: 0.31310760974884033 Acc: 0.875
Train Iteration #6650:: 0.2521081864833832 Acc: 0.9375
Train Iteration #6700:: 0.39510786533355713 Acc: 0.84375
Training:: Loss: 0.4203 Acc: 0.8671
Validation Iteration #1650:: 1.0528101921081543 Acc: 0.6875
Validation Iteration #1700:: 0.2773679494857788 Acc: 1.0
Validation:: Loss: 0.4703 Acc: 0.8467
Epoch 21/49
----------
Train Iteration #6750:: 0.40530580282211304 Acc: 0.90625
Train Iteration #6800:: 0.2348002791404724 Acc: 0.9375
Train Iteration #6850:: 0.31087183952331543 Acc: 0.875
Train Iteration #6900:: 0.5413457155227661 Acc: 0.78125
Train Iteration #6950:: 0.34266558289527893 Acc: 0.90625
Train Iteration #7000:: 0.2324344366788864 Acc: 0.96875
Train Iteration #7050:: 0.5867809653282166 Acc: 0.78125
Training:: Loss: 0.4203 Acc: 0.8698
Validation Iteration #1750:: 0.33346331119537354 Acc: 0.875
Validation:: Loss: 0.4914 Acc: 0.8221
Epoch 22/49
----------
Train Iteration #7100:: 0.3956241011619568 Acc: 0.84375
Train Iteration #7150:: 0.1940726637840271 Acc: 0.90625
Train Iteration #7200:: 0.5375498533248901 Acc: 0.71875
Train Iteration #7250:: 0.20886459946632385 Acc: 0.9375
Train Iteration #7300:: 0.5855788588523865 Acc: 0.75
Train Iteration #7350:: 0.5867201089859009 Acc: 0.6875
Training:: Loss: 0.4088 Acc: 0.8731
Validation Iteration #1800:: 0.6321836709976196 Acc: 0.78125
Validation Iteration #1850:: 0.47789061069488525 Acc: 0.84375
Validation:: Loss: 0.4921 Acc: 0.8233
Epoch 23/49
----------
Train Iteration #7400:: 0.42012375593185425 Acc: 0.8125
Train Iteration #7450:: 0.38126879930496216 Acc: 0.90625
Train Iteration #7500:: 0.2815140187740326 Acc: 0.96875
Train Iteration #7550:: 0.33194446563720703 Acc: 0.90625
Train Iteration #7600:: 0.33203935623168945 Acc: 0.90625
Train Iteration #7650:: 0.24313434958457947 Acc: 0.96875
Train Iteration #7700:: 0.38530316948890686 Acc: 0.875
Training:: Loss: 0.4241 Acc: 0.8668
Validation Iteration #1900:: 0.3304755687713623 Acc: 0.8125
Validation:: Loss: 0.4837 Acc: 0.8299
Epoch 24/49
----------
Train Iteration #7750:: 0.25206220149993896 Acc: 0.9375
Train Iteration #7800:: 0.37848109006881714 Acc: 0.84375
Train Iteration #7850:: 0.47543424367904663 Acc: 0.78125
Train Iteration #7900:: 0.34339696168899536 Acc: 0.96875
Train Iteration #7950:: 0.3290441930294037 Acc: 0.96875
Train Iteration #8000:: 0.4440929591655731 Acc: 0.71875
Training:: Loss: 0.4190 Acc: 0.8682
Validation Iteration #1950:: 0.243113711476326 Acc: 0.90625
Validation Iteration #2000:: 0.5359857082366943 Acc: 0.84375
Validation:: Loss: 0.4895 Acc: 0.8233
Epoch 25/49
----------
Train Iteration #8050:: 0.2255757749080658 Acc: 0.90625
Train Iteration #8100:: 0.49904030561447144 Acc: 0.875
Train Iteration #8150:: 0.31910523772239685 Acc: 0.9375
Train Iteration #8200:: 0.28784191608428955 Acc: 0.84375
Train Iteration #8250:: 0.37782609462738037 Acc: 0.90625
Train Iteration #8300:: 0.578800618648529 Acc: 0.78125
Training:: Loss: 0.4289 Acc: 0.8646
Validation Iteration #2050:: 0.5745515823364258 Acc: 0.71875
Validation Iteration #2100:: 0.6510072350502014 Acc: 0.75
Validation:: Loss: 0.4954 Acc: 0.8158
Epoch 26/49
----------
Train Iteration #8350:: 0.300957053899765 Acc: 0.875
Train Iteration #8400:: 0.4189722537994385 Acc: 0.78125
Train Iteration #8450:: 0.47661900520324707 Acc: 0.875
Train Iteration #8500:: 0.3797726333141327 Acc: 0.8125
Train Iteration #8550:: 0.293512225151062 Acc: 0.90625
Train Iteration #8600:: 0.3889544904232025 Acc: 0.84375
Train Iteration #8650:: 0.2170804738998413 Acc: 0.9375
Training:: Loss: 0.4195 Acc: 0.8689
Validation Iteration #2150:: 0.4715544581413269 Acc: 0.84375
Validation:: Loss: 0.4984 Acc: 0.8143
Epoch 27/49
----------
Train Iteration #8700:: 0.41185885667800903 Acc: 0.90625
Train Iteration #8750:: 0.5255900621414185 Acc: 0.78125
Train Iteration #8800:: 0.519049882888794 Acc: 0.875
Train Iteration #8850:: 0.5270351767539978 Acc: 0.78125
Train Iteration #8900:: 0.4553602635860443 Acc: 0.875
Train Iteration #8950:: 0.41437405347824097 Acc: 0.90625
Training:: Loss: 0.4125 Acc: 0.8707
Validation Iteration #2200:: 0.30996012687683105 Acc: 0.90625
Validation Iteration #2250:: 0.37822389602661133 Acc: 0.84375
Validation:: Loss: 0.4621 Acc: 0.8650
Epoch 28/49
----------
Train Iteration #9000:: 0.5959704518318176 Acc: 0.78125
Train Iteration #9050:: 0.6418477296829224 Acc: 0.875
Train Iteration #9100:: 0.6705488562583923 Acc: 0.78125
Train Iteration #9150:: 0.18752166628837585 Acc: 1.0
Train Iteration #9200:: 0.4022926092147827 Acc: 0.78125
Train Iteration #9250:: 0.3565269708633423 Acc: 0.875
Train Iteration #9300:: 0.5030074119567871 Acc: 0.78125
Training:: Loss: 0.4270 Acc: 0.8652
Validation Iteration #2300:: 0.5879054069519043 Acc: 0.875
Validation:: Loss: 0.4588 Acc: 0.8588
Epoch 29/49
----------
Train Iteration #9350:: 0.498555064201355 Acc: 0.84375
Train Iteration #9400:: 0.40901339054107666 Acc: 0.9375
Train Iteration #9450:: 0.40986964106559753 Acc: 0.84375
Train Iteration #9500:: 0.3655798137187958 Acc: 0.90625
Train Iteration #9550:: 0.335532546043396 Acc: 0.875
Train Iteration #9600:: 0.4170781075954437 Acc: 0.875
Training:: Loss: 0.4147 Acc: 0.8700
Validation Iteration #2350:: 0.8980780839920044 Acc: 0.71875
Validation Iteration #2400:: 0.32143357396125793 Acc: 0.8125
Validation:: Loss: 0.5156 Acc: 0.8006
Epoch 30/49
----------
Train Iteration #9650:: 0.40126049518585205 Acc: 0.875
Train Iteration #9700:: 0.34295910596847534 Acc: 0.9375
Train Iteration #9750:: 0.3504074215888977 Acc: 0.8125
Train Iteration #9800:: 0.36255720257759094 Acc: 0.875
Train Iteration #9850:: 0.5714719295501709 Acc: 0.75
Train Iteration #9900:: 0.9050606489181519 Acc: 0.9375
Train Iteration #9950:: 0.4751241207122803 Acc: 0.75
Training:: Loss: 0.3966 Acc: 0.8804
Validation Iteration #2450:: 0.39876100420951843 Acc: 0.84375
Validation Iteration #2500:: 0.473738431930542 Acc: 0.8125
Validation:: Loss: 0.4715 Acc: 0.8400
Epoch 31/49
----------
Train Iteration #10000:: 0.4401581287384033 Acc: 0.78125
Train Iteration #10050:: 0.453235000371933 Acc: 0.875
Train Iteration #10100:: 0.47181499004364014 Acc: 0.78125
Train Iteration #10150:: 0.44458693265914917 Acc: 0.875
Train Iteration #10200:: 0.6025491952896118 Acc: 0.90625
Train Iteration #10250:: 0.4636528193950653 Acc: 0.90625
Training:: Loss: 0.4125 Acc: 0.8707
Validation Iteration #2550:: 0.4178946614265442 Acc: 0.78125
Validation:: Loss: 0.4595 Acc: 0.8545
Epoch 32/49
----------
Train Iteration #10300:: 0.3832208514213562 Acc: 0.84375
Train Iteration #10350:: 0.6733714938163757 Acc: 0.84375
Train Iteration #10400:: 0.38875460624694824 Acc: 0.875
Train Iteration #10450:: 0.33968859910964966 Acc: 0.8125
Train Iteration #10500:: 0.3139927387237549 Acc: 0.90625
Train Iteration #10550:: 0.28446340560913086 Acc: 0.875
Training:: Loss: 0.4093 Acc: 0.8757
Validation Iteration #2600:: 0.53194260597229 Acc: 0.84375
Validation Iteration #2650:: 0.7689032554626465 Acc: 0.71875
Validation:: Loss: 0.4899 Acc: 0.8170
Epoch 33/49
----------
Train Iteration #10600:: 0.34309542179107666 Acc: 0.90625
Train Iteration #10650:: 0.5598072409629822 Acc: 0.71875
Train Iteration #10700:: 0.6212213635444641 Acc: 0.71875
Train Iteration #10750:: 0.3134869635105133 Acc: 0.90625
Train Iteration #10800:: 0.3734755218029022 Acc: 0.875
Train Iteration #10850:: 0.3455180525779724 Acc: 0.9375
Train Iteration #10900:: 0.4655179977416992 Acc: 0.8125
Training:: Loss: 0.4172 Acc: 0.8684
Validation Iteration #2700:: 0.37358400225639343 Acc: 0.90625
Validation Iteration #2750:: 0.36269110441207886 Acc: 0.84375
Validation:: Loss: 0.4721 Acc: 0.8365
Epoch 34/49
----------
Train Iteration #10950:: 0.3274802565574646 Acc: 0.9375
Train Iteration #11000:: 0.5567446947097778 Acc: 0.71875
Train Iteration #11050:: 0.49347519874572754 Acc: 0.8125
Train Iteration #11100:: 0.2733895182609558 Acc: 0.875
Train Iteration #11150:: 0.3303157091140747 Acc: 0.9375
Train Iteration #11200:: 0.6588601469993591 Acc: 0.875
Training:: Loss: 0.4093 Acc: 0.8691
Validation Iteration #2800:: 0.7933698892593384 Acc: 0.6875
Validation:: Loss: 0.4577 Acc: 0.8568
Epoch 35/49
----------
Train Iteration #11250:: 0.284087598323822 Acc: 0.84375
Train Iteration #11300:: 0.49841928482055664 Acc: 0.78125
Train Iteration #11350:: 0.22763672471046448 Acc: 0.9375
Train Iteration #11400:: 0.3212566077709198 Acc: 0.90625
Train Iteration #11450:: 0.533901572227478 Acc: 0.84375
Train Iteration #11500:: 0.7949204444885254 Acc: 0.8125
Train Iteration #11550:: 0.887397289276123 Acc: 0.875
Training:: Loss: 0.3992 Acc: 0.8735
Validation Iteration #2850:: 0.3434479832649231 Acc: 0.9375
Validation Iteration #2900:: 0.8137122392654419 Acc: 0.75
Validation:: Loss: 0.4612 Acc: 0.8510
Epoch 36/49
----------
Train Iteration #11600:: 0.4179286062717438 Acc: 0.875
Train Iteration #11650:: 0.3405948877334595 Acc: 0.9375
Train Iteration #11700:: 0.3954012989997864 Acc: 0.875
Train Iteration #11750:: 0.7421433925628662 Acc: 0.8125
Train Iteration #11800:: 0.458816260099411 Acc: 0.84375
Train Iteration #11850:: 0.412463903427124 Acc: 0.9375
Training:: Loss: 0.3906 Acc: 0.8791
Validation Iteration #2950:: 0.25678807497024536 Acc: 0.9375
Validation:: Loss: 0.4666 Acc: 0.8424
Epoch 37/49
----------
Train Iteration #11900:: 0.9447251558303833 Acc: 0.8125
Train Iteration #11950:: 0.5339228510856628 Acc: 0.8125
Train Iteration #12000:: 0.4212387800216675 Acc: 0.78125
Train Iteration #12050:: 0.6611247658729553 Acc: 0.84375
Train Iteration #12100:: 0.5204071402549744 Acc: 0.875
Train Iteration #12150:: 0.35955244302749634 Acc: 0.875
Training:: Loss: 0.3976 Acc: 0.8767
Validation Iteration #3000:: 0.37314414978027344 Acc: 0.90625
Validation Iteration #3050:: 0.6044082641601562 Acc: 0.71875
Validation:: Loss: 0.5179 Acc: 0.8022
Epoch 38/49
----------
Train Iteration #12200:: 0.4751507043838501 Acc: 0.8125
Train Iteration #12250:: 0.45645880699157715 Acc: 0.8125
Train Iteration #12300:: 0.13202065229415894 Acc: 1.0
Train Iteration #12350:: 0.8827323913574219 Acc: 0.8125
Train Iteration #12400:: 0.5689822435379028 Acc: 0.90625
Train Iteration #12450:: 0.4922802448272705 Acc: 0.8125
Train Iteration #12500:: 0.40876126289367676 Acc: 0.8125
Training:: Loss: 0.3968 Acc: 0.8789
Validation Iteration #3100:: 0.4301132559776306 Acc: 0.84375
Validation Iteration #3150:: 0.497860848903656 Acc: 0.75
Validation:: Loss: 0.4829 Acc: 0.8264
Epoch 39/49
----------
Train Iteration #12550:: 0.2577172815799713 Acc: 0.90625
Train Iteration #12600:: 0.3827458620071411 Acc: 0.9375
Train Iteration #12650:: 0.32654282450675964 Acc: 0.84375
Train Iteration #12700:: 0.24170586466789246 Acc: 0.96875
Train Iteration #12750:: 0.4894808530807495 Acc: 0.78125
Train Iteration #12800:: 0.47972312569618225 Acc: 0.71875
Training:: Loss: 0.3972 Acc: 0.8788
Validation Iteration #3200:: 0.4059169292449951 Acc: 0.84375
Validation:: Loss: 0.4799 Acc: 0.8244
Epoch 40/49
----------
Train Iteration #12850:: 0.21159496903419495 Acc: 1.0
Train Iteration #12900:: 0.38265687227249146 Acc: 0.90625
Train Iteration #12950:: 0.311242938041687 Acc: 0.84375
Train Iteration #13000:: 0.1119987815618515 Acc: 1.0
Train Iteration #13050:: 0.32172876596450806 Acc: 0.8125
Train Iteration #13100:: 0.3045075833797455 Acc: 0.9375
Train Iteration #13150:: 0.4989771842956543 Acc: 0.9375
Training:: Loss: 0.4010 Acc: 0.8734
Validation Iteration #3250:: 0.46049749851226807 Acc: 0.84375
Validation Iteration #3300:: 0.5687119960784912 Acc: 0.78125
Validation:: Loss: 0.4878 Acc: 0.8236
Epoch 41/49
----------
Train Iteration #13200:: 0.41363489627838135 Acc: 0.875
Train Iteration #13250:: 0.4217904508113861 Acc: 0.84375
Train Iteration #13300:: 0.3715728521347046 Acc: 0.875
Train Iteration #13350:: 0.2748839259147644 Acc: 0.9375
Train Iteration #13400:: 0.35934388637542725 Acc: 0.84375
Train Iteration #13450:: 0.4134500324726105 Acc: 0.84375
Training:: Loss: 0.3979 Acc: 0.8764
Validation Iteration #3350:: 0.32919543981552124 Acc: 0.875
Validation Iteration #3400:: 0.5228246450424194 Acc: 0.84375
Validation:: Loss: 0.4799 Acc: 0.8279
Epoch 42/49
----------
Train Iteration #13500:: 0.30468785762786865 Acc: 0.90625
Train Iteration #13550:: 0.42015954852104187 Acc: 0.90625
Train Iteration #13600:: 0.41853493452072144 Acc: 0.90625
Train Iteration #13650:: 0.15775062143802643 Acc: 1.0
Train Iteration #13700:: 0.23220530152320862 Acc: 0.9375
Train Iteration #13750:: 0.28699153661727905 Acc: 0.90625
Train Iteration #13800:: 0.23963946104049683 Acc: 0.90625
Training:: Loss: 0.3992 Acc: 0.8754
Validation Iteration #3450:: 0.3919225335121155 Acc: 0.8125
Validation:: Loss: 0.4712 Acc: 0.8369
Epoch 43/49
----------
Train Iteration #13850:: 0.49127477407455444 Acc: 0.9375
Train Iteration #13900:: 0.22696453332901 Acc: 0.90625
Train Iteration #13950:: 0.36747437715530396 Acc: 0.875
Train Iteration #14000:: 0.5624310374259949 Acc: 0.84375
Train Iteration #14050:: 0.4723559021949768 Acc: 0.90625
Train Iteration #14100:: 0.32832348346710205 Acc: 0.9375
Training:: Loss: 0.4015 Acc: 0.8756
Validation Iteration #3500:: 0.3496919870376587 Acc: 0.96875
Validation Iteration #3550:: 0.45999205112457275 Acc: 0.875
Validation:: Loss: 0.4589 Acc: 0.8490
Epoch 44/49
----------
Train Iteration #14150:: 0.19204887747764587 Acc: 0.96875
Train Iteration #14200:: 0.46254026889801025 Acc: 0.90625
Train Iteration #14250:: 0.4610680937767029 Acc: 0.875
Train Iteration #14300:: 0.6705703139305115 Acc: 0.84375
Train Iteration #14350:: 0.5082412958145142 Acc: 0.90625
Train Iteration #14400:: 0.14411088824272156 Acc: 0.96875
Training:: Loss: 0.4015 Acc: 0.8735
Validation Iteration #3600:: 0.4743424654006958 Acc: 0.875
Validation:: Loss: 0.4561 Acc: 0.8631
Epoch 45/49
----------
Train Iteration #14450:: 0.21884900331497192 Acc: 0.96875
Train Iteration #14500:: 0.20673978328704834 Acc: 0.96875
Train Iteration #14550:: 0.385612428188324 Acc: 0.875
Train Iteration #14600:: 0.38228219747543335 Acc: 0.90625
Train Iteration #14650:: 0.49800121784210205 Acc: 0.875
Train Iteration #14700:: 0.5052054524421692 Acc: 0.8125
Train Iteration #14750:: 0.4870339035987854 Acc: 0.8125
Training:: Loss: 0.3946 Acc: 0.8796
Validation Iteration #3650:: 0.5710369348526001 Acc: 0.75
Validation Iteration #3700:: 0.8083142638206482 Acc: 0.8125
Validation:: Loss: 0.4819 Acc: 0.8264
Epoch 46/49
----------
Train Iteration #14800:: 0.38430678844451904 Acc: 0.84375
Train Iteration #14850:: 0.4637592136859894 Acc: 0.8125
Train Iteration #14900:: 0.2550220489501953 Acc: 0.96875
Train Iteration #14950:: 0.355947345495224 Acc: 0.875
Train Iteration #15000:: 0.24824239313602448 Acc: 0.90625
Train Iteration #15050:: 0.5166488289833069 Acc: 0.875
Training:: Loss: 0.3726 Acc: 0.8843
Validation Iteration #3750:: 0.7045966386795044 Acc: 0.6875
Validation Iteration #3800:: 0.4991653561592102 Acc: 0.71875
Validation:: Loss: 0.4767 Acc: 0.8295
Epoch 47/49
----------
Train Iteration #15100:: 0.4445645809173584 Acc: 0.9375
Train Iteration #15150:: 0.2925509214401245 Acc: 0.875
Train Iteration #15200:: 0.4268437623977661 Acc: 0.78125
Train Iteration #15250:: 0.3576926290988922 Acc: 0.875
Train Iteration #15300:: 0.43175292015075684 Acc: 0.875
Train Iteration #15350:: 0.21010449528694153 Acc: 0.96875
Train Iteration #15400:: 0.6288536787033081 Acc: 0.78125
Training:: Loss: 0.3913 Acc: 0.8791
Validation Iteration #3850:: 0.22906547784805298 Acc: 0.96875
Validation:: Loss: 0.4605 Acc: 0.8451
Epoch 48/49
----------
Train Iteration #15450:: 0.4263020157814026 Acc: 0.8125
Train Iteration #15500:: 0.359381765127182 Acc: 0.9375
Train Iteration #15550:: 0.36230719089508057 Acc: 0.875
Train Iteration #15600:: 0.21717652678489685 Acc: 0.90625
Train Iteration #15650:: 0.4822109341621399 Acc: 0.9375
Train Iteration #15700:: 0.528730034828186 Acc: 0.8125
Training:: Loss: 0.3921 Acc: 0.8781
Validation Iteration #3900:: 0.57573002576828 Acc: 0.8125
Validation Iteration #3950:: 0.7031639218330383 Acc: 0.75
Validation:: Loss: 0.5200 Acc: 0.8022
Epoch 49/49
----------
Train Iteration #15750:: 0.19156545400619507 Acc: 0.9375
Train Iteration #15800:: 0.48953837156295776 Acc: 0.84375
Train Iteration #15850:: 0.3157893717288971 Acc: 0.90625
Train Iteration #15900:: 0.31090012192726135 Acc: 0.9375
Train Iteration #15950:: 0.39645570516586304 Acc: 0.84375
Train Iteration #16000:: 0.39591747522354126 Acc: 0.84375
Training:: Loss: 0.3880 Acc: 0.8797
Validation Iteration #4000:: 0.4484705626964569 Acc: 0.78125
Validation:: Loss: 0.4715 Acc: 0.8361
Best Validation Acc: 0.865002
End time:3:10:32.528727
Program Complete
Average Train Loss:0.4407367844860732
Average Validation Loss:0.5085629504360912
Average Train Accuracy:0.8571303160358955
Average Validation Accuracy:0.8133905579399142
