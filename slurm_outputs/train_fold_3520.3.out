Cerberus running for fold: 3
cuda
Program started
Epoch 0/49
----------
Train Iteration #0:: 1.3017946481704712 Acc: 0.4375
Train Iteration #50:: 0.9024860858917236 Acc: 0.59375
Train Iteration #100:: 0.8665080070495605 Acc: 0.625
Train Iteration #150:: 0.8531571626663208 Acc: 0.40625
Train Iteration #200:: 0.8022047281265259 Acc: 0.625
Train Iteration #250:: 0.7456769347190857 Acc: 0.71875
Train Iteration #300:: 0.7281196117401123 Acc: 0.71875
Training:: Loss: 0.8248 Acc: 0.6131
Validation Iteration #0:: 0.8088251352310181 Acc: 0.4375
Validation Iteration #50:: 0.7935185432434082 Acc: 0.5625
Validation:: Loss: 0.8041 Acc: 0.5529
Epoch 1/49
----------
Train Iteration #350:: 0.6902518272399902 Acc: 0.71875
Train Iteration #400:: 0.8060805797576904 Acc: 0.9375
Train Iteration #450:: 0.5296264886856079 Acc: 0.8125
Train Iteration #500:: 0.6804298162460327 Acc: 0.53125
Train Iteration #550:: 0.6041901111602783 Acc: 0.65625
Train Iteration #600:: 0.47199511528015137 Acc: 0.84375
Training:: Loss: 0.6342 Acc: 0.7646
Validation Iteration #100:: 0.637751579284668 Acc: 0.75
Validation Iteration #150:: 0.8327714204788208 Acc: 0.5
Validation:: Loss: 0.7146 Acc: 0.6574
Epoch 2/49
----------
Train Iteration #650:: 0.784917950630188 Acc: 0.8125
Train Iteration #700:: 0.588701069355011 Acc: 0.78125
Train Iteration #750:: 0.5498380661010742 Acc: 0.9375
Train Iteration #800:: 0.6041281223297119 Acc: 0.90625
Train Iteration #850:: 0.5477667450904846 Acc: 0.75
Train Iteration #900:: 0.40223991870880127 Acc: 0.90625
Train Iteration #950:: 0.8321830630302429 Acc: 0.53125
Training:: Loss: 0.5724 Acc: 0.8052
Validation Iteration #200:: 0.6975110769271851 Acc: 0.78125
Validation:: Loss: 0.5931 Acc: 0.8322
Epoch 3/49
----------
Train Iteration #1000:: 0.43638235330581665 Acc: 0.8125
Train Iteration #1050:: 0.5610116720199585 Acc: 0.71875
Train Iteration #1100:: 0.6413012742996216 Acc: 0.6875
Train Iteration #1150:: 0.4553453326225281 Acc: 0.84375
Train Iteration #1200:: 0.4357295036315918 Acc: 0.96875
Train Iteration #1250:: 0.4929557740688324 Acc: 0.8125
Training:: Loss: 0.5442 Acc: 0.8192
Validation Iteration #250:: 0.5558789968490601 Acc: 0.78125
Validation Iteration #300:: 0.7954845428466797 Acc: 0.625
Validation:: Loss: 0.6529 Acc: 0.7128
Epoch 4/49
----------
Train Iteration #1300:: 0.7367929816246033 Acc: 0.71875
Train Iteration #1350:: 0.6330589056015015 Acc: 0.8125
Train Iteration #1400:: 0.38964927196502686 Acc: 0.78125
Train Iteration #1450:: 0.48689451813697815 Acc: 0.84375
Train Iteration #1500:: 0.6082577705383301 Acc: 0.71875
Train Iteration #1550:: 0.47246095538139343 Acc: 0.9375
Train Iteration #1600:: 0.311138391494751 Acc: 1.0
Training:: Loss: 0.5011 Acc: 0.8353
Validation Iteration #350:: 0.44138509035110474 Acc: 0.90625
Validation Iteration #400:: 0.7680841088294983 Acc: 0.65625
Validation:: Loss: 0.5912 Acc: 0.7690
Epoch 5/49
----------
Train Iteration #1650:: 0.5275344848632812 Acc: 0.84375
Train Iteration #1700:: 0.6445872783660889 Acc: 0.78125
Train Iteration #1750:: 0.688615083694458 Acc: 0.8125
Train Iteration #1800:: 0.4745061993598938 Acc: 0.84375
Train Iteration #1850:: 0.5469458699226379 Acc: 0.8125
Train Iteration #1900:: 0.6223866939544678 Acc: 0.75
Training:: Loss: 0.4995 Acc: 0.8385
Validation Iteration #450:: 0.6538127660751343 Acc: 0.8125
Validation:: Loss: 0.5408 Acc: 0.8291
Epoch 6/49
----------
Train Iteration #1950:: 0.39648717641830444 Acc: 0.8125
Train Iteration #2000:: 0.4192655682563782 Acc: 0.875
Train Iteration #2050:: 0.4487638771533966 Acc: 0.78125
Train Iteration #2100:: 0.4608320891857147 Acc: 0.84375
Train Iteration #2150:: 0.589236319065094 Acc: 0.75
Train Iteration #2200:: 0.5692648887634277 Acc: 0.8125
Training:: Loss: 0.4825 Acc: 0.8411
Validation Iteration #500:: 0.667953372001648 Acc: 0.75
Validation Iteration #550:: 0.636560320854187 Acc: 0.6875
Validation:: Loss: 0.5824 Acc: 0.7698
Epoch 7/49
----------
Train Iteration #2250:: 0.6020938754081726 Acc: 0.78125
Train Iteration #2300:: 0.4788884222507477 Acc: 0.84375
Train Iteration #2350:: 0.5616253018379211 Acc: 0.78125
Train Iteration #2400:: 0.9128866195678711 Acc: 0.8125
Train Iteration #2450:: 0.20361433923244476 Acc: 0.96875
Train Iteration #2500:: 0.49892422556877136 Acc: 0.8125
Train Iteration #2550:: 0.5961595773696899 Acc: 0.8125
Training:: Loss: 0.4712 Acc: 0.8440
Validation Iteration #600:: 0.4096098840236664 Acc: 0.8125
Validation:: Loss: 0.5273 Acc: 0.8244
Epoch 8/49
----------
Train Iteration #2600:: 0.39234381914138794 Acc: 0.84375
Train Iteration #2650:: 0.3466242551803589 Acc: 0.9375
Train Iteration #2700:: 0.5445401072502136 Acc: 0.78125
Train Iteration #2750:: 0.29982760548591614 Acc: 0.96875
Train Iteration #2800:: 0.3460146486759186 Acc: 0.8125
Train Iteration #2850:: 0.3546106815338135 Acc: 0.84375
Training:: Loss: 0.4651 Acc: 0.8496
Validation Iteration #650:: 0.9350420236587524 Acc: 0.78125
Validation Iteration #700:: 0.4526877999305725 Acc: 0.84375
Validation:: Loss: 0.5233 Acc: 0.8229
Epoch 9/49
----------
Train Iteration #2900:: 0.5236204266548157 Acc: 0.78125
Train Iteration #2950:: 0.4501008689403534 Acc: 0.84375
Train Iteration #3000:: 0.38015925884246826 Acc: 0.875
Train Iteration #3050:: 0.41443634033203125 Acc: 0.9375
Train Iteration #3100:: 0.3170762062072754 Acc: 0.96875
Train Iteration #3150:: 0.4153134226799011 Acc: 0.90625
Train Iteration #3200:: 0.518333375453949 Acc: 0.8125
Training:: Loss: 0.4647 Acc: 0.8505
Validation Iteration #750:: 0.4757859408855438 Acc: 0.71875
Validation Iteration #800:: 0.5558345913887024 Acc: 0.8125
Validation:: Loss: 0.5163 Acc: 0.8275
Epoch 10/49
----------
Train Iteration #3250:: 0.5734318494796753 Acc: 0.8125
Train Iteration #3300:: 0.4767535924911499 Acc: 0.8125
Train Iteration #3350:: 0.5437721014022827 Acc: 0.78125
Train Iteration #3400:: 0.40165048837661743 Acc: 0.90625
Train Iteration #3450:: 0.26448893547058105 Acc: 0.9375
Train Iteration #3500:: 0.5618504285812378 Acc: 0.71875
Training:: Loss: 0.4600 Acc: 0.8509
Validation Iteration #850:: 0.5081264972686768 Acc: 0.8125
Validation:: Loss: 0.5601 Acc: 0.7803
Epoch 11/49
----------
Train Iteration #3550:: 0.6167939305305481 Acc: 0.8125
Train Iteration #3600:: 0.5154010057449341 Acc: 0.84375
Train Iteration #3650:: 0.47113707661628723 Acc: 0.875
Train Iteration #3700:: 0.4572386145591736 Acc: 0.84375
Train Iteration #3750:: 0.45526695251464844 Acc: 0.8125
Train Iteration #3800:: 0.5079249739646912 Acc: 0.78125
Train Iteration #3850:: 0.4129956364631653 Acc: 0.84375
Training:: Loss: 0.4420 Acc: 0.8555
Validation Iteration #900:: 0.38828250765800476 Acc: 0.90625
Validation Iteration #950:: 0.42597150802612305 Acc: 0.875
Validation:: Loss: 0.5081 Acc: 0.8342
Epoch 12/49
----------
Train Iteration #3900:: 0.2585451006889343 Acc: 0.96875
Train Iteration #3950:: 0.4677954316139221 Acc: 0.875
Train Iteration #4000:: 0.5081509351730347 Acc: 0.90625
Train Iteration #4050:: 0.31662771105766296 Acc: 0.90625
Train Iteration #4100:: 0.45661768317222595 Acc: 0.875
Train Iteration #4150:: 0.2033032774925232 Acc: 1.0
Training:: Loss: 0.4385 Acc: 0.8617
Validation Iteration #1000:: 0.3968309164047241 Acc: 0.8125
Validation Iteration #1050:: 0.8056831359863281 Acc: 0.8125
Validation:: Loss: 0.5373 Acc: 0.7995
Epoch 13/49
----------
Train Iteration #4200:: 0.494096577167511 Acc: 0.90625
Train Iteration #4250:: 0.27408063411712646 Acc: 1.0
Train Iteration #4300:: 0.4919867515563965 Acc: 0.75
Train Iteration #4350:: 0.3035063147544861 Acc: 0.90625
Train Iteration #4400:: 0.7959636449813843 Acc: 0.65625
Train Iteration #4450:: 0.42914828658103943 Acc: 0.84375
Training:: Loss: 0.4466 Acc: 0.8586
Validation Iteration #1100:: 0.43195343017578125 Acc: 0.875
Validation:: Loss: 0.5100 Acc: 0.8541
Epoch 14/49
----------
Train Iteration #4500:: 0.3684997856616974 Acc: 0.875
Train Iteration #4550:: 0.33428072929382324 Acc: 0.9375
Train Iteration #4600:: 0.39359569549560547 Acc: 0.78125
Train Iteration #4650:: 0.46949946880340576 Acc: 0.84375
Train Iteration #4700:: 0.8861367702484131 Acc: 0.84375
Train Iteration #4750:: 0.5698732137680054 Acc: 0.78125
Train Iteration #4800:: 0.39115363359451294 Acc: 0.875
Training:: Loss: 0.4234 Acc: 0.8645
Validation Iteration #1150:: 0.4653681218624115 Acc: 0.84375
Validation Iteration #1200:: 0.49292534589767456 Acc: 0.875
Validation:: Loss: 0.4997 Acc: 0.8412
Epoch 15/49
----------
Train Iteration #4850:: 0.5551065802574158 Acc: 0.6875
Train Iteration #4900:: 0.464080810546875 Acc: 0.84375
Train Iteration #4950:: 0.5942665338516235 Acc: 0.875
Train Iteration #5000:: 0.40309369564056396 Acc: 0.8125
Train Iteration #5050:: 0.4214347302913666 Acc: 0.875
Train Iteration #5100:: 0.366609662771225 Acc: 0.875
Training:: Loss: 0.4432 Acc: 0.8567
Validation Iteration #1250:: 0.6933364868164062 Acc: 0.8125
Validation:: Loss: 0.4955 Acc: 0.8447
Epoch 16/49
----------
Train Iteration #5150:: 0.48385608196258545 Acc: 0.90625
Train Iteration #5200:: 0.6918560266494751 Acc: 0.78125
Train Iteration #5250:: 0.21238036453723907 Acc: 0.96875
Train Iteration #5300:: 0.40807968378067017 Acc: 0.90625
Train Iteration #5350:: 0.2609662711620331 Acc: 0.90625
Train Iteration #5400:: 0.35082289576530457 Acc: 0.90625
Train Iteration #5450:: 0.5072810649871826 Acc: 0.8125
Training:: Loss: 0.4319 Acc: 0.8654
Validation Iteration #1300:: 0.43910348415374756 Acc: 0.78125
Validation Iteration #1350:: 0.36773842573165894 Acc: 0.90625
Validation:: Loss: 0.5188 Acc: 0.8147
Epoch 17/49
----------
Train Iteration #5500:: 0.789922833442688 Acc: 0.71875
Train Iteration #5550:: 0.3347085118293762 Acc: 0.875
Train Iteration #5600:: 0.5376625061035156 Acc: 0.71875
Train Iteration #5650:: 0.2976571023464203 Acc: 0.96875
Train Iteration #5700:: 0.5877044796943665 Acc: 0.8125
Train Iteration #5750:: 0.5120516419410706 Acc: 0.90625
Training:: Loss: 0.4284 Acc: 0.8595
Validation Iteration #1400:: 0.3510574698448181 Acc: 0.90625
Validation Iteration #1450:: 0.5126079320907593 Acc: 0.84375
Validation:: Loss: 0.4936 Acc: 0.8416
Epoch 18/49
----------
Train Iteration #5800:: 0.32871896028518677 Acc: 0.875
Train Iteration #5850:: 0.45811793208122253 Acc: 0.875
Train Iteration #5900:: 0.32685229182243347 Acc: 0.875
Train Iteration #5950:: 0.3606334626674652 Acc: 0.875
Train Iteration #6000:: 0.3325917720794678 Acc: 0.84375
Train Iteration #6050:: 0.3107450604438782 Acc: 0.90625
Training:: Loss: 0.4329 Acc: 0.8626
Validation Iteration #1500:: 0.44069233536720276 Acc: 0.875
Validation:: Loss: 0.5670 Acc: 0.7760
Epoch 19/49
----------
Train Iteration #6100:: 0.5431509017944336 Acc: 0.78125
Train Iteration #6150:: 0.48754650354385376 Acc: 0.78125
Train Iteration #6200:: 0.28204137086868286 Acc: 0.90625
Train Iteration #6250:: 0.4352629482746124 Acc: 0.875
Train Iteration #6300:: 0.5394214987754822 Acc: 0.875
Train Iteration #6350:: 0.3976691961288452 Acc: 0.875
Train Iteration #6400:: 0.40179741382598877 Acc: 0.84375
Training:: Loss: 0.4399 Acc: 0.8610
Validation Iteration #1550:: 0.4334941506385803 Acc: 0.9375
Validation Iteration #1600:: 0.4893066883087158 Acc: 0.875
Validation:: Loss: 0.5317 Acc: 0.7991
Epoch 20/49
----------
Train Iteration #6450:: 0.5237021446228027 Acc: 0.8125
Train Iteration #6500:: 0.3281928300857544 Acc: 0.9375
Train Iteration #6550:: 0.2784956097602844 Acc: 0.9375
Train Iteration #6600:: 0.38265612721443176 Acc: 0.9375
Train Iteration #6650:: 0.3085595369338989 Acc: 0.9375
Train Iteration #6700:: 0.23110006749629974 Acc: 0.9375
Training:: Loss: 0.4243 Acc: 0.8708
Validation Iteration #1650:: 0.3562999367713928 Acc: 0.90625
Validation Iteration #1700:: 0.13621461391448975 Acc: 1.0
Validation:: Loss: 0.4810 Acc: 0.8502
Epoch 21/49
----------
Train Iteration #6750:: 0.5554741024971008 Acc: 0.84375
Train Iteration #6800:: 0.45296710729599 Acc: 0.78125
Train Iteration #6850:: 0.36835694313049316 Acc: 0.90625
Train Iteration #6900:: 0.304740309715271 Acc: 0.90625
Train Iteration #6950:: 0.3693002760410309 Acc: 0.90625
Train Iteration #7000:: 0.6720108985900879 Acc: 0.75
Train Iteration #7050:: 0.3225225806236267 Acc: 0.90625
Training:: Loss: 0.4145 Acc: 0.8671
Validation Iteration #1750:: 0.7242072820663452 Acc: 0.78125
Validation:: Loss: 0.5173 Acc: 0.8155
Epoch 22/49
----------
Train Iteration #7100:: 0.4656675457954407 Acc: 0.875
Train Iteration #7150:: 0.499900221824646 Acc: 0.78125
Train Iteration #7200:: 0.28659260272979736 Acc: 0.90625
Train Iteration #7250:: 0.6308855414390564 Acc: 0.71875
Train Iteration #7300:: 0.27654045820236206 Acc: 1.0
Train Iteration #7350:: 0.6551001071929932 Acc: 0.84375
Training:: Loss: 0.4242 Acc: 0.8668
Validation Iteration #1800:: 0.43384337425231934 Acc: 0.90625
Validation Iteration #1850:: 0.7052924036979675 Acc: 0.8125
Validation:: Loss: 0.4823 Acc: 0.8549
Epoch 23/49
----------
Train Iteration #7400:: 0.512158989906311 Acc: 0.78125
Train Iteration #7450:: 0.2830427885055542 Acc: 0.84375
Train Iteration #7500:: 0.4902912676334381 Acc: 0.8125
Train Iteration #7550:: 0.36433497071266174 Acc: 0.90625
Train Iteration #7600:: 0.41151177883148193 Acc: 0.875
Train Iteration #7650:: 0.700599193572998 Acc: 0.65625
Train Iteration #7700:: 0.49657168984413147 Acc: 0.78125
Training:: Loss: 0.4358 Acc: 0.8624
Validation Iteration #1900:: 0.5551927089691162 Acc: 0.78125
Validation:: Loss: 0.4822 Acc: 0.8494
Epoch 24/49
----------
Train Iteration #7750:: 0.3351347744464874 Acc: 0.9375
Train Iteration #7800:: 0.5538317561149597 Acc: 0.90625
Train Iteration #7850:: 0.25114595890045166 Acc: 0.96875
Train Iteration #7900:: 0.30403298139572144 Acc: 0.9375
Train Iteration #7950:: 0.323241651058197 Acc: 0.84375
Train Iteration #8000:: 0.3786073327064514 Acc: 0.84375
Training:: Loss: 0.4156 Acc: 0.8728
Validation Iteration #1950:: 0.7014501094818115 Acc: 0.6875
Validation Iteration #2000:: 0.5251795649528503 Acc: 0.71875
Validation:: Loss: 0.5551 Acc: 0.7838
Epoch 25/49
----------
Train Iteration #8050:: 0.31172990798950195 Acc: 0.875
Train Iteration #8100:: 0.40003910660743713 Acc: 0.875
Train Iteration #8150:: 0.15569031238555908 Acc: 1.0
Train Iteration #8200:: 0.29347312450408936 Acc: 0.9375
Train Iteration #8250:: 0.3887123167514801 Acc: 0.90625
Train Iteration #8300:: 0.3883742094039917 Acc: 0.90625
Training:: Loss: 0.4170 Acc: 0.8696
Validation Iteration #2050:: 0.5355321168899536 Acc: 0.78125
Validation Iteration #2100:: 0.5227944254875183 Acc: 0.8125
Validation:: Loss: 0.4924 Acc: 0.8365
Epoch 26/49
----------
Train Iteration #8350:: 0.4985341727733612 Acc: 0.84375
Train Iteration #8400:: 0.3199761211872101 Acc: 0.90625
Train Iteration #8450:: 0.48266667127609253 Acc: 0.8125
Train Iteration #8500:: 0.6954757571220398 Acc: 0.84375
Train Iteration #8550:: 0.5759443640708923 Acc: 0.875
Train Iteration #8600:: 0.45477059483528137 Acc: 0.875
Train Iteration #8650:: 0.1382705271244049 Acc: 1.0
Training:: Loss: 0.4115 Acc: 0.8743
Validation Iteration #2150:: 0.5053778886795044 Acc: 0.875
Validation:: Loss: 0.4884 Acc: 0.8369
Epoch 27/49
----------
Train Iteration #8700:: 0.5582273006439209 Acc: 0.78125
Train Iteration #8750:: 0.2955009341239929 Acc: 0.875
Train Iteration #8800:: 0.257821261882782 Acc: 0.9375
Train Iteration #8850:: 0.37030088901519775 Acc: 0.875
Train Iteration #8900:: 0.2127879112958908 Acc: 1.0
Train Iteration #8950:: 0.2384614497423172 Acc: 0.9375
Training:: Loss: 0.4383 Acc: 0.8601
Validation Iteration #2200:: 0.4945526719093323 Acc: 0.84375
Validation Iteration #2250:: 0.5265094041824341 Acc: 0.84375
Validation:: Loss: 0.4960 Acc: 0.8314
Epoch 28/49
----------
Train Iteration #9000:: 0.435370534658432 Acc: 0.84375
Train Iteration #9050:: 0.29451972246170044 Acc: 0.90625
Train Iteration #9100:: 0.410283625125885 Acc: 0.90625
Train Iteration #9150:: 0.2996577322483063 Acc: 0.9375
Train Iteration #9200:: 0.23171117901802063 Acc: 0.9375
Train Iteration #9250:: 0.3677535355091095 Acc: 0.9375
Train Iteration #9300:: 0.5035222768783569 Acc: 0.6875
Training:: Loss: 0.4086 Acc: 0.8701
Validation Iteration #2300:: 0.43222776055336 Acc: 0.875
Validation:: Loss: 0.4816 Acc: 0.8443
Epoch 29/49
----------
Train Iteration #9350:: 0.6480896472930908 Acc: 0.84375
Train Iteration #9400:: 0.5640332102775574 Acc: 0.75
Train Iteration #9450:: 0.721454381942749 Acc: 0.78125
Train Iteration #9500:: 0.40762847661972046 Acc: 0.84375
Train Iteration #9550:: 0.24963676929473877 Acc: 0.96875
Train Iteration #9600:: 0.4558088779449463 Acc: 0.90625
Training:: Loss: 0.4056 Acc: 0.8697
Validation Iteration #2350:: 0.44006025791168213 Acc: 0.84375
Validation Iteration #2400:: 0.5003108978271484 Acc: 0.8125
Validation:: Loss: 0.4943 Acc: 0.8314
Epoch 30/49
----------
Train Iteration #9650:: 0.23496690392494202 Acc: 0.9375
Train Iteration #9700:: 0.24122147262096405 Acc: 0.9375
Train Iteration #9750:: 0.3545025587081909 Acc: 0.90625
Train Iteration #9800:: 0.5901644229888916 Acc: 0.78125
Train Iteration #9850:: 0.36563318967819214 Acc: 0.9375
Train Iteration #9900:: 0.664789080619812 Acc: 0.8125
Train Iteration #9950:: 0.4409791827201843 Acc: 0.9166666666666666
Training:: Loss: 0.4245 Acc: 0.8723
Validation Iteration #2450:: 0.3789346218109131 Acc: 0.84375
Validation Iteration #2500:: 0.5938107967376709 Acc: 0.875
Validation:: Loss: 0.4823 Acc: 0.8474
Epoch 31/49
----------
Train Iteration #10000:: 0.5052171945571899 Acc: 0.90625
Train Iteration #10050:: 0.31819596886634827 Acc: 0.84375
Train Iteration #10100:: 0.5054455995559692 Acc: 0.84375
Train Iteration #10150:: 0.4030758738517761 Acc: 0.875
Train Iteration #10200:: 0.3056229054927826 Acc: 0.84375
Train Iteration #10250:: 0.3435977101325989 Acc: 0.90625
Training:: Loss: 0.4055 Acc: 0.8752
Validation Iteration #2550:: 0.48990598320961 Acc: 0.875
Validation:: Loss: 0.4747 Acc: 0.8642
Epoch 32/49
----------
Train Iteration #10300:: 0.29858654737472534 Acc: 0.90625
Train Iteration #10350:: 0.6036299467086792 Acc: 0.875
Train Iteration #10400:: 0.36690396070480347 Acc: 0.84375
Train Iteration #10450:: 0.3059641718864441 Acc: 0.9375
Train Iteration #10500:: 0.28669536113739014 Acc: 0.90625
Train Iteration #10550:: 0.6528984308242798 Acc: 0.875
Training:: Loss: 0.4039 Acc: 0.8729
Validation Iteration #2600:: 0.3458966612815857 Acc: 0.875
Validation Iteration #2650:: 0.37675315141677856 Acc: 0.84375
Validation:: Loss: 0.4729 Acc: 0.8533
Epoch 33/49
----------
Train Iteration #10600:: 0.5611468553543091 Acc: 0.75
Train Iteration #10650:: 0.5372200608253479 Acc: 0.875
Train Iteration #10700:: 0.35676056146621704 Acc: 0.875
Train Iteration #10750:: 0.3449443578720093 Acc: 0.90625
Train Iteration #10800:: 0.3868132531642914 Acc: 0.875
Train Iteration #10850:: 0.34050843119621277 Acc: 0.875
Train Iteration #10900:: 0.29354241490364075 Acc: 0.90625
Training:: Loss: 0.4153 Acc: 0.8671
Validation Iteration #2700:: 0.5241481065750122 Acc: 0.875
Validation Iteration #2750:: 0.49585139751434326 Acc: 0.875
Validation:: Loss: 0.4774 Acc: 0.8631
Epoch 34/49
----------
Train Iteration #10950:: 0.4408000111579895 Acc: 0.84375
Train Iteration #11000:: 0.3320457935333252 Acc: 0.90625
Train Iteration #11050:: 0.5291392207145691 Acc: 0.8125
Train Iteration #11100:: 0.2382318377494812 Acc: 0.9375
Train Iteration #11150:: 0.35683268308639526 Acc: 0.875
Train Iteration #11200:: 0.521281361579895 Acc: 0.71875
Training:: Loss: 0.4064 Acc: 0.8739
Validation Iteration #2800:: 0.411960244178772 Acc: 0.875
Validation:: Loss: 0.4727 Acc: 0.8631
Epoch 35/49
----------
Train Iteration #11250:: 0.30405503511428833 Acc: 0.84375
Train Iteration #11300:: 0.5221188068389893 Acc: 0.84375
Train Iteration #11350:: 0.31710565090179443 Acc: 0.875
Train Iteration #11400:: 0.3997054398059845 Acc: 0.9375
Train Iteration #11450:: 0.3526464104652405 Acc: 0.875
Train Iteration #11500:: 0.20295700430870056 Acc: 0.9375
Train Iteration #11550:: 0.179866760969162 Acc: 0.9375
Training:: Loss: 0.4029 Acc: 0.8738
Validation Iteration #2850:: 0.3300620913505554 Acc: 0.90625
Validation Iteration #2900:: 0.24283671379089355 Acc: 0.90625
Validation:: Loss: 0.4775 Acc: 0.8564
Epoch 36/49
----------
Train Iteration #11600:: 0.1934739351272583 Acc: 0.96875
Train Iteration #11650:: 0.3929831385612488 Acc: 0.9375
Train Iteration #11700:: 0.28656190633773804 Acc: 0.96875
Train Iteration #11750:: 0.4881739318370819 Acc: 0.75
Train Iteration #11800:: 0.3554919958114624 Acc: 0.875
Train Iteration #11850:: 0.337514728307724 Acc: 0.875
Training:: Loss: 0.4000 Acc: 0.8729
Validation Iteration #2950:: 0.4029494524002075 Acc: 0.875
Validation:: Loss: 0.4809 Acc: 0.8420
Epoch 37/49
----------
Train Iteration #11900:: 0.5164294242858887 Acc: 0.84375
Train Iteration #11950:: 0.23930533230304718 Acc: 0.9375
Train Iteration #12000:: 0.5352467894554138 Acc: 0.78125
Train Iteration #12050:: 0.47232767939567566 Acc: 0.875
Train Iteration #12100:: 0.28940334916114807 Acc: 0.90625
Train Iteration #12150:: 0.48065078258514404 Acc: 0.84375
Training:: Loss: 0.4140 Acc: 0.8710
Validation Iteration #3000:: 0.7676305770874023 Acc: 0.6875
Validation Iteration #3050:: 0.5700758695602417 Acc: 0.8125
Validation:: Loss: 0.5255 Acc: 0.8084
Epoch 38/49
----------
Train Iteration #12200:: 0.3789615333080292 Acc: 0.8125
Train Iteration #12250:: 0.30535659193992615 Acc: 0.84375
Train Iteration #12300:: 0.4246112108230591 Acc: 0.90625
Train Iteration #12350:: 0.5889537930488586 Acc: 0.875
Train Iteration #12400:: 0.34081894159317017 Acc: 0.90625
Train Iteration #12450:: 0.48270344734191895 Acc: 0.78125
Train Iteration #12500:: 0.2672611474990845 Acc: 0.9375
Training:: Loss: 0.3885 Acc: 0.8763
Validation Iteration #3100:: 0.4685032069683075 Acc: 0.8125
Validation Iteration #3150:: 0.46129950881004333 Acc: 0.9375
Validation:: Loss: 0.4940 Acc: 0.8236
Epoch 39/49
----------
Train Iteration #12550:: 0.33789628744125366 Acc: 0.875
Train Iteration #12600:: 0.5987447500228882 Acc: 0.78125
Train Iteration #12650:: 0.3531944453716278 Acc: 0.90625
Train Iteration #12700:: 0.46422791481018066 Acc: 0.84375
Train Iteration #12750:: 0.6283997297286987 Acc: 0.78125
Train Iteration #12800:: 0.26146310567855835 Acc: 0.9375
Training:: Loss: 0.3937 Acc: 0.8777
Validation Iteration #3200:: 0.4036242365837097 Acc: 0.84375
Validation:: Loss: 0.4709 Acc: 0.8588
Epoch 40/49
----------
Train Iteration #12850:: 0.2817421853542328 Acc: 0.875
Train Iteration #12900:: 0.5981059074401855 Acc: 0.78125
Train Iteration #12950:: 0.1612480729818344 Acc: 0.96875
Train Iteration #13000:: 0.27599528431892395 Acc: 0.9375
Train Iteration #13050:: 0.42737945914268494 Acc: 0.84375
Train Iteration #13100:: 0.2696036696434021 Acc: 0.90625
Train Iteration #13150:: 0.2774506211280823 Acc: 0.90625
Training:: Loss: 0.3912 Acc: 0.8742
Validation Iteration #3250:: 0.42311716079711914 Acc: 0.84375
Validation Iteration #3300:: 0.35565185546875 Acc: 0.90625
Validation:: Loss: 0.4840 Acc: 0.8283
Epoch 41/49
----------
Train Iteration #13200:: 0.2707332968711853 Acc: 0.9375
Train Iteration #13250:: 0.4388432204723358 Acc: 0.71875
Train Iteration #13300:: 0.3342578113079071 Acc: 0.8125
Train Iteration #13350:: 0.1899789273738861 Acc: 0.9375
Train Iteration #13400:: 0.44634509086608887 Acc: 0.875
Train Iteration #13450:: 0.36510616540908813 Acc: 0.90625
Training:: Loss: 0.3893 Acc: 0.8800
Validation Iteration #3350:: 0.6508692502975464 Acc: 0.78125
Validation Iteration #3400:: 0.43636173009872437 Acc: 0.78125
Validation:: Loss: 0.4900 Acc: 0.8225
Epoch 42/49
----------
Train Iteration #13500:: 0.2639368176460266 Acc: 0.875
Train Iteration #13550:: 0.39950454235076904 Acc: 0.875
Train Iteration #13600:: 0.9077922105789185 Acc: 0.75
Train Iteration #13650:: 0.29529717564582825 Acc: 0.875
Train Iteration #13700:: 0.25233715772628784 Acc: 0.84375
Train Iteration #13750:: 0.3468489646911621 Acc: 0.875
Train Iteration #13800:: 0.5754424333572388 Acc: 0.875
Training:: Loss: 0.3891 Acc: 0.8773
Validation Iteration #3450:: 0.24959999322891235 Acc: 0.9375
Validation:: Loss: 0.4744 Acc: 0.8650
Epoch 43/49
----------
Train Iteration #13850:: 0.23123842477798462 Acc: 0.9375
Train Iteration #13900:: 0.7877253293991089 Acc: 0.75
Train Iteration #13950:: 0.29233622550964355 Acc: 0.9375
Train Iteration #14000:: 0.3384162187576294 Acc: 0.90625
Train Iteration #14050:: 0.271646648645401 Acc: 0.90625
Train Iteration #14100:: 0.21180161833763123 Acc: 0.9375
Training:: Loss: 0.3919 Acc: 0.8779
Validation Iteration #3500:: 0.2263733297586441 Acc: 0.96875
Validation Iteration #3550:: 0.5200166702270508 Acc: 0.8125
Validation:: Loss: 0.4702 Acc: 0.8572
Epoch 44/49
----------
Train Iteration #14150:: 0.30202287435531616 Acc: 0.9375
Train Iteration #14200:: 0.39305996894836426 Acc: 0.90625
Train Iteration #14250:: 0.28960585594177246 Acc: 0.9375
Train Iteration #14300:: 0.45244669914245605 Acc: 0.9375
Train Iteration #14350:: 0.7907936573028564 Acc: 0.75
Train Iteration #14400:: 0.39606034755706787 Acc: 0.84375
Training:: Loss: 0.3973 Acc: 0.8780
Validation Iteration #3600:: 0.4020874500274658 Acc: 0.8125
Validation:: Loss: 0.5170 Acc: 0.8108
Epoch 45/49
----------
Train Iteration #14450:: 0.4576372504234314 Acc: 0.875
Train Iteration #14500:: 0.19813291728496552 Acc: 0.90625
Train Iteration #14550:: 0.6133800148963928 Acc: 0.71875
Train Iteration #14600:: 0.21578216552734375 Acc: 0.96875
Train Iteration #14650:: 0.3953453004360199 Acc: 0.875
Train Iteration #14700:: 0.3726910948753357 Acc: 0.9375
Train Iteration #14750:: 0.34849080443382263 Acc: 0.90625
Training:: Loss: 0.3865 Acc: 0.8788
Validation Iteration #3650:: 0.5045575499534607 Acc: 0.8125
Validation Iteration #3700:: 0.5679079294204712 Acc: 0.84375
Validation:: Loss: 0.4826 Acc: 0.8330
Epoch 46/49
----------
Train Iteration #14800:: 0.4233517050743103 Acc: 0.84375
Train Iteration #14850:: 0.2695212960243225 Acc: 0.9375
Train Iteration #14900:: 0.20074768364429474 Acc: 0.9375
Train Iteration #14950:: 0.4231390953063965 Acc: 0.84375
Train Iteration #15000:: 0.5161886215209961 Acc: 0.71875
Train Iteration #15050:: 0.4738118052482605 Acc: 0.90625
Training:: Loss: 0.4022 Acc: 0.8729
Validation Iteration #3750:: 0.4040262997150421 Acc: 0.8125
Validation Iteration #3800:: 0.3446529507637024 Acc: 0.90625
Validation:: Loss: 0.4694 Acc: 0.8638
Epoch 47/49
----------
Train Iteration #15100:: 0.598610520362854 Acc: 0.90625
Train Iteration #15150:: 0.29683762788772583 Acc: 0.96875
Train Iteration #15200:: 0.2760998606681824 Acc: 0.875
Train Iteration #15250:: 0.40146076679229736 Acc: 0.84375
Train Iteration #15300:: 0.2971072793006897 Acc: 0.875
Train Iteration #15350:: 0.25836658477783203 Acc: 0.90625
Train Iteration #15400:: 0.34357380867004395 Acc: 0.8125
Training:: Loss: 0.4012 Acc: 0.8761
Validation Iteration #3850:: 0.24862101674079895 Acc: 0.90625
Validation:: Loss: 0.4678 Acc: 0.8588
Epoch 48/49
----------
Train Iteration #15450:: 0.22082272171974182 Acc: 0.96875
Train Iteration #15500:: 0.3468301296234131 Acc: 0.90625
Train Iteration #15550:: 0.5281268954277039 Acc: 0.875
Train Iteration #15600:: 0.1963149905204773 Acc: 0.9375
Train Iteration #15650:: 0.35947972536087036 Acc: 0.875
Train Iteration #15700:: 0.27830731868743896 Acc: 0.96875
Training:: Loss: 0.4004 Acc: 0.8735
Validation Iteration #3900:: 0.6343481540679932 Acc: 0.75
Validation Iteration #3950:: 0.6021193861961365 Acc: 0.84375
Validation:: Loss: 0.4881 Acc: 0.8291
Epoch 49/49
----------
Train Iteration #15750:: 0.8583460450172424 Acc: 0.75
Train Iteration #15800:: 0.522757887840271 Acc: 0.6875
Train Iteration #15850:: 0.7144986391067505 Acc: 0.65625
Train Iteration #15900:: 0.2606838047504425 Acc: 0.9375
Train Iteration #15950:: 0.2773580551147461 Acc: 0.9375
Train Iteration #16000:: 0.3225613832473755 Acc: 0.84375
Training:: Loss: 0.3887 Acc: 0.8786
Validation Iteration #4000:: 0.44594302773475647 Acc: 0.84375
Validation:: Loss: 0.4707 Acc: 0.8533
Best Validation Acc: 0.865002
End time:3:11:19.150923
Program Complete
Average Train Loss:0.44069174915866094
Average Validation Loss:0.5176348951738583
Average Train Accuracy:0.856824034334764
Average Validation Accuracy:0.8203979711275848
