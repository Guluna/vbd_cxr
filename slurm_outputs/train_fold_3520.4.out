Cerberus running for fold: 4
cuda
Program started
Epoch 0/49
----------
Train Iteration #0:: 1.1775221824645996 Acc: 0.46875
Train Iteration #50:: 0.9479560256004333 Acc: 0.5
Train Iteration #100:: 0.9287397861480713 Acc: 0.4375
Train Iteration #150:: 0.8003586530685425 Acc: 0.6875
Train Iteration #200:: 0.8191924095153809 Acc: 0.53125
Train Iteration #250:: 0.6533477306365967 Acc: 0.75
Train Iteration #300:: 0.824294924736023 Acc: 0.84375
Training:: Loss: 0.8398 Acc: 0.6009
Validation Iteration #0:: 0.7054505348205566 Acc: 0.8125
Validation Iteration #50:: 0.5269294381141663 Acc: 0.8125
Validation:: Loss: 0.7284 Acc: 0.6824
Epoch 1/49
----------
Train Iteration #350:: 0.7094129323959351 Acc: 0.5625
Train Iteration #400:: 0.6537909507751465 Acc: 0.65625
Train Iteration #450:: 0.5932715535163879 Acc: 0.8125
Train Iteration #500:: 0.7307546138763428 Acc: 0.78125
Train Iteration #550:: 0.7769679427146912 Acc: 0.59375
Train Iteration #600:: 0.5867264270782471 Acc: 0.78125
Training:: Loss: 0.6482 Acc: 0.7597
Validation Iteration #100:: 0.6397300362586975 Acc: 0.75
Validation Iteration #150:: 0.5404261350631714 Acc: 0.78125
Validation:: Loss: 0.6770 Acc: 0.6992
Epoch 2/49
----------
Train Iteration #650:: 0.6550143957138062 Acc: 0.8125
Train Iteration #700:: 0.6258449554443359 Acc: 0.75
Train Iteration #750:: 0.49578142166137695 Acc: 0.875
Train Iteration #800:: 0.35300108790397644 Acc: 0.84375
Train Iteration #850:: 0.6255407333374023 Acc: 0.78125
Train Iteration #900:: 0.5779649019241333 Acc: 0.84375
Train Iteration #950:: 0.5162902474403381 Acc: 0.875
Training:: Loss: 0.5752 Acc: 0.8012
Validation Iteration #200:: 0.4196476936340332 Acc: 0.9375
Validation:: Loss: 0.6029 Acc: 0.7749
Epoch 3/49
----------
Train Iteration #1000:: 0.46440184116363525 Acc: 1.0
Train Iteration #1050:: 0.6356043815612793 Acc: 0.8125
Train Iteration #1100:: 0.5586673617362976 Acc: 0.9375
Train Iteration #1150:: 0.5891073942184448 Acc: 0.84375
Train Iteration #1200:: 0.5462218523025513 Acc: 0.71875
Train Iteration #1250:: 0.5668627619743347 Acc: 0.84375
Training:: Loss: 0.5353 Acc: 0.8246
Validation Iteration #250:: 0.622579038143158 Acc: 0.75
Validation Iteration #300:: 0.5107313394546509 Acc: 0.875
Validation:: Loss: 0.5536 Acc: 0.8307
Epoch 4/49
----------
Train Iteration #1300:: 0.5967483520507812 Acc: 0.71875
Train Iteration #1350:: 0.6489726901054382 Acc: 0.6875
Train Iteration #1400:: 0.3432779610157013 Acc: 0.96875
Train Iteration #1450:: 0.4895208775997162 Acc: 0.8125
Train Iteration #1500:: 0.36530613899230957 Acc: 0.875
Train Iteration #1550:: 0.7153035402297974 Acc: 0.71875
Train Iteration #1600:: 0.4782636761665344 Acc: 0.90625
Training:: Loss: 0.5123 Acc: 0.8313
Validation Iteration #350:: 0.5755268931388855 Acc: 0.6875
Validation Iteration #400:: 0.49583810567855835 Acc: 0.84375
Validation:: Loss: 0.5369 Acc: 0.8463
Epoch 5/49
----------
Train Iteration #1650:: 0.821405291557312 Acc: 0.6875
Train Iteration #1700:: 0.32235679030418396 Acc: 0.9375
Train Iteration #1750:: 0.44173967838287354 Acc: 0.9375
Train Iteration #1800:: 0.35760533809661865 Acc: 0.875
Train Iteration #1850:: 0.34768229722976685 Acc: 0.875
Train Iteration #1900:: 0.41448846459388733 Acc: 0.84375
Training:: Loss: 0.5019 Acc: 0.8350
Validation Iteration #450:: 0.6417279839515686 Acc: 0.84375
Validation:: Loss: 0.5540 Acc: 0.7889
Epoch 6/49
----------
Train Iteration #1950:: 0.3844950795173645 Acc: 0.8125
Train Iteration #2000:: 0.5601871609687805 Acc: 0.78125
Train Iteration #2050:: 0.41260552406311035 Acc: 0.84375
Train Iteration #2100:: 0.4411585032939911 Acc: 0.78125
Train Iteration #2150:: 0.370977520942688 Acc: 0.8125
Train Iteration #2200:: 0.4795476198196411 Acc: 0.875
Training:: Loss: 0.4813 Acc: 0.8427
Validation Iteration #500:: 0.4434191584587097 Acc: 0.84375
Validation Iteration #550:: 0.7243893146514893 Acc: 0.75
Validation:: Loss: 0.5889 Acc: 0.7565
Epoch 7/49
----------
Train Iteration #2250:: 0.47311919927597046 Acc: 0.78125
Train Iteration #2300:: 0.5247616767883301 Acc: 0.875
Train Iteration #2350:: 0.3673008382320404 Acc: 0.9375
Train Iteration #2400:: 0.48284828662872314 Acc: 0.84375
Train Iteration #2450:: 0.3079773187637329 Acc: 0.96875
Train Iteration #2500:: 0.24236351251602173 Acc: 0.9375
Train Iteration #2550:: 0.4504431188106537 Acc: 0.84375
Training:: Loss: 0.4811 Acc: 0.8431
Validation Iteration #600:: 0.7430513501167297 Acc: 0.8125
Validation:: Loss: 0.5102 Acc: 0.8529
Epoch 8/49
----------
Train Iteration #2600:: 0.45974624156951904 Acc: 0.90625
Train Iteration #2650:: 0.6258504986763 Acc: 0.84375
Train Iteration #2700:: 0.8102880716323853 Acc: 0.875
Train Iteration #2750:: 0.46083569526672363 Acc: 0.9375
Train Iteration #2800:: 0.2485075443983078 Acc: 1.0
Train Iteration #2850:: 0.41769593954086304 Acc: 0.84375
Training:: Loss: 0.4789 Acc: 0.8474
Validation Iteration #650:: 0.48087078332901 Acc: 0.84375
Validation Iteration #700:: 0.39843058586120605 Acc: 0.9375
Validation:: Loss: 0.5173 Acc: 0.8182
Epoch 9/49
----------
Train Iteration #2900:: 0.43793821334838867 Acc: 0.78125
Train Iteration #2950:: 0.41731953620910645 Acc: 0.875
Train Iteration #3000:: 0.4354442358016968 Acc: 0.8125
Train Iteration #3050:: 0.3654406666755676 Acc: 0.875
Train Iteration #3100:: 0.39199092984199524 Acc: 0.875
Train Iteration #3150:: 0.5504932403564453 Acc: 0.71875
Train Iteration #3200:: 0.6016284227371216 Acc: 0.8125
Training:: Loss: 0.4654 Acc: 0.8517
Validation Iteration #750:: 0.5071769952774048 Acc: 0.78125
Validation Iteration #800:: 0.5908181667327881 Acc: 0.78125
Validation:: Loss: 0.5128 Acc: 0.8205
Epoch 10/49
----------
Train Iteration #3250:: 0.4532597064971924 Acc: 0.90625
Train Iteration #3300:: 0.5097241401672363 Acc: 0.84375
Train Iteration #3350:: 0.27521663904190063 Acc: 0.9375
Train Iteration #3400:: 0.2812398374080658 Acc: 0.96875
Train Iteration #3450:: 0.421856164932251 Acc: 0.875
Train Iteration #3500:: 0.3778146207332611 Acc: 0.9375
Training:: Loss: 0.4541 Acc: 0.8556
Validation Iteration #850:: 0.3254610598087311 Acc: 0.9375
Validation:: Loss: 0.4965 Acc: 0.8529
Epoch 11/49
----------
Train Iteration #3550:: 0.32134222984313965 Acc: 0.875
Train Iteration #3600:: 0.53516685962677 Acc: 0.78125
Train Iteration #3650:: 0.42694607377052307 Acc: 0.8125
Train Iteration #3700:: 0.3312207758426666 Acc: 0.84375
Train Iteration #3750:: 0.5254825949668884 Acc: 0.875
Train Iteration #3800:: 0.44879260659217834 Acc: 0.8125
Train Iteration #3850:: 0.5799217224121094 Acc: 0.8125
Training:: Loss: 0.4581 Acc: 0.8526
Validation Iteration #900:: 0.4690273106098175 Acc: 0.84375
Validation Iteration #950:: 0.4719320237636566 Acc: 0.78125
Validation:: Loss: 0.5176 Acc: 0.8100
Epoch 12/49
----------
Train Iteration #3900:: 0.7063266038894653 Acc: 0.78125
Train Iteration #3950:: 0.6950628757476807 Acc: 0.78125
Train Iteration #4000:: 0.5215268135070801 Acc: 0.8125
Train Iteration #4050:: 0.3216383755207062 Acc: 0.90625
Train Iteration #4100:: 0.4848170876502991 Acc: 0.8125
Train Iteration #4150:: 0.638163685798645 Acc: 0.84375
Training:: Loss: 0.4630 Acc: 0.8534
Validation Iteration #1000:: 0.34380030632019043 Acc: 0.8125
Validation Iteration #1050:: 0.9563409686088562 Acc: 0.78125
Validation:: Loss: 0.4965 Acc: 0.8291
Epoch 13/49
----------
Train Iteration #4200:: 0.5057303309440613 Acc: 0.84375
Train Iteration #4250:: 0.24198603630065918 Acc: 0.90625
Train Iteration #4300:: 0.4181062877178192 Acc: 0.71875
Train Iteration #4350:: 0.3217490017414093 Acc: 0.9375
Train Iteration #4400:: 0.3810109794139862 Acc: 0.84375
Train Iteration #4450:: 0.41024643182754517 Acc: 0.8125
Training:: Loss: 0.4560 Acc: 0.8529
Validation Iteration #1100:: 0.8482967615127563 Acc: 0.59375
Validation:: Loss: 0.6462 Acc: 0.7214
Epoch 14/49
----------
Train Iteration #4500:: 0.5137978196144104 Acc: 0.75
Train Iteration #4550:: 0.5125109553337097 Acc: 0.78125
Train Iteration #4600:: 0.30190426111221313 Acc: 0.9375
Train Iteration #4650:: 0.443502813577652 Acc: 0.8125
Train Iteration #4700:: 0.505213737487793 Acc: 0.90625
Train Iteration #4750:: 0.7581621408462524 Acc: 0.90625
Train Iteration #4800:: 0.2571086287498474 Acc: 0.96875
Training:: Loss: 0.4517 Acc: 0.8561
Validation Iteration #1150:: 0.3721795380115509 Acc: 0.875
Validation Iteration #1200:: 0.4795718789100647 Acc: 0.8125
Validation:: Loss: 0.5051 Acc: 0.8166
Epoch 15/49
----------
Train Iteration #4850:: 0.3781896233558655 Acc: 0.875
Train Iteration #4900:: 0.4901895821094513 Acc: 0.84375
Train Iteration #4950:: 0.3989010453224182 Acc: 0.90625
Train Iteration #5000:: 0.8089302182197571 Acc: 0.75
Train Iteration #5050:: 0.574947714805603 Acc: 0.90625
Train Iteration #5100:: 0.29728421568870544 Acc: 0.875
Training:: Loss: 0.4421 Acc: 0.8596
Validation Iteration #1250:: 0.5922859907150269 Acc: 0.8125
Validation:: Loss: 0.5770 Acc: 0.7573
Epoch 16/49
----------
Train Iteration #5150:: 0.6897057294845581 Acc: 0.875
Train Iteration #5200:: 0.23751673102378845 Acc: 0.90625
Train Iteration #5250:: 0.23899675905704498 Acc: 0.96875
Train Iteration #5300:: 0.3375431299209595 Acc: 0.96875
Train Iteration #5350:: 0.39288121461868286 Acc: 0.90625
Train Iteration #5400:: 0.29329150915145874 Acc: 0.9375
Train Iteration #5450:: 0.23964497447013855 Acc: 0.96875
Training:: Loss: 0.4372 Acc: 0.8607
Validation Iteration #1300:: 0.758100152015686 Acc: 0.71875
Validation Iteration #1350:: 0.41112059354782104 Acc: 0.84375
Validation:: Loss: 0.5818 Acc: 0.7546
Epoch 17/49
----------
Train Iteration #5500:: 0.29153966903686523 Acc: 0.9375
Train Iteration #5550:: 0.31448519229888916 Acc: 0.875
Train Iteration #5600:: 0.3818761110305786 Acc: 0.875
Train Iteration #5650:: 0.27657079696655273 Acc: 0.90625
Train Iteration #5700:: 0.4081573486328125 Acc: 0.84375
Train Iteration #5750:: 0.5763967633247375 Acc: 0.84375
Training:: Loss: 0.4257 Acc: 0.8665
Validation Iteration #1400:: 0.5046480298042297 Acc: 0.84375
Validation Iteration #1450:: 0.5638786554336548 Acc: 0.78125
Validation:: Loss: 0.5299 Acc: 0.7897
Epoch 18/49
----------
Train Iteration #5800:: 0.23482322692871094 Acc: 0.96875
Train Iteration #5850:: 0.46936482191085815 Acc: 0.875
Train Iteration #5900:: 0.4083499312400818 Acc: 0.84375
Train Iteration #5950:: 0.5813300013542175 Acc: 0.84375
Train Iteration #6000:: 0.4988577365875244 Acc: 0.78125
Train Iteration #6050:: 0.3630245327949524 Acc: 0.875
Training:: Loss: 0.4271 Acc: 0.8648
Validation Iteration #1500:: 0.7520966529846191 Acc: 0.84375
Validation:: Loss: 0.4824 Acc: 0.8638
Epoch 19/49
----------
Train Iteration #6100:: 0.48977789282798767 Acc: 0.90625
Train Iteration #6150:: 0.48585352301597595 Acc: 0.78125
Train Iteration #6200:: 0.3163512945175171 Acc: 0.96875
Train Iteration #6250:: 0.22632545232772827 Acc: 0.9375
Train Iteration #6300:: 0.38444381952285767 Acc: 0.90625
Train Iteration #6350:: 0.42169874906539917 Acc: 0.90625
Train Iteration #6400:: 0.35857531428337097 Acc: 0.875
Training:: Loss: 0.4330 Acc: 0.8666
Validation Iteration #1550:: 0.5106709003448486 Acc: 0.8125
Validation Iteration #1600:: 0.6234370470046997 Acc: 0.65625
Validation:: Loss: 0.5523 Acc: 0.7745
Epoch 20/49
----------
Train Iteration #6450:: 0.46509885787963867 Acc: 0.875
Train Iteration #6500:: 0.21619607508182526 Acc: 0.9375
Train Iteration #6550:: 0.31287437677383423 Acc: 0.875
Train Iteration #6600:: 0.36685582995414734 Acc: 0.8125
Train Iteration #6650:: 0.36400631070137024 Acc: 0.84375
Train Iteration #6700:: 0.6496590971946716 Acc: 0.875
Training:: Loss: 0.4260 Acc: 0.8678
Validation Iteration #1650:: 0.9973204135894775 Acc: 0.71875
Validation Iteration #1700:: 0.9153621196746826 Acc: 0.6666666666666666
Validation:: Loss: 0.5005 Acc: 0.8197
Epoch 21/49
----------
Train Iteration #6750:: 0.5960074663162231 Acc: 0.78125
Train Iteration #6800:: 0.25615394115448 Acc: 0.9375
Train Iteration #6850:: 0.413095623254776 Acc: 0.875
Train Iteration #6900:: 0.3472670912742615 Acc: 0.875
Train Iteration #6950:: 0.3730071783065796 Acc: 0.96875
Train Iteration #7000:: 0.3952052891254425 Acc: 0.90625
Train Iteration #7050:: 0.8311256170272827 Acc: 0.875
Training:: Loss: 0.4283 Acc: 0.8651
Validation Iteration #1750:: 0.5992167592048645 Acc: 0.71875
Validation:: Loss: 0.5858 Acc: 0.7577
Epoch 22/49
----------
Train Iteration #7100:: 0.3321923613548279 Acc: 0.96875
Train Iteration #7150:: 0.37672877311706543 Acc: 0.84375
Train Iteration #7200:: 0.5729193091392517 Acc: 0.8125
Train Iteration #7250:: 0.7810081243515015 Acc: 0.71875
Train Iteration #7300:: 0.41898608207702637 Acc: 0.84375
Train Iteration #7350:: 0.32793182134628296 Acc: 0.96875
Training:: Loss: 0.4132 Acc: 0.8700
Validation Iteration #1800:: 0.4182080328464508 Acc: 0.8125
Validation Iteration #1850:: 0.4254055619239807 Acc: 0.8125
Validation:: Loss: 0.5239 Acc: 0.7967
Epoch 23/49
----------
Train Iteration #7400:: 0.44692203402519226 Acc: 0.84375
Train Iteration #7450:: 0.36675775051116943 Acc: 0.90625
Train Iteration #7500:: 0.4961257874965668 Acc: 0.9375
Train Iteration #7550:: 0.33351653814315796 Acc: 0.875
Train Iteration #7600:: 0.9271384477615356 Acc: 0.78125
Train Iteration #7650:: 0.5204654932022095 Acc: 0.84375
Train Iteration #7700:: 0.3982927203178406 Acc: 0.8125
Training:: Loss: 0.4188 Acc: 0.8702
Validation Iteration #1900:: 0.8621054887771606 Acc: 0.75
Validation:: Loss: 0.5212 Acc: 0.8018
Epoch 24/49
----------
Train Iteration #7750:: 0.46444663405418396 Acc: 0.84375
Train Iteration #7800:: 0.41744253039360046 Acc: 0.84375
Train Iteration #7850:: 0.38954055309295654 Acc: 0.90625
Train Iteration #7900:: 0.5031402111053467 Acc: 0.78125
Train Iteration #7950:: 0.31051936745643616 Acc: 0.9375
Train Iteration #8000:: 0.11484400928020477 Acc: 0.96875
Training:: Loss: 0.4053 Acc: 0.8759
Validation Iteration #1950:: 0.4034542441368103 Acc: 0.84375
Validation Iteration #2000:: 0.9977928400039673 Acc: 0.65625
Validation:: Loss: 0.5487 Acc: 0.7827
Epoch 25/49
----------
Train Iteration #8050:: 0.4468972682952881 Acc: 0.78125
Train Iteration #8100:: 0.357879102230072 Acc: 0.84375
Train Iteration #8150:: 0.3306015729904175 Acc: 0.90625
Train Iteration #8200:: 0.3800661563873291 Acc: 0.875
Train Iteration #8250:: 0.23658451437950134 Acc: 0.9375
Train Iteration #8300:: 0.3450968563556671 Acc: 0.9375
Training:: Loss: 0.4185 Acc: 0.8692
Validation Iteration #2050:: 0.28544437885284424 Acc: 0.90625
Validation Iteration #2100:: 0.3559228181838989 Acc: 0.78125
Validation:: Loss: 0.4953 Acc: 0.8233
Epoch 26/49
----------
Train Iteration #8350:: 0.47739705443382263 Acc: 0.71875
Train Iteration #8400:: 0.5785651803016663 Acc: 0.8125
Train Iteration #8450:: 0.34320566058158875 Acc: 0.90625
Train Iteration #8500:: 0.3211440443992615 Acc: 0.875
Train Iteration #8550:: 0.31350457668304443 Acc: 0.96875
Train Iteration #8600:: 0.49071264266967773 Acc: 0.9375
Train Iteration #8650:: 0.2440088391304016 Acc: 0.90625
Training:: Loss: 0.4280 Acc: 0.8675
Validation Iteration #2150:: 0.6011185646057129 Acc: 0.8125
Validation:: Loss: 0.5163 Acc: 0.8010
Epoch 27/49
----------
Train Iteration #8700:: 0.43299978971481323 Acc: 0.875
Train Iteration #8750:: 0.48315462470054626 Acc: 0.78125
Train Iteration #8800:: 0.29592061042785645 Acc: 0.875
Train Iteration #8850:: 0.415078341960907 Acc: 0.9375
Train Iteration #8900:: 0.33741694688796997 Acc: 0.875
Train Iteration #8950:: 0.45938968658447266 Acc: 0.875
Training:: Loss: 0.4063 Acc: 0.8749
Validation Iteration #2200:: 0.19473205506801605 Acc: 0.96875
Validation Iteration #2250:: 0.41831302642822266 Acc: 0.84375
Validation:: Loss: 0.4703 Acc: 0.8662
Epoch 28/49
----------
Train Iteration #9000:: 0.5467923283576965 Acc: 0.84375
Train Iteration #9050:: 0.4710236191749573 Acc: 0.8125
Train Iteration #9100:: 0.7043750882148743 Acc: 0.6875
Train Iteration #9150:: 0.7629842162132263 Acc: 0.71875
Train Iteration #9200:: 0.3458826243877411 Acc: 0.875
Train Iteration #9250:: 0.4370531439781189 Acc: 0.84375
Train Iteration #9300:: 0.3063119649887085 Acc: 0.9375
Training:: Loss: 0.4099 Acc: 0.8722
Validation Iteration #2300:: 0.3166816830635071 Acc: 0.9375
Validation:: Loss: 0.4740 Acc: 0.8486
Epoch 29/49
----------
Train Iteration #9350:: 0.5260099172592163 Acc: 0.8125
Train Iteration #9400:: 0.39386361837387085 Acc: 0.875
Train Iteration #9450:: 0.6548154950141907 Acc: 0.6875
Train Iteration #9500:: 0.7919120788574219 Acc: 0.875
Train Iteration #9550:: 0.17852215468883514 Acc: 0.9375
Train Iteration #9600:: 0.23148572444915771 Acc: 0.96875
Training:: Loss: 0.4103 Acc: 0.8722
Validation Iteration #2350:: 0.3172028958797455 Acc: 0.96875
Validation Iteration #2400:: 0.2829074263572693 Acc: 0.9375
Validation:: Loss: 0.4906 Acc: 0.8264
Epoch 30/49
----------
Train Iteration #9650:: 0.4481826424598694 Acc: 0.71875
Train Iteration #9700:: 0.2358112931251526 Acc: 0.96875
Train Iteration #9750:: 0.541224479675293 Acc: 0.84375
Train Iteration #9800:: 0.3794999122619629 Acc: 0.84375
Train Iteration #9850:: 0.48751354217529297 Acc: 0.84375
Train Iteration #9900:: 0.3128604292869568 Acc: 0.875
Train Iteration #9950:: 0.44331344962120056 Acc: 0.75
Training:: Loss: 0.4000 Acc: 0.8739
Validation Iteration #2450:: 0.5117747783660889 Acc: 0.84375
Validation Iteration #2500:: 0.3956910967826843 Acc: 0.8125
Validation:: Loss: 0.4688 Acc: 0.8619
Epoch 31/49
----------
Train Iteration #10000:: 0.32116034626960754 Acc: 0.875
Train Iteration #10050:: 0.45332345366477966 Acc: 0.90625
Train Iteration #10100:: 0.4661544859409332 Acc: 0.8125
Train Iteration #10150:: 0.18624550104141235 Acc: 0.96875
Train Iteration #10200:: 0.3474721610546112 Acc: 0.875
Train Iteration #10250:: 0.2850448787212372 Acc: 0.875
Training:: Loss: 0.4238 Acc: 0.8626
Validation Iteration #2550:: 0.4729181230068207 Acc: 0.8125
Validation:: Loss: 0.4760 Acc: 0.8420
Epoch 32/49
----------
Train Iteration #10300:: 0.17814597487449646 Acc: 0.9375
Train Iteration #10350:: 0.5802502036094666 Acc: 0.78125
Train Iteration #10400:: 0.4748366177082062 Acc: 0.84375
Train Iteration #10450:: 0.23027455806732178 Acc: 0.9375
Train Iteration #10500:: 0.2947533130645752 Acc: 0.90625
Train Iteration #10550:: 0.4772557318210602 Acc: 0.8125
Training:: Loss: 0.4061 Acc: 0.8734
Validation Iteration #2600:: 0.8849920034408569 Acc: 0.625
Validation Iteration #2650:: 0.44212010502815247 Acc: 0.84375
Validation:: Loss: 0.5159 Acc: 0.7998
Epoch 33/49
----------
Train Iteration #10600:: 0.5675469636917114 Acc: 0.84375
Train Iteration #10650:: 0.3697027564048767 Acc: 0.84375
Train Iteration #10700:: 0.3132588267326355 Acc: 0.875
Train Iteration #10750:: 0.4391438066959381 Acc: 0.84375
Train Iteration #10800:: 0.47558045387268066 Acc: 0.8125
Train Iteration #10850:: 0.6875629425048828 Acc: 0.6875
Train Iteration #10900:: 0.5247118473052979 Acc: 0.875
Training:: Loss: 0.3903 Acc: 0.8805
Validation Iteration #2700:: 0.37362244725227356 Acc: 0.84375
Validation Iteration #2750:: 0.5392646789550781 Acc: 0.84375
Validation:: Loss: 0.4816 Acc: 0.8330
Epoch 34/49
----------
Train Iteration #10950:: 0.2734004557132721 Acc: 0.9375
Train Iteration #11000:: 0.19698083400726318 Acc: 0.96875
Train Iteration #11050:: 0.38381773233413696 Acc: 0.90625
Train Iteration #11100:: 0.2534668445587158 Acc: 0.90625
Train Iteration #11150:: 0.19828370213508606 Acc: 0.96875
Train Iteration #11200:: 0.4056461453437805 Acc: 0.875
Training:: Loss: 0.3938 Acc: 0.8790
Validation Iteration #2800:: 0.4632587134838104 Acc: 0.90625
Validation:: Loss: 0.4672 Acc: 0.8642
Epoch 35/49
----------
Train Iteration #11250:: 0.4347335696220398 Acc: 0.8125
Train Iteration #11300:: 0.43284276127815247 Acc: 0.75
Train Iteration #11350:: 0.5013661980628967 Acc: 0.90625
Train Iteration #11400:: 0.3657452166080475 Acc: 0.78125
Train Iteration #11450:: 0.5649327039718628 Acc: 0.875
Train Iteration #11500:: 0.23842032253742218 Acc: 0.90625
Train Iteration #11550:: 0.5424032211303711 Acc: 0.84375
Training:: Loss: 0.4075 Acc: 0.8700
Validation Iteration #2850:: 0.2501993179321289 Acc: 0.9375
Validation Iteration #2900:: 0.8331873416900635 Acc: 0.6875
Validation:: Loss: 0.4839 Acc: 0.8303
Epoch 36/49
----------
Train Iteration #11600:: 0.48215043544769287 Acc: 0.78125
Train Iteration #11650:: 0.5475621223449707 Acc: 0.875
Train Iteration #11700:: 0.4845101237297058 Acc: 0.875
Train Iteration #11750:: 0.43222033977508545 Acc: 0.75
Train Iteration #11800:: 0.21046961843967438 Acc: 0.96875
Train Iteration #11850:: 0.3830253481864929 Acc: 0.90625
Training:: Loss: 0.3927 Acc: 0.8755
Validation Iteration #2950:: 0.4429832696914673 Acc: 0.875
Validation:: Loss: 0.4742 Acc: 0.8424
Epoch 37/49
----------
Train Iteration #11900:: 0.528594434261322 Acc: 0.84375
Train Iteration #11950:: 0.6197279095649719 Acc: 0.875
Train Iteration #12000:: 0.5453749299049377 Acc: 0.875
Train Iteration #12050:: 0.4035898745059967 Acc: 0.9375
Train Iteration #12100:: 0.315869003534317 Acc: 0.90625
Train Iteration #12150:: 0.5109190940856934 Acc: 0.78125
Training:: Loss: 0.4038 Acc: 0.8737
Validation Iteration #3000:: 0.23575571179389954 Acc: 0.9375
Validation Iteration #3050:: 0.4940550923347473 Acc: 0.90625
Validation:: Loss: 0.4719 Acc: 0.8474
Epoch 38/49
----------
Train Iteration #12200:: 0.39829176664352417 Acc: 0.9375
Train Iteration #12250:: 0.36036422848701477 Acc: 0.90625
Train Iteration #12300:: 0.27713871002197266 Acc: 0.90625
Train Iteration #12350:: 0.7259317636489868 Acc: 0.875
Train Iteration #12400:: 0.6848928332328796 Acc: 0.875
Train Iteration #12450:: 0.3204963505268097 Acc: 0.9375
Train Iteration #12500:: 0.4428531527519226 Acc: 0.875
Training:: Loss: 0.4086 Acc: 0.8753
Validation Iteration #3100:: 0.268964946269989 Acc: 0.90625
Validation Iteration #3150:: 0.33883804082870483 Acc: 0.78125
Validation:: Loss: 0.5315 Acc: 0.7913
Epoch 39/49
----------
Train Iteration #12550:: 0.2867441475391388 Acc: 0.875
Train Iteration #12600:: 0.38666313886642456 Acc: 0.90625
Train Iteration #12650:: 0.3729262948036194 Acc: 0.875
Train Iteration #12700:: 0.7101411819458008 Acc: 0.8125
Train Iteration #12750:: 0.38876718282699585 Acc: 0.90625
Train Iteration #12800:: 0.41264280676841736 Acc: 0.78125
Training:: Loss: 0.4164 Acc: 0.8695
Validation Iteration #3200:: 0.7212187051773071 Acc: 0.8125
Validation:: Loss: 0.4634 Acc: 0.8619
Epoch 40/49
----------
Train Iteration #12850:: 0.23349089920520782 Acc: 0.9375
Train Iteration #12900:: 0.2841569781303406 Acc: 0.9375
Train Iteration #12950:: 0.35915857553482056 Acc: 0.96875
Train Iteration #13000:: 0.586286187171936 Acc: 0.84375
Train Iteration #13050:: 0.342185914516449 Acc: 0.875
Train Iteration #13100:: 0.38155806064605713 Acc: 0.90625
Train Iteration #13150:: 0.190486341714859 Acc: 0.96875
Training:: Loss: 0.3980 Acc: 0.8752
Validation Iteration #3250:: 0.4325588345527649 Acc: 0.875
Validation Iteration #3300:: 0.909959614276886 Acc: 0.65625
Validation:: Loss: 0.4861 Acc: 0.8272
Epoch 41/49
----------
Train Iteration #13200:: 0.5831645131111145 Acc: 0.78125
Train Iteration #13250:: 0.36110061407089233 Acc: 0.90625
Train Iteration #13300:: 0.2739797532558441 Acc: 0.90625
Train Iteration #13350:: 0.50452721118927 Acc: 0.90625
Train Iteration #13400:: 0.516345739364624 Acc: 0.90625
Train Iteration #13450:: 0.4477649927139282 Acc: 0.78125
Training:: Loss: 0.4103 Acc: 0.8744
Validation Iteration #3350:: 0.2536173462867737 Acc: 0.90625
Validation Iteration #3400:: 0.6340206265449524 Acc: 0.78125
Validation:: Loss: 0.4684 Acc: 0.8474
Epoch 42/49
----------
Train Iteration #13500:: 0.27463388442993164 Acc: 0.90625
Train Iteration #13550:: 0.43187394738197327 Acc: 0.90625
Train Iteration #13600:: 0.4203115999698639 Acc: 0.8125
Train Iteration #13650:: 0.1853390783071518 Acc: 0.9375
Train Iteration #13700:: 0.27852821350097656 Acc: 0.90625
Train Iteration #13750:: 0.2048710286617279 Acc: 0.96875
Train Iteration #13800:: 0.4698633551597595 Acc: 0.8125
Training:: Loss: 0.3946 Acc: 0.8799
Validation Iteration #3450:: 0.5347744226455688 Acc: 0.71875
Validation:: Loss: 0.4782 Acc: 0.8342
Epoch 43/49
----------
Train Iteration #13850:: 0.46036669611930847 Acc: 0.875
Train Iteration #13900:: 0.3075553774833679 Acc: 0.9375
Train Iteration #13950:: 0.35725104808807373 Acc: 0.90625
Train Iteration #14000:: 0.6854353547096252 Acc: 0.71875
Train Iteration #14050:: 0.4279325604438782 Acc: 0.78125
Train Iteration #14100:: 0.5594911575317383 Acc: 0.71875
Training:: Loss: 0.3891 Acc: 0.8778
Validation Iteration #3500:: 0.659970760345459 Acc: 0.71875
Validation Iteration #3550:: 0.5034708380699158 Acc: 0.75
Validation:: Loss: 0.4702 Acc: 0.8447
Epoch 44/49
----------
Train Iteration #14150:: 0.14063507318496704 Acc: 0.96875
Train Iteration #14200:: 0.488930344581604 Acc: 0.8125
Train Iteration #14250:: 0.3024919331073761 Acc: 0.96875
Train Iteration #14300:: 0.24604688584804535 Acc: 0.9375
Train Iteration #14350:: 0.27911582589149475 Acc: 1.0
Train Iteration #14400:: 0.1849631667137146 Acc: 0.9375
Training:: Loss: 0.3777 Acc: 0.8816
Validation Iteration #3600:: 0.3627064824104309 Acc: 0.84375
Validation:: Loss: 0.5026 Acc: 0.8123
Epoch 45/49
----------
Train Iteration #14450:: 0.545085608959198 Acc: 0.84375
Train Iteration #14500:: 0.4703882336616516 Acc: 0.84375
Train Iteration #14550:: 0.5528863072395325 Acc: 0.875
Train Iteration #14600:: 0.40066927671432495 Acc: 0.8125
Train Iteration #14650:: 0.5569526553153992 Acc: 0.78125
Train Iteration #14700:: 0.41035330295562744 Acc: 0.84375
Train Iteration #14750:: 0.427461713552475 Acc: 0.78125
Training:: Loss: 0.3824 Acc: 0.8823
Validation Iteration #3650:: 0.6869679689407349 Acc: 0.84375
Validation Iteration #3700:: 0.751097559928894 Acc: 0.78125
Validation:: Loss: 0.4692 Acc: 0.8697
Epoch 46/49
----------
Train Iteration #14800:: 0.5572983026504517 Acc: 0.78125
Train Iteration #14850:: 0.30458885431289673 Acc: 0.90625
Train Iteration #14900:: 0.3378244638442993 Acc: 0.90625
Train Iteration #14950:: 0.4947463274002075 Acc: 0.875
Train Iteration #15000:: 0.36444592475891113 Acc: 0.9375
Train Iteration #15050:: 0.35201317071914673 Acc: 0.84375
Training:: Loss: 0.3855 Acc: 0.8785
Validation Iteration #3750:: 0.44559401273727417 Acc: 0.84375
Validation Iteration #3800:: 0.4193488359451294 Acc: 0.84375
Validation:: Loss: 0.5023 Acc: 0.8119
Epoch 47/49
----------
Train Iteration #15100:: 0.2607826888561249 Acc: 0.90625
Train Iteration #15150:: 0.47165536880493164 Acc: 0.84375
Train Iteration #15200:: 0.3925480842590332 Acc: 0.875
Train Iteration #15250:: 0.2078854739665985 Acc: 0.9375
Train Iteration #15300:: 0.26580411195755005 Acc: 0.90625
Train Iteration #15350:: 0.4598305821418762 Acc: 0.8125
Train Iteration #15400:: 0.2978631258010864 Acc: 0.875
Training:: Loss: 0.4033 Acc: 0.8764
Validation Iteration #3850:: 0.430743545293808 Acc: 0.90625
Validation:: Loss: 0.5106 Acc: 0.8057
Epoch 48/49
----------
Train Iteration #15450:: 0.20927280187606812 Acc: 0.96875
Train Iteration #15500:: 0.14335599541664124 Acc: 0.9375
Train Iteration #15550:: 0.34038522839546204 Acc: 0.9375
Train Iteration #15600:: 0.5353825092315674 Acc: 0.71875
Train Iteration #15650:: 0.374493807554245 Acc: 0.84375
Train Iteration #15700:: 0.24943384528160095 Acc: 0.9375
Training:: Loss: 0.4054 Acc: 0.8758
Validation Iteration #3900:: 0.45481961965560913 Acc: 0.8125
Validation Iteration #3950:: 0.40565669536590576 Acc: 0.84375
Validation:: Loss: 0.4916 Acc: 0.8158
Epoch 49/49
----------
Train Iteration #15750:: 0.3733145296573639 Acc: 0.84375
Train Iteration #15800:: 0.3974260091781616 Acc: 0.84375
Train Iteration #15850:: 0.32942983508110046 Acc: 0.84375
Train Iteration #15900:: 0.26956993341445923 Acc: 0.9375
Train Iteration #15950:: 0.22839054465293884 Acc: 0.9375
Train Iteration #16000:: 0.39835405349731445 Acc: 0.75
Training:: Loss: 0.4005 Acc: 0.8769
Validation Iteration #4000:: 0.6040786504745483 Acc: 0.78125
Validation:: Loss: 0.5077 Acc: 0.8069
Best Validation Acc: 0.869684
End time:3:10:57.549549
Program Complete
Average Train Loss:0.44243478073233794
Average Validation Loss:0.5203006125998786
Average Train Accuracy:0.8568728053062817
Average Validation Accuracy:0.8122902848224736
